{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Загрузка-и-подготовка-данных\" data-toc-modified-id=\"Загрузка-и-подготовка-данных-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Загрузка и подготовка данных</a></span><ul class=\"toc-item\"><li><span><a href=\"#Загрузка-данных\" data-toc-modified-id=\"Загрузка-данных-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Загрузка данных</a></span></li><li><span><a href=\"#Подготовка-данных\" data-toc-modified-id=\"Подготовка-данных-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Подготовка данных</a></span></li><li><span><a href=\"#Анализ-обучающих-признаков-и-распределений-по-классам\" data-toc-modified-id=\"Анализ-обучающих-признаков-и-распределений-по-классам-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Анализ обучающих признаков и распределений по классам</a></span><ul class=\"toc-item\"><li><span><a href=\"#Количество-слов-word_count\" data-toc-modified-id=\"Количество-слов-word_count-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>Количество слов <code>word_count</code></a></span></li><li><span><a href=\"#Длина-текста-src_len\" data-toc-modified-id=\"Длина-текста-src_len-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>Длина текста <code>src_len</code></a></span></li><li><span><a href=\"#Длина-лемматизированного-текста-lemm_len\" data-toc-modified-id=\"Длина-лемматизированного-текста-lemm_len-1.3.3\"><span class=\"toc-item-num\">1.3.3&nbsp;&nbsp;</span>Длина лемматизированного текста <code>lemm_len</code></a></span></li><li><span><a href=\"#Доля-сжатия-zip_ratio\" data-toc-modified-id=\"Доля-сжатия-zip_ratio-1.3.4\"><span class=\"toc-item-num\">1.3.4&nbsp;&nbsp;</span>Доля сжатия <code>zip_ratio</code></a></span></li><li><span><a href=\"#Текст-в-UPPERCASE-is_upper\" data-toc-modified-id=\"Текст-в-UPPERCASE-is_upper-1.3.5\"><span class=\"toc-item-num\">1.3.5&nbsp;&nbsp;</span>Текст в UPPERCASE <code>is_upper</code></a></span></li><li><span><a href=\"#Формирование-обучающей-и-тестовой-выборок\" data-toc-modified-id=\"Формирование-обучающей-и-тестовой-выборок-1.3.6\"><span class=\"toc-item-num\">1.3.6&nbsp;&nbsp;</span>Формирование обучающей и тестовой выборок</a></span></li><li><span><a href=\"#Наиболее-часто-употребляемые-слова\" data-toc-modified-id=\"Наиболее-часто-употребляемые-слова-1.3.7\"><span class=\"toc-item-num\">1.3.7&nbsp;&nbsp;</span>Наиболее часто употребляемые слова</a></span></li></ul></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Выводы</a></span></li></ul></li><li><span><a href=\"#Обучение-моделей\" data-toc-modified-id=\"Обучение-моделей-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение моделей</a></span><ul class=\"toc-item\"><li><span><a href=\"#Подготовка-данных\" data-toc-modified-id=\"Подготовка-данных-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Подготовка данных</a></span></li><li><span><a href=\"#Логистическая-регрессия\" data-toc-modified-id=\"Логистическая-регрессия-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Логистическая регрессия</a></span></li><li><span><a href=\"#LinearSVC\" data-toc-modified-id=\"LinearSVC-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>LinearSVC</a></span></li><li><span><a href=\"#CatBoost\" data-toc-modified-id=\"CatBoost-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>CatBoost</a></span></li></ul></li><li><span><a href=\"#Анализ-наилучшей-модели\" data-toc-modified-id=\"Анализ-наилучшей-модели-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Анализ наилучшей модели</a></span><ul class=\"toc-item\"><li><span><a href=\"#Оценка-значимости-обучающих-признаков\" data-toc-modified-id=\"Оценка-значимости-обучающих-признаков-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Оценка значимости обучающих признаков</a></span></li><li><span><a href=\"#Остатки\" data-toc-modified-id=\"Остатки-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Остатки</a></span></li></ul></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Выводы</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для модерации комментариев в «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Цель проекта - обучить модель классифицировать комментарии на позитивные и негативные. В нашем распоряжении набор данных с разметкой о токсичности правок. \n",
    "\n",
    "Целевая метрика - построение модели со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "Задачи проекта:\n",
    "1. Загрузить данные и выполнить их предварительную подготовку.\n",
    "2. Обучить модели с различными гиперпараметрами.\n",
    "3. Проверить данные на тестовой выборке и сделать выводы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка и подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pymystem3 import Mystem\n",
    "from collections import Counter\n",
    "import re \n",
    "import datetime\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from catboost import Pool, CatBoostClassifier\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# метрики\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import zlib\n",
    "from scipy.sparse import coo_matrix, hstack\n",
    "\n",
    "from sklearn.metrics import f1_score, roc_auc_score, roc_curve, precision_score, \\\n",
    "                            recall_score, accuracy_score, precision_recall_curve\n",
    "\n",
    "from termcolor import colored\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполним загрузку пакета *nltk* для символьной и статистической обработки естественного языка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "tokenizer = WordPunctTokenizer()\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stopwords = nltk_stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Расширим список стоп-слов английского языка."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords.extend(['i\\'m', 'hi', '\\'m', '\\'t', '\\'s', '\\'', 'u', 'ok'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_MAGIC = 1024\n",
    "F1_TARGET_SCORE = 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных\n",
    "\n",
    "Выполним загрузку и предварительную оценку данных.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments = pd.read_csv('datasets/toxic_comments.csv')\n",
    "#df_comments = df_comments.sample(10000)\n",
    "df_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'toxic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_comments = df_comments.sample(15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Доля токсичных коментариев: {0:.1%}'.format(df_comments['toxic'].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исходные данные представлены в виде одной таблицы с двумя признаками: \n",
    "- текст (комментарий)\n",
    "- признак токсичности (целевой признак)\n",
    "\n",
    "В таблице содержится порядка 160 тысяч записей с размеченными комментариями. По условиям задачи моделирования требуется обучить модель, позволяющую классифицировать текст по признаку токсичности. Указанная модель предполагается к использованию Интернет-магазином «Викишоп» при оценке описаний товаров, оставляемых пользователями. Модель должна искать токсичные комментарии и отправлять их на модерацию.\n",
    "\n",
    "Метрикой качества является F1, целевым значением - 0.75. При этом следует обращать внимание на значение метрик полнота и точность. С точки зрения бизнеса интерпретировать эти метрики можно следующим образом:\n",
    "- полнота (recall) тем выше, чем меньше ложноотрицательных прогнозов дает модель - т.е. меньше количество пропущенных \"токсичных\" комментариев - указанная метрика содержит \"репутационные\" риски и издержки магазина (их сложно перевести непосредственно в денежное выражение, это скорее репутационные потери от наличия на сайте токсичных (в том числе, возможно, содержащих нецензурную лексику) комментариев\n",
    "- точность (precision) тем выше, чем меньше ложноположительных прогнозов - т.е. ошибочно отправленных на модерацию нетоксчиных комментариев - указанная метрика имеет непосредственное денежное выражение, это стоимость модерации одного комментария (у.е./час).\n",
    "О бизнесе Интернет-магазина «Викишоп» дополнительных данных не представлено, но с высокой степенью вероятности следует считать метрику полноты более значимой в денежном выражении относительно точности (репутационные риски обычно намного выше чем стоимость оплаты труда оператора/модератора).\n",
    "\n",
    "Доля токсичных комментариев в общем объеме данных - 10%. При обучении модели следует учитывать то, что целевые классы несбалансированы.\n",
    "\n",
    "Дубликатов в исходном наборе данных нет.\n",
    "\n",
    "Подробнее рассмотрим имеющиеся данные."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на примеры отдельных комментариев отнесенных к категории токсчиных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments[df_comments[target] == 1].head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Во-первых следует обратить внимание на то, что некоторые комментарии написаны в UPPERCASE. Чтобы не потерять эту информацию при последующей обработке текста, добавим новый признак к набору данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments['is_upper'] = df_comments['text'].str.isupper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Доля токсичных коментариев среди текстов в UPPERCASE: {0:.1%}'.format(\n",
    "    df_comments[df_comments['is_upper'] == 1]['toxic'].mean()\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, доля токсичных комментариев среди текстов в UPPERCASE существенно выше чем во всем наборе данных. Соответственно указанный признак целесообразно использовать при обучении модели.\n",
    "\n",
    "Далее проведем очистку текстов от знаков препинания, токенизацию и последующую лемматизацию исходного текста. Лемматизированный текст в дальнейшем будет использоваться для построения TF-IDF матрицы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "    eng = re.sub(r'[^A-Za-z \\']', ' ', text) \n",
    "    \n",
    "    #text_tokens = word_tokenize(eng)\n",
    "    text_tokens = tokenizer.tokenize(eng)\n",
    "\n",
    "    return \" \".join([word for word in text_tokens if not word in stopwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mys = Mystem()\n",
    "\n",
    "def lemmatize(text):\n",
    "    lemm_list = mys.lemmatize(text)\n",
    "    lemm_text = \"\".join(lemm_list)\n",
    "        \n",
    "    return lemm_text.replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments['clear_text'] = df_comments['text'].str.lower().apply(clear_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments['lemm_text'] = df_comments['clear_text'].apply(lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments['word_count'] = df_comments['lemm_text'].str.count(r'[ ]') + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кроме того, дополним обучающие признаки синтетическим признаком `zip_ratio` - соотношением объема сжатого лемматизированного текста к исходному объему текста. В основе генерации указанного признака предположение о том, что для токсичных комментариев  относительно нетоксичных комментариев характерна другая информативность (возможно, чаще используются повторения слов и фраз целиком, более частое употребление стоп-слов), соответственно по степени сжатия указанные тексты также будут отличаться."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_compressed_ratio(text):\n",
    "    text_rep = text.replace(' ', '')\n",
    "    text_len = len(text)\n",
    "\n",
    "    if (text_len > 0):\n",
    "        compressed = zlib.compress(bytes(text_rep, 'utf-8'))\n",
    "        return len(compressed) \n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments['src_len'] = df_comments['text'].str.len()\n",
    "df_comments['lemm_len'] = df_comments['lemm_text'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments['zip_len'] = df_comments['lemm_text'].apply(calc_compressed_ratio)\n",
    "df_comments['zip_ratio'] = df_comments[['zip_len','lemm_len']].min(axis=1) / df_comments['src_len']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Анализ обучающих признаков и распределений по классам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим особенности и распределение обучающих признаков по целевым классам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция отображения сводной информации о категориальном признаке:\n",
    "# выводит в текстовом виде униклаьные значения признака и график (гистограмму) распределения по категориям:\n",
    "# действующие и ушедшие клиенты\n",
    "def describe_column_category(column, title, df):\n",
    "    print('Признак', column, ':\\n')\n",
    "    print('Уникальные значения (процент):')\n",
    "    print(df[column].value_counts(normalize=True).mul(100).round(1).astype(str) + '%')\n",
    "    \n",
    "    print(\"\\nДоля по целевому признаку (токсичные/все комментарии):\")\n",
    "    print((\n",
    "            df.query('toxic == 1')[column].value_counts() / \n",
    "            df[column].value_counts()\n",
    "        ).mul(100).round(1).astype(str) + '%'\n",
    "    )\n",
    "        \n",
    "    fig = px.histogram(\n",
    "        df, \n",
    "        x = column,  \n",
    "        color = 'toxic',\n",
    "        color_discrete_map={\n",
    "                0: 'Green', 1: 'Red'\n",
    "            },\n",
    "        opacity = 0.7,\n",
    "        title = title\n",
    "    )\n",
    "\n",
    "    fig.update_layout(xaxis_title=title, yaxis_title='Число комментариев')\n",
    "    fig.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция отображения сводной информации о числовом признаке:\n",
    "# выводит в текстовом виде основные параметры распределения значений признака и график (гистограмму и \"ящик с усами\")\n",
    "# распределения по категориям:\n",
    "# действующие и ушедшие клиенты\n",
    "def describe_column_numeric(column, title, df):\n",
    "    print('Признак', column, ':')\n",
    "    \n",
    "    print(df[column].describe())\n",
    "    \n",
    "    fig = px.histogram(\n",
    "        df, \n",
    "        x = column, \n",
    "        marginal = 'box', \n",
    "        color = \"toxic\",\n",
    "        color_discrete_map={\n",
    "                0: 'Green', 1: 'Red'\n",
    "            },\n",
    "        opacity = 0.7,\n",
    "        title = title\n",
    "    )\n",
    "\n",
    "    fig.update_layout(xaxis_title=title, yaxis_title='Число комментариев')\n",
    "    fig.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Количество слов `word_count`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим тексты, в которых после лемматизации осталось только 1 слово."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments.query('word_count == 1').head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Доля текстов с 1 словом после лемматизации относительно всех данных: {0:.1%}'.format(\n",
    "    df_comments.query('word_count == 1').shape[0] / df_comments.shape[0])\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Среди указанных текстов есть как ошибочные (например, содержащие только дату или IP-адрес), так и пустые (например, \"No, it doesn´t\" - в силу особенностей английского языка предложения, состоящие только из стоп-слов могут быть значимыми в общем контексте - например, как ответ на предыдущий комментарий). \n",
    "\n",
    "Доля таких текстов - менее 1%. Учитывая то, что в дальшнейшем можно встроить в модель дополнительные проверки (например, проверка по словарю ненормативной лексики), то рассматривать тексты, состоящие из 1 слова (после лемматизации) в целом нецелесообразно, исключим их из рассмотрения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments = df_comments.query('word_count > 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Длина текста `src_len`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим распределение исходных текстов по длине текста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_column_numeric('src_len', 'Длина текста', df_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на \"выбросы\" по длине текста, в качестве возможной границы отсечения возьмем Q3+3*IQR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q3_3iqr = df_comments['src_len'].quantile(0.75) + 3 * (\n",
    "    df_comments['src_len'].quantile(0.75) - df_comments['src_len'].quantile(0.25)\n",
    ")\n",
    "q3_3iqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments[df_comments['src_len'] > q3_3iqr].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Доля текстов длины более {0} символов относительно всех данных: {1:.1%}'.format(int(q3_3iqr),\n",
    "    df_comments.query('src_len > @q3_3iqr').shape[0] / df_comments.shape[0])\n",
    "     )\n",
    "print('Доля токсичных коментариев в указанных текстах: {0:.1%}'.format(\n",
    "    df_comments[df_comments['src_len'] > q3_3iqr]['toxic'].mean())\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Доля токсичных комментариев среди отобранных \"длинных\" текстов немного меньше их доли в общем объеме данных. В целом объем \"длинных\" текстов составляет ~4.4% исходной выборки.\n",
    "\n",
    "У нас недостаточно сведений о деятельности Интернет-магазина «Викишоп», но с большой долей уверенности можно предположить, что разумное ограничение на длину комментария/описания товара, оставляемого пользователем, вполне допустимо (в целом, это нормальная практика, когда при вводе текста пользователь ограничен в количестве вводимых символов/слов). Исключим указанные \"длинные\" тексты из дальнейшего рассмотрения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments = df_comments.query('src_len <= @q3_3iqr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_column_numeric('src_len', 'Длина текста', df_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь форма распределения текстов по длине близка к распределению Пуассона. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Длина лемматизированного текста `lemm_len`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим распределение исходных текстов по длине лемматизированного текста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_column_numeric('lemm_len', 'Длина лемматизированного текста', df_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на \"выбросы\" по длине текста после лемматизации, в качестве возможной границы отсечения возьмем Q3+3*IQR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q3_3iqr = df_comments['lemm_len'].quantile(0.75) + 3 * (\n",
    "    df_comments['lemm_len'].quantile(0.75) - df_comments['lemm_len'].quantile(0.25)\n",
    ")\n",
    "q3_3iqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments[df_comments['lemm_len'] > q3_3iqr].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Доля текстов длины более {0} символов после лемматизации относительно всех данных: {1:.1%}'.format(int(q3_3iqr),\n",
    "    df_comments.query('lemm_len > @q3_3iqr').shape[0] / df_comments.shape[0])\n",
    "     )\n",
    "print('Доля токсичных коментариев в указанных текстах: {0:.1%}'.format(\n",
    "    df_comments[df_comments['lemm_len'] > q3_3iqr]['toxic'].mean())\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Доля токсичных комментариев среди отобранных \"длинных\" текстов немного меньше их доли в общем объеме данных. В целом объем \"длинных\" текстов составляет ~4.1% исходной выборки.\n",
    "\n",
    "Учитывая то, что мы ввели ограничение на общую длину оставляемого комментария, цеелесообразно также рассмотреть и длины текстов после лемматизации (или их соотношение с исходной длиной). Наверно здесь требуются более глубокие лингвистические исследования или статистические сведения об особенностях текстов на английском языке, но было бы разумно предположить, что \"обычные\" комментарии (оставляемые пользователями) с точки зрения длины лемматизированных текстов отличаются, например, от сгенерированных ботами или выдержками из специальной литературы. В рамках построения настоящей модели мы исключим указанные \"длинные\" лемматизированные тексты из дальнейшего рассмотрения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments = df_comments.query('lemm_len <= @q3_3iqr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_column_numeric('lemm_len', 'Длина лемматизированного текста', df_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь форма распределения текстов по длине лемматизированного текста близка к распределению Пуассона. При этом распределения по целевому признаку различаются (смещены медиана и межквартильный размах), что говорит о целесообразности применения указанного признака при обучении."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Доля сжатия `zip_ratio`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим распределение исходных текстов по соотношению объема сжатого текста к исходному объему."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_column_numeric('zip_ratio', 'Доля сжатия', df_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Доля текстов с коэффициентом сжатия менее 0.2 относительно всех данных: {1:.1%}'.format(int(q3_3iqr),\n",
    "    df_comments.query('zip_ratio < 0.2').shape[0] / df_comments.shape[0])\n",
    "     )\n",
    "print('Доля токсичных коментариев в указанных текстах: {0:.1%}'.format(\n",
    "    df_comments.query('zip_ratio < 0.2')['toxic'].mean())\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments.query('zip_ratio < 0.2').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Среди текстов с высоким коэффициентом сжатия доля токсичных существенно выше, чем в среднем по набору данных. При этом указанные тексты вполне могут быть написаны человеком. Их целесообразно оставить для обучения (этот признак может оказаться значимым).\n",
    "\n",
    "Посмотрим на \"выбросы\" в районе 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Доля текстов с коэффициентом сжатия равным 1 относительно всех данных: {1:.1%}'.format(int(q3_3iqr),\n",
    "    df_comments.query('zip_ratio == 1').shape[0] / df_comments.shape[0])\n",
    "     )\n",
    "print('Доля токсичных коментариев в указанных текстах: {0:.1%}'.format(\n",
    "    df_comments.query('zip_ratio == 1')['toxic'].mean())\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments.query('zip_ratio == 1').head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Указанные тексты в основном похожи на служебную сообщения (в том чсиле, перенаправления на другие комментарии/статьи). В них доля токсичных совпадает со средней по набору данных.\n",
    "\n",
    "Указанные тексты исключим из дальнейшего рассмотрения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments = df_comments.query('zip_ratio < 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Текст в UPPERCASE `is_upper`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_column_category('is_upper', 'Текст в UPPERCASE', df_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как было рассмотрено выше - доля токсичных комментариев в UPPERCASE намного выше, чем в среднем по набору данных. Указанный признак целесообразно использовать при обучении."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Формирование обучающей и тестовой выборок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('После удаления выбросов в наборе данных осталось: {0} записей'.format(df_comments.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделим в исходном наборе данных обучающую и тестовую выборки со стратификацией по целевому признаку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(\n",
    "    df_comments, test_size=0.15, random_state=RANDOM_MAGIC, stratify=df_comments[target]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Наиболее часто употребляемые слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_all_class(df_data, target_value):\n",
    "    text = \" \"\n",
    "    category = df_data[df_data[target] == target_value]\n",
    "    for idx, row in tqdm(category.iterrows(), total=category.shape[0]):\n",
    "        text += row['lemm_text'] + \" \"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_class(df_data, target_value, figsize=(7, 5)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    category = get_text_all_class(df_data, target_value)\n",
    "    wordcloud = WordCloud(max_font_size=40).generate(category)\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отобразим в виде облака слов наиболее часто встречаемые слова в каждом из классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_class(df_train, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_class(df_train, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следует отметить, что для класса токсичных комментариев ожидаемо наиболее часто употребляемыми являются нецензурные слова. Вместе с тем, отдельные общеупотребительные слова (например, think, one, page, article, make) являются частыми в обоих классах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы\n",
    "\n",
    "Исходные данные представлены в виде одной таблицы с двумя признаками: \n",
    "- текст (комментарий)\n",
    "- признак токсичности (целевой признак)\n",
    "\n",
    "В таблице содержится порядка 160 тысяч записей с размеченными комментариями. Дубликатов в исходном наборе данных нет. Доля токсичных комментариев в общем объеме данных - 10%. При обучении модели следует учитывать то, что целевые классы несбалансированы.\n",
    "\n",
    "По условиям задачи моделирования требуется обучить модель, позволяющую классифицировать текст по признаку токсичности. Указанная модель предполагается к использованию Интернет-магазином «Викишоп» при оценке описаний товаров, оставляемых пользователями. Модель должна искать токсичные комментарии и отправлять их на модерацию.\n",
    "\n",
    "Метрикой качества является F1, целевым значением - 0.75. При этом следует обращать внимание на значение метрик полнота и точность. С точки зрения бизнеса интерпретировать эти метрики можно следующим образом:\n",
    "- полнота (recall) тем выше, чем меньше ложноотрицательных прогнозов дает модель - т.е. меньше количество пропущенных \"токсичных\" комментариев - указанная метрика содержит \"репутационные\" риски и издержки магазина (их сложно перевести непосредственно в денежное выражение, это скорее репутационные потери от наличия на сайте токсичных (в том числе, возможно, содержащих нецензурную лексику) комментариев\n",
    "- точность (precision) тем выше, чем меньше ложноположительных прогнозов - т.е. ошибочно отправленных на модерацию нетоксчиных комментариев - указанная метрика имеет непосредственное денежное выражение, это стоимость модерации одного комментария (у.е./час).\n",
    "О бизнесе Интернет-магазина «Викишоп» дополнительных данных не представлено, но с высокой степенью вероятности следует считать метрику полноты более значимой в денежном выражении относительно точности (репутационные риски обычно намного выше чем стоимость оплаты труда оператора/модератора).\n",
    "\n",
    "На этапе подготовки данных обучающие признаки дополнены несколькими синтетическими признаками, в частности `zip_ratio` - соотношением объема сжатого лемматизированного текста к исходному объему текста. В основе генерации указанного признака предположение о том, что для токсичных комментариев  относительно нетоксичных комментариев характерна другая информативность (возможно, чаще используются повторения слов и фраз целиком, более частое употребление стоп-слов), соответственно по степени сжатия указанные тексты также будут отличаться.\n",
    "\n",
    "На этапе анализа проведена оценка распределения значений отдельных признаков по целевым классам. Устранены отдельные выбросы, в том числе по длине представленных текстов, на основе предположения об имеющихся на сайте Интернет-магазина «Викишоп» разумных ограничениях на длину комментария/описания товара, оставляемого пользователем. \n",
    "\n",
    "Данные подготовлены для последующего обучения моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассчитаем частоты слов обучающей выборки и на их основе составим матрицы TF-IDF для корпуса слов обучающей и тестовой выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = df_train['lemm_text'].values.astype('U')\n",
    "\n",
    "count_tf_idf = TfidfVectorizer() \n",
    "\n",
    "tf_idf_train = count_tf_idf.fit_transform(corpus) \n",
    "\n",
    "tf_idf_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = df_test['lemm_text'].values.astype('U')\n",
    "\n",
    "tf_idf_test = count_tf_idf.transform(corpus) \n",
    "\n",
    "tf_idf_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_Y = df_train[target]\n",
    "df_test_Y = df_test[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дополним сформированные TF-IDF матрицы значениями дополнительных обучающих признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_X = tf_idf_train\n",
    "df_train_X = hstack((df_train_X, np.array(df_train['is_upper'])[:,None]))\n",
    "df_train_X = hstack((df_train_X, np.array(df_train['zip_ratio'])[:,None]))\n",
    "df_train_X = hstack((df_train_X, np.array(df_train['lemm_len'])[:,None]))\n",
    "#df_train_X = hstack((df_train_X, np.array(df_train['src_len'])[:,None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_X = tf_idf_test\n",
    "df_test_X = hstack((df_test_X, np.array(df_test['is_upper'])[:,None]))\n",
    "df_test_X = hstack((df_test_X, np.array(df_test['zip_ratio'])[:,None]))\n",
    "df_test_X = hstack((df_test_X, np.array(df_test['lemm_len'])[:,None]))\n",
    "#df_test_X = hstack((df_test_X, np.array(df_test['src_len'])[:,None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция печати графика ROC-кривой\n",
    "# df_roc_auc - dataframe исходных данных для построения графика ROC-кривой (значения TPR, FPR и пороговые отсечки)\n",
    "# roc_auc_val - значение метрики ROC-AUC\n",
    "# color - цвет отображения\n",
    "def print_roc_auc_plot(df_roc_auc, roc_auc_val, color):\n",
    "    fig = px.area(\n",
    "        df_roc_auc,\n",
    "        x='fpr', y='tpr',\n",
    "        title=f'ROC-кривая (AUC={roc_auc_val:.4f})',\n",
    "        width=900, \n",
    "        height=500,\n",
    "        color='color',\n",
    "        color_discrete_map={\n",
    "                'red': 'Red', 'green': 'Green'\n",
    "            },\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[0, 1], \n",
    "            y=[0, 1], \n",
    "            name=\"Случайная модель\",\n",
    "            line=dict(color=color, width=2, dash='dash'),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.update_yaxes(scaleanchor=\"x\", scaleratio=0.9)\n",
    "    fig.update_xaxes(constrain='domain')\n",
    "    fig.update_layout(xaxis_title='FPR (доля ложноположительных)', yaxis_title='TPR (доля истинно положительных)')\n",
    "    fig.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция печати метрик обученной модели\n",
    "def print_scores(model_fitted, X_test, Y_test):\n",
    "    predictions = model_fitted.predict(X_test)\n",
    "    \n",
    "    probabilities_valid = model_fitted.predict_proba(X_test)\n",
    "    probabilities_one_valid = probabilities_valid[:, 1]\n",
    "\n",
    "    f1_val = f1_score(Y_test, predictions)\n",
    "    roc_auc_val = roc_auc_score(Y_test, probabilities_one_valid)\n",
    "    \n",
    "    print(colored(\"\\x1b[1mF1: {0}\\x1b[0m\".format(f1_val), 'red' if f1_val < F1_TARGET_SCORE else 'green'))\n",
    "    print('AUC-ROC:', roc_auc_val)\n",
    "    print('Precision:', precision_score(Y_test, predictions))\n",
    "    print('Recall:', recall_score(Y_test, predictions))\n",
    "    print('Accuracy:', accuracy_score(Y_test, predictions))\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(Y_test, probabilities_one_valid) \n",
    "\n",
    "    df_roc_auc = pd.DataFrame()\n",
    "    df_roc_auc['fpr'] = fpr\n",
    "    df_roc_auc['tpr'] = tpr\n",
    "    df_roc_auc['thresholds'] = thresholds\n",
    "    df_roc_auc['color'] = 'red'\n",
    "        \n",
    "    if f1_val >= F1_TARGET_SCORE:\n",
    "        df_roc_auc['color'] = 'green'\n",
    "        print_roc_auc_plot(df_roc_auc, roc_auc_val, 'green')\n",
    "    else:\n",
    "        print_roc_auc_plot(df_roc_auc, roc_auc_val, 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#функция формирования датафрейма со значениями метрик precision, recall и f1 в диапазоне порогов\n",
    "def get_proba_df(model_fitted, X_test, Y_test):\n",
    "    probabilities_valid = model_fitted.predict_proba(X_test)\n",
    "    probabilities_one_valid = probabilities_valid[:, 1]\n",
    "\n",
    "    scores = []\n",
    "    for threshold in np.arange(0.1, 0.9, 0.01):\n",
    "        predicted_valid = probabilities_one_valid > threshold\n",
    "        precision = precision_score(Y_test, predicted_valid)\n",
    "        recall = recall_score(Y_test, predicted_valid)\n",
    "        f1 = f1_score(Y_test, predicted_valid)\n",
    "\n",
    "        scores.append([threshold, precision, recall, f1])\n",
    "        \n",
    "    df_scores = pd.DataFrame(scores, columns=['threshold', 'precision', 'recall', 'f1'])\n",
    "    return df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#функция вывода графика метрик precision, recall и f1\n",
    "def print_proba(df_scores):\n",
    "    fig = px.area(\n",
    "        df_scores,\n",
    "        x='threshold', \n",
    "        y='f1',\n",
    "        width=900, \n",
    "        height=500,\n",
    "        color_discrete_map={\n",
    "                'red': 'Red', 'green': 'Green'\n",
    "            },\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df_scores['threshold'], \n",
    "            y=df_scores['precision'], \n",
    "            name=\"Точность (precision)\",\n",
    "            line=dict(color='red', width=2),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df_scores['threshold'], \n",
    "            y=df_scores['recall'], \n",
    "            name=\"Полнота (recall)\",\n",
    "            line=dict(color='blue', width=2),\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[0.1,0.9],\n",
    "            y=[F1_TARGET_SCORE, F1_TARGET_SCORE], \n",
    "            name=\"Целевое значение<br>метрики F1\",\n",
    "            line=dict(color='magenta', width=3),\n",
    "        )\n",
    "    )\n",
    "        \n",
    "    fig.update_yaxes(scaleanchor=\"x\", scaleratio=0.9)\n",
    "    fig.update_xaxes(constrain='domain')\n",
    "    \n",
    "    fig.update_layout(\n",
    "        xaxis=dict(\n",
    "            #range=[0.1, 0.9],\n",
    "\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            range=[0.6, 0.95],\n",
    "        ),\n",
    "        \n",
    "        \n",
    "        xaxis_title='Порог', \n",
    "        yaxis_title='Метрика'\n",
    "    )\n",
    "    fig.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# политика разбиения на фолды при кросс-валидации: число фолдов - 6, со стратификацией\n",
    "cv = StratifiedKFold(6, random_state=RANDOM_MAGIC, shuffle=True)\n",
    "\n",
    "# мера, используемая при кросс-валидации - F1, положительный класс - значение '1' (токсичные комментарии)\n",
    "#scoring = make_scorer(roc_auc_score, labels=['1'])\n",
    "scoring = make_scorer(roc_auc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем обучение и последующий анализ нескольких моделей на подготовленных данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = LogisticRegression(random_state=RANDOM_MAGIC, max_iter=5000, solver='liblinear', class_weight='balanced')\n",
    "\n",
    "param_grid_lr = {\n",
    "    'model__C': [100, 10, 1.0],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = param_grid_lr\n",
    "model = model_lr\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    Pipeline([('model', model)]), \n",
    "    param_grid=params, \n",
    "    cv=cv, \n",
    "    scoring=scoring\n",
    ")    \n",
    "\n",
    "grid_search.fit(df_train_X, df_train_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем график кривой ROC-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_scores(grid_search, df_test_X, df_test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А также выведем график зависимости метрик от используемых порогов отнесения к целевым классам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores = get_proba_df(grid_search, df_test_X, df_test_Y)\n",
    "print_proba(df_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На графике видно, что целевое значение метрики F1 достигается в достаточно широком диапазоне порогов - примерно в интервале от 0.49 до 0.59. Вместе с тем, одновременно необходимо оценивать значения метрик полноты и точности. Учитывая то, что ранее мы определили метрику полноты более значимой с точки зрения ее \"стоимости\" в бизнесе, к приемлемым значениям порогов следует отнести более узкий интервал вокруг точки пересечения метрик - (0.6, 0.7)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores.loc[(df_scores[\"threshold\"] >= 0.6) & (df_scores[\"threshold\"] <= 0.7)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_svc = LinearSVC(random_state=RANDOM_MAGIC, max_iter=5000, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = CalibratedClassifierCV(model_svc, cv = cv) \n",
    "clf.fit(df_train_X, df_train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_scores(clf, df_test_X, df_test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем график зависимости метрик от используемых порогов отнесения к целевым классам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores = get_proba_df(clf, df_test_X, df_test_Y)\n",
    "print_proba(df_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На графике видно, что целевое значение метрики F1 также достигается в достаточно широком диапазоне порогов - примерно в интервале от 0.17 до 0.64. \n",
    "К приемлемым значениям порогов следует отнести более узкий интервал вокруг точки пересечения метрик - (0.24, 0.34)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores.loc[(df_scores[\"threshold\"] >= 0.22) & (df_scores[\"threshold\"] <= 0.32)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В целом следует отметить, что рассмотренные модели показали примерно одинаковый результат по достигнутым значениям метрик. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перейдем к рассмотрению модели, которая учитывает не только частоты слов в тексте, но и частоты различных синтаксических N-грамм (последовательностей лемматизированных слов).\n",
    "\n",
    "Дополнительно разделим обучающую выборку на обучающую и валидационную (доля валидационной примерно соответствует доле тестовой выборки для финальной проверки модели)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = train_test_split(df_train,\n",
    "                                                test_size=0.15, \n",
    "                                                stratify=df_train['toxic'], \n",
    "                                                shuffle=True, random_state=RANDOM_MAGIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['is_upper', 'zip_ratio', 'lemm_len', 'lemm_text']\n",
    "\n",
    "cat_features = ['is_upper']\n",
    "\n",
    "text_features = ['lemm_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(\n",
    "    cat_features=cat_features,\n",
    "    text_features=text_features,\n",
    "    verbose=50,\n",
    "    #loss_function='MultiClass',\n",
    "    eval_metric='AUC',\n",
    "    task_type=\"CPU\",\n",
    "    iterations=1000,\n",
    "    learning_rate=0.2,      \n",
    "#     reg_lambda=0.0001,\n",
    "    \n",
    "    text_processing = {\n",
    "        \"tokenizers\" : [{\n",
    "            \"tokenizer_id\" : \"Space\",\n",
    "            \"separator_type\" : \"ByDelimiter\",\n",
    "            \"delimiter\" : \" \"\n",
    "        }],\n",
    "\n",
    "        \"dictionaries\" : [{\n",
    "            \"dictionary_id\" : \"BiGram\",\n",
    "            \"token_level_type\": \"Letter\",\n",
    "            \"max_dictionary_size\" : \"150000\",\n",
    "            \"occurrence_lower_bound\" : \"1\",\n",
    "            \"gram_order\" : \"2\"\n",
    "        },{\n",
    "            \"dictionary_id\" : \"Trigram\",\n",
    "            \"max_dictionary_size\" : \"150000\",\n",
    "            \"token_level_type\": \"Letter\",\n",
    "            \"occurrence_lower_bound\" : \"1\",\n",
    "            \"gram_order\" : \"3\"\n",
    "        },{\n",
    "            \"dictionary_id\" : \"Fourgram\",\n",
    "            \"max_dictionary_size\" : \"150000\",\n",
    "            \"token_level_type\": \"Letter\",\n",
    "            \"occurrence_lower_bound\" : \"1\",\n",
    "            \"gram_order\" : \"4\"\n",
    "        },{\n",
    "            \"dictionary_id\" : \"Fivegram\",\n",
    "            \"max_dictionary_size\" : \"150000\",\n",
    "            \"token_level_type\": \"Letter\",\n",
    "            \"occurrence_lower_bound\" : \"1\",\n",
    "            \"gram_order\" : \"5\"\n",
    "        },{\n",
    "            \"dictionary_id\" : \"Sixgram\",\n",
    "            \"max_dictionary_size\" : \"150000\",\n",
    "            \"token_level_type\": \"Letter\",\n",
    "            \"occurrence_lower_bound\" : \"1\",\n",
    "            \"gram_order\" : \"6\"\n",
    "        }\n",
    "        ],\n",
    "\n",
    "        \"feature_processing\" : {\n",
    "            \"default\" : [\n",
    "                    {\n",
    "                    \"dictionaries_names\" : [\"BiGram\", \"Trigram\", \"Fourgram\", \"Fivegram\", \"Sixgram\"],\n",
    "                    \"feature_calcers\" : [\"BoW\"],\n",
    "                    \"tokenizers_names\" : [\"Space\"]\n",
    "                },\n",
    "                    {\n",
    "                \"dictionaries_names\" : [\"BiGram\", \"Trigram\", \"Fourgram\", \"Fivegram\", \"Sixgram\"],\n",
    "                \"feature_calcers\" : [\"NaiveBayes\"],\n",
    "                \"tokenizers_names\" : [\"Space\"]\n",
    "            },{\n",
    "                \"dictionaries_names\" : [ \"BiGram\", \"Trigram\", \"Fourgram\", \"Fivegram\", \"Sixgram\"],\n",
    "                \"feature_calcers\" : [\"BM25\"],\n",
    "                \"tokenizers_names\" : [\"Space\"]\n",
    "            },\n",
    "            ],\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    train[feature_names], train[target],\n",
    "    eval_set=(valid[feature_names], valid[target]),\n",
    "    plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_X = df_test[feature_names]\n",
    "df_test_Y = df_test[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_scores(model, df_test_X, df_test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем график зависимости метрик от используемых порогов отнесения к целевым классам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores = get_proba_df(model, df_test_X, df_test_Y)\n",
    "print_proba(df_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В отличие от рассмотренных выше моделей на графике видно, что целевое значение метрики F1 также достигается не только в более широком диапазоне порогов - примерно в интервале от 0.15 до 0.75 - но и само значение метрики F1 существенно выше. \n",
    "К приемлемым значениям порогов следует отнести более узкий интервал вокруг точки пересечения метрик - (0.27, 0.40)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores.loc[(df_scores[\"threshold\"] >= 0.27) & (df_scores[\"threshold\"] <= 0.40)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Анализ наилучшей модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем анализ результатов, полученных при использовании модели CatBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оценка значимости обучающих признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция печати графика значимости обучающих признаков\n",
    "def print_feature_importance(arr_importance, column_names):\n",
    "    rel_feature_imp = np.abs(100 * (arr_importance / max(arr_importance)))\n",
    "    \n",
    "    rel_feature_df = pd.DataFrame(\n",
    "        {\n",
    "            'features' : list(column_names),\n",
    "            'rel_importance' : rel_feature_imp\n",
    "        }\n",
    "    )\n",
    "\n",
    "    rel_feature_df = rel_feature_df.sort_values('rel_importance', ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.yticks(fontsize=15)\n",
    "\n",
    "    ax = sns.barplot(\n",
    "        x = 'rel_importance', \n",
    "        y = 'features',\n",
    "        data = rel_feature_df,\n",
    "        palette = 'Accent_r'\n",
    "    )\n",
    "\n",
    "    plt.xlabel('Относительная значимость', fontsize=25)\n",
    "    plt.ylabel('Признаки', fontsize=25)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_importance = model.get_feature_importance(prettified=True)\n",
    "\n",
    "print_feature_importance(df_importance['Importances'], df_importance['Feature Id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ожидаемо наиболее значимым признаком оказался лемматизированный текст (и соответственно производное от него векторное представление текста), но вместе с тем и введенные дополнительные признаки имеют ненулевую значимость."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Остатки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Немного подробнее посмотрим на ошибки классификации модели. В качестве порогового значения выберем значение 0.38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_threshold = 0.38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities_valid = model.predict_proba(df_test_X)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "\n",
    "scores = []\n",
    "\n",
    "predicted_valid = probabilities_one_valid > f1_threshold\n",
    "precision = precision_score(df_test_Y, predicted_valid)\n",
    "recall = recall_score(df_test_Y, predicted_valid)\n",
    "f1 = f1_score(df_test_Y, predicted_valid)\n",
    "\n",
    "scores.append([f1_threshold, precision, recall, f1])\n",
    "        \n",
    "df_scores = pd.DataFrame(scores, columns=['threshold', 'precision', 'recall', 'f1'])\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим к таргету тестовой выборки предсказанные значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_Y_res = pd.DataFrame(df_test_Y.copy())\n",
    "df_test_Y_res['pred'] = pd.DataFrame(np.transpose(predicted_valid.astype(int)), index=df_test_Y_res.index)\n",
    "df_test_Y_res.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сфомируем датафреймы с ложноположительными и ложноотрицательными значениями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fp = df_test_Y_res.query('pred > toxic')\n",
    "df_fn = df_test_Y_res.query('pred < toxic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В первую очередь посмотрим ложноотрицательные значения.\n",
    "\n",
    "Посмотрим на распределение по длине исходного текста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_column_numeric(\n",
    "    'src_len', 'Длина лемматизированного текста', \n",
    "    df_comments.loc[df_fn.index][['toxic', 'src_len', 'lemm_len', 'text', 'lemm_text']]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Распределение в целом повторяет распределение на обучающей выборке, но при этом правая граница межквартильного размаха смещена вправо, т.е. больше \"длинных\" текстов попало в межквартильный интервал ошибки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_comments.loc[df_fn.index].query('src_len < 250').sample(30)[['toxic', 'is_upper', 'src_len', 'text', 'lemm_text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По указанным примерам можно сделать следующие предположения о возможных направлениях улучшения модели:\n",
    "- следует лучше отбирать значения в UPPERCASE (например, считать долю символов в UPPERCASE относительно всего текста)\n",
    "- следует отдельно интерпретировать нецензурные слова с пропусками букв (например, cr@p, f*ing, WTF, Dl2000CK)\n",
    "- возможно следует подключить проверку по словарю/наличию орфографических ошибок (опять-таки размечать долю слов с ошибками относительно всего текста)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_comments.loc[df_fn.index].query('src_len > 400').sample(15)[['toxic', 'is_upper', 'src_len', 'text', 'lemm_text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На примерах \"длинных\" текстов также можно сделать предположение о возможных направлениях улучшения модели:\n",
    "- исключать тексты на политическую тематику (например, с упоминанием стран, национальностей, политических партий) либо давать им соответствующую разметку"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также посмотрим на примеры ложноположительных ответов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments.loc[df_fp.index].query('src_len < 250').sample(15)[['toxic', 'is_upper', 'src_len', 'text', 'lemm_text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примеры ложноположительных ответов вместе с тем говорят скорее об ошибках в разметке исходных данных - очевидно наличие комментариев, которые по содержанию скорее следует отнести к токсичным (что модель и сделала):\n",
    "- ILL COME TO YOUR HOUSE ND MAKE U SORE BETWEEN UR LEGS\n",
    "- A JEW? OR NOT A JEW?\n",
    "- JULIE \\n\\nWOW THANKS FOR BLOCKING ME! hateyouevenmore\n",
    "- moved to http://www.freearchive.org/wiki2/index.php/Tape_editing\\nfor safety (the wikipedia idiots don't want to include this page)\n",
    "- NO I HATE IT BECAUSE YOU DELETE EVERYTHING\n",
    "- shut up man! \\n\\nSHUT UP I DID NOT DO ANYTHING Click Here for what I Wrote To You A Few Months Ago.\n",
    "\n",
    "Указанные примеры говорят об имеющихся недостатках в разметке исходных данных, которые целесообразно в последующем устранить (что также должно сказаться на повышении точности модели)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исследование проводилось в интересах Интернет-магазина «Викишоп», запускающего новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.\n",
    "\n",
    "Цель проекта - обучить модель классифицировать комментарии на позитивные и негативные. На исследование предоставлен набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Исходные данные представлены в виде одной таблицы с двумя признаками: \n",
    "- текст (комментарий)\n",
    "- признак токсичности (целевой признак)\n",
    "\n",
    "В таблице содержится порядка 160 тысяч записей с размеченными комментариями. Дубликатов в исходном наборе данных нет. Доля токсичных комментариев в общем объеме данных - 10%. При обучении модели следует учитывать то, что целевые классы несбалансированы.\n",
    "\n",
    "По условиям задачи моделирования требуется обучить модель, позволяющую классифицировать текст по признаку токсичности. Модель должна искать токсичные комментарии и отправлять их на модерацию.\n",
    "\n",
    "Метрикой качества является F1, целевым значением - 0.75. При этом следует обращать внимание на значение метрик полнота и точность. С точки зрения бизнеса интерпретировать эти метрики можно следующим образом:\n",
    "- полнота (recall) тем выше, чем меньше ложноотрицательных прогнозов дает модель - т.е. меньше количество пропущенных \"токсичных\" комментариев - указанная метрика содержит \"репутационные\" риски и издержки магазина (их сложно перевести непосредственно в денежное выражение, это скорее репутационные потери от наличия на сайте токсичных (в том числе, возможно, содержащих нецензурную лексику) комментариев\n",
    "- точность (precision) тем выше, чем меньше ложноположительных прогнозов - т.е. ошибочно отправленных на модерацию нетоксчиных комментариев - указанная метрика имеет непосредственное денежное выражение, это стоимость модерации одного комментария (у.е./час).\n",
    "О бизнесе Интернет-магазина «Викишоп» дополнительных данных не представлено, но с высокой степенью вероятности следует считать метрику полноты более значимой в денежном выражении относительно точности (репутационные риски обычно намного выше чем стоимость оплаты труда оператора/модератора).\n",
    "\n",
    "На этапе подготовки данных обучающие признаки дополнены несколькими синтетическими признаками.\n",
    "\n",
    "На этапе анализа проведена оценка распределения значений отдельных признаков по целевым классам. Устранены отдельные выбросы, в том числе по длине представленных текстов, на основе предположения об имеющихся на сайте Интернет-магазина «Викишоп» разумных ограничениях на длину комментария/описания товара, оставляемого пользователем. \n",
    "\n",
    "Проведено обучение двух моделей на основе матрицы TF-IDF значимости слов лемматизированного текста (модели линейной регрессии и LinearSVC), а также модели CatBoostClassifier на основе векторного представления различных N-грамм лемматизированного текста.\n",
    "\n",
    "По результатам обучения модели получены следующие результаты:\n",
    "- все модели позволили достичь целевое значение метрики F1\n",
    "- наилучшее значение метрики показала модель CatBoostClassifier - F1 = 0.79, Точность - 0.81, Полнота -\t0.77, при пороговом значении отнесения к положительному классу равным 0.38\n",
    "\n",
    "Анализ неверных предсказаний модели позволил определить возможные направления для ее улучшения:\n",
    "- следует лучше отбирать значения в UPPERCASE (например, считать долю символов в UPPERCASE относительно всего текста)\n",
    "- следует отдельно интерпретировать нецензурные слова с пропусками букв (например, cr@p, f*ing, WTF, Dl2000CK)\n",
    "- возможно следует подключить проверку по словарю/наличию орфографических ошибок (опять-таки размечать долю слов с ошибками относительно всего текста)\n",
    "- исключать тексты на политическую тематику (например, с упоминанием стран, национальностей, политических партий) либо давать им соответствующую разметку\n",
    "\n",
    "Кроме того, выборочная оценка ложноположительных ответов говорит скорее об ошибках в разметке исходных данных - очевидно наличие комментариев, которые по содержанию скорее следует отнести к токсичным (что модель и сделала). Указанные недостатки в разметке исходных данных целесообразно в последующем устранить для повышении точности модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
