{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Загрузка-и-подготовка-данных\" data-toc-modified-id=\"Загрузка-и-подготовка-данных-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Загрузка и подготовка данных</a></span><ul class=\"toc-item\"><li><span><a href=\"#Загрузка-данных\" data-toc-modified-id=\"Загрузка-данных-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Загрузка данных</a></span></li><li><span><a href=\"#Сортировка-и-семплирование\" data-toc-modified-id=\"Сортировка-и-семплирование-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Сортировка и семплирование</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Выводы</a></span></li></ul></li><li><span><a href=\"#Анализ-обучающей-выборки\" data-toc-modified-id=\"Анализ-обучающей-выборки-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Анализ обучающей выборки</a></span><ul class=\"toc-item\"><li><span><a href=\"#Выявление-трендов\" data-toc-modified-id=\"Выявление-трендов-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Выявление трендов</a></span></li><li><span><a href=\"#Дневные-графики-(D1)\" data-toc-modified-id=\"Дневные-графики-(D1)-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Дневные графики (D1)</a></span></li><li><span><a href=\"#4-часовые-графики-(H4)\" data-toc-modified-id=\"4-часовые-графики-(H4)-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>4-часовые графики (H4)</a></span></li><li><span><a href=\"#Часовые-графики-(H1)\" data-toc-modified-id=\"Часовые-графики-(H1)-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Часовые графики (H1)</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Выводы</a></span></li></ul></li><li><span><a href=\"#Создание-признаков\" data-toc-modified-id=\"Создание-признаков-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Создание признаков</a></span><ul class=\"toc-item\"><li><span><a href=\"#Создание-признаков-на-основе-часовых,-4-часовых-и-дневных-данных\" data-toc-modified-id=\"Создание-признаков-на-основе-часовых,-4-часовых-и-дневных-данных-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Создание признаков на основе часовых, 4-часовых и дневных данных</a></span></li><li><span><a href=\"#Формирование-единого-датасета\" data-toc-modified-id=\"Формирование-единого-датасета-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Формирование единого датасета</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Выводы</a></span></li></ul></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#Формирование-обучающей-и-тестовой-выборок\" data-toc-modified-id=\"Формирование-обучающей-и-тестовой-выборок-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Формирование обучающей и тестовой выборок</a></span><ul class=\"toc-item\"><li><span><a href=\"#Определение-метрики-и-функций-вывода-результатов\" data-toc-modified-id=\"Определение-метрики-и-функций-вывода-результатов-4.1.1\"><span class=\"toc-item-num\">4.1.1&nbsp;&nbsp;</span>Определение метрики и функций вывода результатов</a></span></li></ul></li><li><span><a href=\"#Dummy-модель\" data-toc-modified-id=\"Dummy-модель-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Dummy-модель</a></span></li><li><span><a href=\"#Линейная-регрессия\" data-toc-modified-id=\"Линейная-регрессия-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Линейная регрессия</a></span></li><li><span><a href=\"#Случайный-лес\" data-toc-modified-id=\"Случайный-лес-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Случайный лес</a></span></li><li><span><a href=\"#CatBoost\" data-toc-modified-id=\"CatBoost-4.5\"><span class=\"toc-item-num\">4.5&nbsp;&nbsp;</span>CatBoost</a></span></li><li><span><a href=\"#LightGBM\" data-toc-modified-id=\"LightGBM-4.6\"><span class=\"toc-item-num\">4.6&nbsp;&nbsp;</span>LightGBM</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-4.7\"><span class=\"toc-item-num\">4.7&nbsp;&nbsp;</span>Выводы</a></span></li></ul></li><li><span><a href=\"#Анализ-моделей\" data-toc-modified-id=\"Анализ-моделей-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Анализ моделей</a></span><ul class=\"toc-item\"><li><span><a href=\"#Оценка-значимости-обучающих-признаков\" data-toc-modified-id=\"Оценка-значимости-обучающих-признаков-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Оценка значимости обучающих признаков</a></span></li><li><span><a href=\"#Остатки\" data-toc-modified-id=\"Остатки-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Остатки</a></span></li></ul></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Выводы</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Прогнозирование заказов такси"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Компания «Чётенькое такси» собрала исторические данные о заказах такси в аэропортах. Чтобы привлекать больше водителей в период пиковой нагрузки, нужно спрогнозировать количество заказов такси на следующий час. \n",
    "\n",
    "Цель - построение модели предсказания количества заказов на следующий час со значением метрики *RMSE* на тестовой выборке не больше 48.\n",
    "\n",
    "Задачи:\n",
    "1. Загрузить данные и выполнить их ресемплирование по одному часу.\n",
    "2. Проанализировать данные.\n",
    "3. Обучить разные модели с различными гиперпараметрами. Сделать тестовую выборку размером 10% от исходных данных.\n",
    "4. Проверить данные на тестовой выборке и сделать выводы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка и подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime\n",
    "\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#sns.set_theme(style=\"darkgrid\")\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from catboost import Pool, CatBoostRegressor\n",
    "\n",
    "# метрики\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler, RobustScaler, OrdinalEncoder\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_magic = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных\n",
    "\n",
    "Выполним загрузку данных и предварительную оценку данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_taxi = pd.read_csv('datasets/taxi.csv', parse_dates=['datetime'])\n",
    "df_taxi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исходные данные представлены в виде одной таблицы с двумя признаками: \n",
    "- дата и время\n",
    "- количество заказов\n",
    "\n",
    "В таблице содержится порядка 26.5 тысяч записей с данными о количестве заказов такси (в 10-минутном интервале). По условиям задачи моделирования требуется спрогнозировать количество заказов такси на следующий час. Соответственно целесообразно провести ресемплирование данных по одному часу.\n",
    "\n",
    "Проверим исходные данные на наличие дубликатов перед проведением ресемплирования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_taxi.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дубликаты отсутствуют. Укажем в качестве индекса таблицы - признак времени."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_taxi = df_taxi.set_index('datetime')\n",
    "df_taxi.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сортировка и семплирование\n",
    "\n",
    "Выполним сортировку значений по индексу по возрастанию. Проверим монотонность значений индекса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_taxi.sort_index(ascending=True, inplace=True)\n",
    "df_taxi.index.is_monotonic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_taxi.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В таблице данные представлены за период с 01 марта 2018 года по 31 августа 2018 года (6 месяцев).\n",
    "\n",
    "Поскольку задача предсказания на час вперед выполняем ресемплирование по часу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_taxi = df_taxi.resample('1H').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделим трейн и тест в соответствии с исходными требованиями - объем теста 10%. Разделение будем производить без перемешивания (тестовые данные - в конце рассматриваемого периода)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df_taxi, shuffle=False, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные разделены на обучающую и тестовую выборку, границей разделения является '2018-08-13 14:00:00' (монотонное разделение). Всего из исходных 26.5 тысяч записей после ресемплирования осталось порядка 4.5 тысяч записей.\n",
    "\n",
    "Целесообразно сдвинуть границу разделения к границе дня для последующей оценки дневной динамики данных. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(df):\n",
    "    df_train = df[:'2018-08-13 23:00:00']\n",
    "    df_test = df['2018-08-14 00:00:00':]  \n",
    "    \n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = split_train_test(df_taxi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы\n",
    "\n",
    "Исходные данные представлены в виде одной таблицы с двумя признаками: \n",
    "- дата и время\n",
    "- количество заказов\n",
    "\n",
    "В таблице содержится порядка 26.5 тысяч записей с данными о количестве заказов такси (в 10-минутном интервале). В таблице данные представлены за период с 01 марта 2018 года по 31 августа 2018 года (6 месяцев). Границей разделения на обучающую и тестовую выборку является 14 августа 2018 года.\n",
    "\n",
    "Дубликатов данных нет.\n",
    "\n",
    "Перейдем к этапу анализа обучающей выборки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Анализ обучающей выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выявление трендов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем общую оценку данных обучающей выборки. Визуализируем на графике данные по количеству заказов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_orders(df, num_range=None, tickformat='%b\\n%Y'):\n",
    "    fig = go.Figure(\n",
    "        [go.Scatter(x=df.index, y=df['num_orders'])]\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        xaxis=dict(\n",
    "            tickangle=-45,\n",
    "            title='Дата',\n",
    "            tickformat=tickformat\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            range=num_range,\n",
    "            title='Количество заказов',\n",
    "        ),\n",
    "\n",
    "\n",
    "        autosize=False,\n",
    "        width=950,\n",
    "        height=700\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_orders(df_train, [0, 300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На графике виден некоторый тренд на увеличение числа заказов ближе к концу рассматриваемого периода.\n",
    "\n",
    "Проведем более подробный анализ обучающей выборки. Проведем дополнительное семплирование данных - по дням и 4-часовым промежуткам - и выявление трендов и сезонности в полученных данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дневные графики (D1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_taxi_D1 = df_train.resample('1D').sum()\n",
    "df_taxi_D1['day'] = df_taxi_D1.index.day\n",
    "df_taxi_D1['dayofweek'] = df_taxi_D1.index.dayofweek\n",
    "\n",
    "plot_orders(df_taxi_D1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На дневном графике наличие восходящего тренда является более очевидным. Оценим наличие трендов и сезонности средствами библиотеки `statsmodels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposed_D1 = seasonal_decompose(df_taxi_D1['num_orders'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 16))\n",
    "plt.subplot(311)\n",
    "\n",
    "decomposed_D1.trend.plot(ax=plt.gca())\n",
    "plt.title('Тренд')\n",
    "plt.subplot(312)\n",
    "decomposed_D1.seasonal.plot(ax=plt.gca())\n",
    "plt.title('Сезонность')\n",
    "plt.subplot(313)\n",
    "decomposed_D1.resid.plot(ax=plt.gca())\n",
    "plt.title('Шумы')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На дневных графиках можно четко выделить растущий тренд, а также недельные периоды сезонности. Рассмотрим несколько таких периодов подробнее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_orders(\n",
    "    pd.DataFrame(decomposed_D1.seasonal['2018-06-01':'2018-07-01']).rename(columns={\"seasonal\": \"num_orders\"}), \n",
    "    None, '%d-%b, %a'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На графике видно ярко выраженные сезонные периоды продолжительностью 7 дней с минимальными значениями в воскресенье и вторник и пиками в понедельник и пятницу.\n",
    "\n",
    "Выявленные закономерности позволяют сделать предположений о возможных значимых признаках для модели:\n",
    "- дневной объем заказов с лагом в 7 дней (неделю назад)\n",
    "- дневной объем заказов в предыдущий день\n",
    "- скользящая средняя по кратным неделям периодам (например 1 и 4 недели) - со сдвигом в 1 день (для исключения утечек данных)\n",
    "\n",
    "Указанные признаки будут добавлены к исходному датасету непосредственно перед обучением модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-часовые графики (H4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также рассмотрим 4-часовые графики, построенные на исходной обучающей выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_taxi_H4 = df_train.resample('4H').sum()\n",
    "df_taxi_H4['day'] = df_taxi_H4.index.day\n",
    "df_taxi_H4['dayofweek'] = df_taxi_H4.index.dayofweek\n",
    "\n",
    "plot_orders(df_taxi_H4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposed_H4 = seasonal_decompose(df_taxi_H4['num_orders'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 16))\n",
    "plt.subplot(311)\n",
    "\n",
    "decomposed_H4.trend.plot(ax=plt.gca())\n",
    "plt.title('Тренд')\n",
    "plt.subplot(312)\n",
    "decomposed_H4.seasonal.plot(ax=plt.gca())\n",
    "plt.title('Сезонность')\n",
    "plt.subplot(313)\n",
    "decomposed_H4.resid.plot(ax=plt.gca())\n",
    "plt.title('Шумы')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_orders(\n",
    "    pd.DataFrame(decomposed_H4.seasonal['2018-06-01':'2018-06-07']).rename(columns={\"seasonal\": \"num_orders\"}),\n",
    "    None, '%H:%M, %d-%b, %a'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очевидным образом 4-часовые графики имеют ярко выраженную суточную сезонность. \n",
    "\n",
    "Целесообразно рассмотреть следующие возможные признаки для модели:\n",
    "- 4-часовой объем заказов с лагом в 6 периодов (сутки назад)\n",
    "- 4-часовой объем заказов в предыдущий период\n",
    "- скользящая средняя по кратным дням периоду (например 4 дня - 24 периода) - со сдвигом в 1 период - 4 часа (для исключения утечек данных)\n",
    "\n",
    "Указанные признаки будут добавлены к исходному датасету непосредственно перед обучением модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Часовые графики (H1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Соответственно на часовых графиках также выделим сезонность и тренд и подробнее рассмотрим график сезонной компоненты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposed_H1 = seasonal_decompose(df_train['num_orders'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_orders(\n",
    "    pd.DataFrame(decomposed_H1.seasonal['2018-06-01':'2018-06-03']).rename(columns={\"seasonal\": \"num_orders\"}),\n",
    "    None, '%H:%M, %d-%b, %a'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Часовые сезонные циклы также достаточно хорошо выделены:\n",
    "- сутки начинаются с пикового значения объема заказов в 0 часов\n",
    "- далее следует резкое падение до минимума в районе 6 часов утра\n",
    "- рост объема заказов с 7 часов и боковой тренд в рабочие часы (с 8 до 18)\n",
    "- плавный рост до пикового значения с 18 до 0 часов\n",
    "\n",
    "Целесообразно рассмотреть следующие возможные признаки для модели:\n",
    "- часовой объем заказов с лагом в 24 часа \n",
    "- часовой объем заказов 1, 2 и 3 часа назад\n",
    "- скользящая средняя по 12 и 4 часам - со сдвигом в 1 час (для исключения утечек данных)\n",
    "\n",
    "Указанные признаки будут добавлены к исходному датасету непосредственно перед обучением модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы\n",
    "\n",
    "Результаты семплирования и анализа дневных, 4-часовых и часовых графиков позволяют выявить следующие закономерности:\n",
    "- общий тренд рассматриваемых данных - восходящий\n",
    "- данные обладают выраженной недельной и суточной сезонностью (поскольку данные представлены только за 6 месяцев говорить о выявлении более крупных сезонных зависимостях не представляется возможным)\n",
    "\n",
    "Эти закономерности позволяют сделать предположение о возможных обучающих признаках - различных комбинациях исторических значений (предыдущих периодов со сдвигом) и скользящих средних переменных размеров окна. При этом необходимо соблюдать требование по сдвигу значений скользящих средних для избежания утечек данных на тестовой выборке.\n",
    "\n",
    "Переходим к проектированию обучающих признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создание признаков на основе часовых, 4-часовых и дневных данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Снова рассмотрим весь исходный набор данных, семплированный по часам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_taxi.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сформируем семплированные по дням и 4-часовым отрезкам наборы данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_taxi_D1 = df_taxi.resample('1D').sum()\n",
    "df_taxi_H4 = df_taxi.resample('4H').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим признаки - компоненты даты - которые будут в последующем использоваться для объединения часовых данных с данными по дням и 4-часовым интервалам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_date_features(df):\n",
    "    df['dayofweek'] = df.index.dayofweek\n",
    "    df['month'] = df.index.month\n",
    "    df['day'] = df.index.day\n",
    "    df['hour'] = df.index.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_date_features(df_taxi)\n",
    "make_date_features(df_taxi_D1)\n",
    "make_date_features(df_taxi_H4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее выполним генерацию признаков для каждого из рассматриваемого периода (часовой, 4-часовой, дневной), руководствуясь следующими принципами:\n",
    "- в каждом масштабе сохраняем ближайшие предыдущие значения и значения прошлого аналогичного периода (например, для недельного цикла это будут значения - 1, 2 дня назад и 7 дней назад (предыдущий аналог)\n",
    "- скользящие средние комбинируем по окнам разной ширины (при этом для более коротких скользящих средних выбираем способ построения, учитывающий последния значения с бОльшим весом относительно более старых)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сформируем признаки на основе данных по дням (для удобства восприятия усредним их к значению за 1 час)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lag in (1, 2, 7):\n",
    "    df_taxi_D1['D1_lag_{}'.format(lag)] = df_taxi_D1['num_orders'].shift(lag) / 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_taxi_D1['D1_rolling_mean_3'] = df_taxi_D1['num_orders'].shift(1).rolling(3, win_type='hann').mean() / 24\n",
    "df_taxi_D1['D1_rolling_mean_7'] = df_taxi_D1['num_orders'].shift(1).rolling(7).mean() / 24\n",
    "df_taxi_D1['D1_rolling_mean_14'] = df_taxi_D1['num_orders'].shift(1).rolling(14).mean() / 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сформируем признаки на основе 4-часовых данным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lag in (1, 2, 3, 6):\n",
    "    df_taxi_H4['H4_lag_{}'.format(lag)] = df_taxi_H4['num_orders'].shift(lag) / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_taxi_H4['H4_rolling_mean_3'] = df_taxi_H4['num_orders'].shift(1).rolling(3, win_type='hann').mean() / 4\n",
    "df_taxi_H4['H4_rolling_mean_6'] = df_taxi_H4['num_orders'].shift(1).rolling(6, win_type='hann').mean() / 4\n",
    "df_taxi_H4['H4_rolling_mean_24'] = df_taxi_H4['num_orders'].shift(1).rolling(24).mean() / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_taxi_H4.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для последующего объединения с часовыми данными \"размножим\" строчки набора данных, заполнив все интервальные значения часов (т.е. например строчка со значением часов = 0 дублируется 4 раза, значения часов заполняются в интервале от 0 до 3 с шагом 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_taxi_H4 = df_taxi_H4.loc[df_taxi_H4.index.repeat(4)]\n",
    "df_taxi_H4['hour'] += df_taxi_H4.groupby(level=0).cumcount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_taxi_H4.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сформируем признаки на основе часовых данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lag in (1, 2, 3, 24, 48, 72):\n",
    "    df_taxi['H1_lag_{}'.format(lag)] = df_taxi['num_orders'].shift(lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_taxi['H1_rolling_mean_6'] = df_taxi['num_orders'].shift(1).rolling(6).mean()\n",
    "df_taxi['H1_rolling_mean_12'] = df_taxi['num_orders'].shift(1).rolling(12).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Формирование единого датасета"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объединим в одной таблице исходные часовые данные и подготовленную статистику по более крупным периодам - неделям и 4-часовым интервалам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# объединяем с дневными данными\n",
    "df_merged = df_taxi.reset_index().merge(\n",
    "    df_taxi_D1, on=['month', 'day'], how='inner'\n",
    ")\n",
    "\n",
    "df_merged.drop([col for col in df_merged.columns if \"_y\" in col], axis=1, inplace=True)\n",
    "df_merged = df_merged.rename(columns=lambda x: x.replace('_x', ''))\n",
    "\n",
    "# объединяем с 4-часовыми данными\n",
    "df_merged = df_merged.merge(\n",
    "    df_taxi_H4, on=['month', 'day', 'hour'], how='inner'\n",
    ")\n",
    "\n",
    "df_merged.drop([col for col in df_merged.columns if \"_y\" in col], axis=1, inplace=True)\n",
    "df_merged = df_merged.rename(columns=lambda x: x.replace('_x', ''))\n",
    "\n",
    "\n",
    "df_merged = df_merged.dropna()\n",
    "df_merged.set_index('datetime', inplace=True)\n",
    "df_merged.drop(columns=['month', 'day'], inplace=True)\n",
    "df_merged.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы\n",
    "\n",
    "Датасет сформирован, в нем собраны и приведены к единой масштабной шкале данные как по часовым интервалам (предыдущие значения, скользящие средние), так и данные более крупных интервалов (4-часовые, дни).\n",
    "\n",
    "Переходим непосредственно к обучению моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Формирование обучающей и тестовой выборок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = split_train_test(df_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Доля тестовой выборки относительно обучающей: {0:.1%}'.format(df_test.shape[0] / df_train.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим обучающие и целевой признаки. Также выделим категориальные признаки - день недели и час."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = ['num_orders']\n",
    "\n",
    "features = [col for col in list(df_merged.columns) if col not in target]\n",
    "\n",
    "# категориальные признаки - день недели и час\n",
    "features_category = ['dayofweek', 'hour']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train[features]\n",
    "Y_train = df_train[target]\n",
    "\n",
    "X_test = df_test[features]\n",
    "Y_test = df_test[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Определение метрики и функций вывода результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция расчета метрики RMSE\n",
    "\n",
    "def rmse(Y_true, Y_predicted):\n",
    "    return mean_squared_error(Y_true, Y_predicted) ** 0.5\n",
    "    \n",
    "# в версии 0.24.1:    \n",
    "#    return mean_squared_error(Y_true, Y_predicted, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# мера, используемая при кросс-валидации - RMSE\n",
    "scoring = make_scorer(rmse, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция печати сводной информации о параметрах модели\n",
    "def print_scores(grid_search, params):\n",
    "    print ('Наилучшее значение метрики RMSE: %0.3f' % np.abs(grid_search.best_score_))\n",
    "    print ('Наилучшие параметры:')\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    \n",
    "    for param_name in sorted(params.keys()):\n",
    "        print ('\\t%s: %r' % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_scores_on_test(grid_search, params, X_test, Y_test):\n",
    "    print ('Параметры модели:')\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    grid_parameters = {}\n",
    "    \n",
    "    for param_name in sorted(params.keys()):\n",
    "        grid_parameters[param_name] = best_parameters[param_name]\n",
    "        print ('\\t%s: %r' % (param_name, best_parameters[param_name]))\n",
    "    \n",
    "    score_value = np.abs(grid_search.score(X_test, Y_test))\n",
    "    print('Значение метрики RMSE на тестовых данных:', score_value)\n",
    "    \n",
    "    return score_value, grid_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_param_count(params):\n",
    "    return np.prod([len(value) for key, value in params.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция печати графика значимости обучающих признаков\n",
    "def print_feature_importance(arr_importance, column_names):\n",
    "    rel_feature_imp = np.abs(100 * (arr_importance / max(arr_importance)))\n",
    "    \n",
    "    rel_feature_df = pd.DataFrame(\n",
    "        {\n",
    "            'features' : list(column_names),\n",
    "            'rel_importance' : rel_feature_imp\n",
    "        }\n",
    "    )\n",
    "\n",
    "    rel_feature_df = rel_feature_df.sort_values('rel_importance', ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.yticks(fontsize=15)\n",
    "\n",
    "    ax = sns.barplot(\n",
    "        x = 'rel_importance', \n",
    "        y = 'features',\n",
    "        data = rel_feature_df,\n",
    "        palette = 'Accent_r'\n",
    "    )\n",
    "\n",
    "    plt.xlabel('Относительная значимость', fontsize=25)\n",
    "    plt.ylabel('Признаки', fontsize=25)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# способ кросс-валидации, учитывающий временнЫе характеристики набора данных\n",
    "tscv = TimeSeriesSplit(n_splits=8)\n",
    "\n",
    "# словарь значений важности признаков наилучшей модели в каждом классе\n",
    "feature_imp = {}\n",
    "\n",
    "# массив параметров наилучших моделей в каждом классе\n",
    "ml_data = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy-модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве отправной точки рассмотрим модель, предсказывающую значение заказов следующего часа равное предыдущему."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = Y_test.shift()\n",
    "predictions.iloc[0] = Y_train.iloc[Y_train.shape[0]-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MAE:\", rmse(Y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data.append(['dummy', 0, 0, 59.15, {}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значение метрики dummy-модели равно ~59 (заказам). Базовое значение ошибки для построения моделей машинного обучения получено."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Линейная регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_steps = [\n",
    "    (\n",
    "        'qtl', ColumnTransformer(\n",
    "            remainder='passthrough',\n",
    "            transformers=[  \n",
    "                ('std', StandardScaler(copy=False, with_mean=True, with_std=True), features),\n",
    "            ])\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = LinearRegression()\n",
    "\n",
    "params = {\n",
    "    'model__fit_intercept': [True, False],\n",
    "    'model__normalize': [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(\n",
    "        Pipeline(transform_steps + [('model', model_lr)]), \n",
    "        param_grid=params, \n",
    "        cv=tscv, \n",
    "        scoring=scoring,\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "grid_search.fit(X_train, Y_train.values.ravel())\n",
    "\n",
    "learning_time = (datetime.datetime.now()-start_time).seconds\n",
    "\n",
    "print_scores(grid_search, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_score, grid_parameters = print_scores_on_test(grid_search, params, X_test, Y_test.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data.append(['Линейная регрессия', learning_time, learning_time / get_param_count(params), rmse_score, grid_parameters])\n",
    "feature_imp['Линейная регрессия'] = [grid_search.best_estimator_.get_params()['model'].coef_, features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью линейной регрессии удалось достичь значения метрики RMSE = ~42, что практически в 1.5 раза лучше, чем dummy-модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Случайный лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rfr = RandomForestRegressor(random_state=random_magic)\n",
    "\n",
    "params = {\n",
    "    'model__n_estimators': [10, 20, 30, 40],\n",
    "    'model__max_depth': [2, 3, 5, 7],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(\n",
    "        Pipeline(transform_steps + [('model', model_rfr)]), \n",
    "        param_grid=params, \n",
    "        cv=tscv, \n",
    "        scoring=scoring,\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "grid_search.fit(X_train, Y_train.values.ravel())\n",
    "\n",
    "learning_time = (datetime.datetime.now()-start_time).seconds\n",
    "\n",
    "print_scores(grid_search, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_score, grid_parameters = print_scores_on_test(grid_search, params, X_test, Y_test.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data.append(['Случайный лес', learning_time, learning_time / get_param_count(params), rmse_score, grid_parameters])\n",
    "feature_imp['Случайный лес'] = [grid_search.best_estimator_.get_params()['model'].feature_importances_, features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель случайного леса позволила получить значения метрики RMSE = ~42, что совпадает с результатами линейной регрессии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для модели градиентного бустинга CatBoostRegressor создадим дополнительный признак типа `timestamp`, который должен быть воспринят моделью в качестве временнОго признака (при заданном ключе `has_time=True`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cb = df_train.append(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cb['datetime'] = df_cb.index\n",
    "df_cb['timestamp'] = df_cb[['datetime']].apply(lambda x: x[0].timestamp(), axis=1).astype(int)\n",
    "df_cb.drop(columns=['datetime'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_cb = features + ['timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cb.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_cb = df_cb.loc[df_train.index]\n",
    "df_test_cb = df_cb.loc[df_test.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train_cb[features_cb]\n",
    "Y_train = df_train_cb[target]\n",
    "\n",
    "X_test = df_test_cb[features_cb]\n",
    "Y_test = df_test_cb[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RmseMetric(object):\n",
    "    def get_final_error(self, error, weight):\n",
    "        return np.sqrt(error / (weight + 1e-38))\n",
    "\n",
    "    def is_max_optimal(self):\n",
    "        return False\n",
    "\n",
    "    def evaluate(self, approxes, target, weight):\n",
    "        assert len(approxes) == 1\n",
    "        assert len(target) == len(approxes[0])\n",
    "\n",
    "        approx = approxes[0]\n",
    "\n",
    "        error_sum = 0.0\n",
    "        weight_sum = 0.0\n",
    "\n",
    "        for i in range(len(approx)):\n",
    "            w = 1.0 if weight is None else weight[i]\n",
    "            weight_sum += w\n",
    "            error_sum += w * ((approx[i] - target[i])**2)\n",
    "\n",
    "        return error_sum, weight_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cbr = CatBoostRegressor(\n",
    "    verbose=50,\n",
    "    #eval_metric='RMSE',\n",
    "    eval_metric=RmseMetric(),\n",
    "    cat_features=features_category,\n",
    "    task_type=\"CPU\",\n",
    "    has_time=True,\n",
    "    iterations=1000,  \n",
    ")\n",
    "\n",
    "params = {\n",
    "    'learning_rate': [0.03, 0.05, 0.15],\n",
    "    'depth': [5, 7, 10],\n",
    "}\n",
    "\n",
    "#\n",
    "#    params = {\n",
    "#        'learning_rate': [0.15],\n",
    "#        'depth': [7],\n",
    "#    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#start_time = datetime.datetime.now()\n",
    "\n",
    "#grid_search = model_cbr.grid_search(\n",
    "#        params,\n",
    "#        cv=tscv,\n",
    "#        X=X_train, \n",
    "#        y=Y_train, \n",
    "#        plot=True\n",
    "#    )\n",
    "\n",
    "#learning_time = (datetime.datetime.now()-start_time).seconds\n",
    "\n",
    "#print_scores(grid_search, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#обучение без перебора гиперпараметров\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "model_cbr.fit(\n",
    "    X_train, Y_train,\n",
    "    plot=True\n",
    ")\n",
    "\n",
    "learning_time = (datetime.datetime.now()-start_time).seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_score = rmse(Y_test.values.ravel(), model_cbr.predict(X_test))\n",
    "\n",
    "print('Значение метрики RMSE на тестовых данных:', rmse_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data.append(['CatBoost', learning_time, learning_time, rmse_score, {}])\n",
    "\n",
    "df_importance = model_cbr.get_feature_importance(prettified=True)\n",
    "\n",
    "feature_imp['CatBoost'] = [df_importance['Importances'], df_importance['Feature Id']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель CatBoostRegressor библиотеки CatBoost позволила получить значение метрики RMSE на тестовых данных ~ 38.4, что лучше рассмотренных выше моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для модели градиентного бустинга LightGBM категориальные признаки (час, день недели) переведем в тип `category`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lgbm = df_train.append(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in features_category:\n",
    "    df_lgbm[col] = df_lgbm[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_lgbm = df_lgbm.loc[df_train.index]\n",
    "df_test_lgbm = df_lgbm.loc[df_test.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train_lgbm[features]\n",
    "Y_train = df_train_lgbm[target]\n",
    "\n",
    "X_test = df_test_lgbm[features]\n",
    "Y_test = df_test_lgbm[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgbm = lgb.LGBMRegressor(\n",
    "    random_state=random_magic,\n",
    "    device=\"cpu\"\n",
    ")\n",
    "\n",
    "params = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.03, 0.05, 0.15],\n",
    "}\n",
    "\n",
    "# наилучшие параметры\n",
    "params = {\n",
    "    'max_depth': [5],\n",
    "    'learning_rate': [0.05],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# примерное время выполнения - 23 минуты\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "        estimator=model_lgbm,\n",
    "        param_grid=params, \n",
    "        cv=tscv, \n",
    "        scoring=scoring,\n",
    "        n_jobs=-1, \n",
    "        verbose=5\n",
    "    )\n",
    "fitted_model = grid_search.fit(X_train, Y_train)\n",
    "\n",
    "learning_time = (datetime.datetime.now()-start_time).seconds\n",
    "\n",
    "print_scores(grid_search, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_score, grid_parameters = print_scores_on_test(grid_search, params, X_test, Y_test.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data.append(['LightGBM', learning_time, learning_time / get_param_count(params), rmse_score, grid_parameters])\n",
    "feature_imp['LightGBM'] = [grid_search.best_estimator_.feature_importances_, features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель LGBMRegressor библиотеки LightGBM позволила получить значение метрики RMSE на тестовых данных ~ 38.3, что немного лучше CatBoostRegressor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы\n",
    "\n",
    "Проведено обучение 4 различных видов моделей машинного обучения:\n",
    "- линейная регрессия\n",
    "- случайный лес\n",
    "- CatBoostRegressor\n",
    "- LGBMRegressor\n",
    "\n",
    "Все модели улучшили значение метрики RMSE dummy-модели более чем в 1.5 раза. При этом модели градиентного бустинга показали наилучшее значение метрики ~38.3, что на 10% лучше результатов линейной регрессии и случайного леса. \n",
    "\n",
    "Рассмотрим подробнее полученные результаты обучения моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Анализ моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оценка значимости обучающих признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отобразим в табличном виде полученные значения метрики RMSE рассмотренных моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml_compare = pd.DataFrame(ml_data, columns=['model', 'learning_time', 'learning_time_per_param', 'rmse', 'params'])\n",
    "df_ml_compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью модели LightGBM получено наилучшее значение метрики RMSE. При этом время обучения LightGBM намного меньше чем у CatBoost.\n",
    "\n",
    "В целом следует отметить, что качество линейной регрессии и случайного леса также вполне удовлетворительны - в 1.5 раза лучше dummy-модели и на 10% хуже градиентного бустинга."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем графики относительной значимости обучающих признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for key, value in feature_imp.items():\n",
    "    print(key)\n",
    "    print_feature_importance(value[0], value[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следует отметить, что состав наиболее значимых признаков по всем моделям практически совпадает:\n",
    "- текущий час\n",
    "- значения 24, 48 и 72-часовых сдвигов \n",
    "\n",
    "При этом в линейной регрессии наибольшей значимостью обладает скользящая средняя 4-часовых периодов, рассчитываемая по 24-периодному окну (4 дня).\n",
    "\n",
    "Наиболее сбалансированная веса обучающих признаков в модели LightGBM.\n",
    "\n",
    "Также следует отметить важность во многих моделях признака числа заказов неделю назад (D1_lag_7), что снова подтверждает наличие ярко выраженной недельной цикличности.\n",
    "\n",
    "В целом следует отметить, что указанное сочетание признаков, содержащее как значения сдвигов (разных интервалов на разных масштабах), так и значения скользящих средних (по разным окнам) позволило достичь и существенно превзойти целевое значение метрики RMSE всеми рассмотренными моделями."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Остатки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим остатки с тем, чтобы определить, какие ситуации модель предсказывает хуже всего."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff = Y_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff['pred'] = grid_search.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff['diff'] = df_diff['pred'] - df_diff['num_orders']\n",
    "df_diff['dayofweek'] = df_diff.index.dayofweek\n",
    "df_diff['hour'] = df_diff.index.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff_merged = pd.concat([df_diff[df_diff['diff']>=0]['diff'], df_diff[df_diff['diff']<0]['diff']], axis=1)\n",
    "df_diff_merged.columns=['pos', 'neg']\n",
    "df_diff_merged.fillna(0, inplace=True)\n",
    "df_diff_merged.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сформируем общую таблицу с разностью между предсказанным и фактическим значением, а также признаками положительных и отрицательных ошибок по отдельности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff['pos'] = df_diff_merged['pos']\n",
    "df_diff['neg'] = df_diff_merged['neg']\n",
    "df_diff['absv'] = np.abs(df_diff['diff'])\n",
    "df_diff.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сформируем сводную таблицу ошибок по часам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_err_hour = df_diff.pivot_table(\n",
    "    index='hour', \n",
    "    values=['pos', 'neg', 'diff'], \n",
    "    aggfunc=['sum']\n",
    ").reset_index()\n",
    "\n",
    "df_err_hour.columns=['hour', 'absv', 'neg', 'pos']\n",
    "df_err_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наиболее количество ошибок - в ночные часы (с 1 до 4), когда вероятно на предсказание оказывает большое значение восходящий тренд предыдущего дня (увеличение числа заказов с 18 до 0 часов). Т.е. модель плохо улавливает завершение восходящего вечернего тренда и его смену на ночной период с малым числом заказов. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сформируем сводную таблицу ошибок по неделям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_err_dow = df_diff.pivot_table(\n",
    "    index='dayofweek', \n",
    "    values=['pos', 'neg', 'diff'], \n",
    "    aggfunc=['sum']\n",
    ").reset_index()\n",
    "\n",
    "df_err_dow.columns=['dow', 'absv', 'neg', 'pos']\n",
    "df_err_dow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим график ошибок по дням недели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Violin(x=df_diff['dayofweek'][ df_diff['pos'] > 0 ],\n",
    "                        y=df_diff['pos'][ df_diff['pos'] > 0 ],\n",
    "                        legendgroup='Pos', scalegroup='Pos', name='Ошибка +',\n",
    "                        line_color='green')\n",
    "             )\n",
    "fig.add_trace(go.Violin(x=df_diff['dayofweek'][ df_diff['neg'] < 0 ],\n",
    "                        y=df_diff['neg'][ df_diff['neg'] < 0 ],\n",
    "                        legendgroup='Neg', scalegroup='Neg', name='Ошибка -',\n",
    "                        line_color='red')\n",
    "             )\n",
    "\n",
    "fig.update_traces(box_visible=True, meanline_visible=True)\n",
    "fig.update_layout(violinmode='group')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На графике видно, что в понедельник (день с номером 0) наибольшее количество ошибок со знаком `-`, т.е. когда модель предсказывает меньшее количество заказов, чем было фактически. Вероятно это связано с тем, что за выходные (когда количество заказов меньше чем в будни) значения предыдущих периодов оказывают большее значение - фактически модель плохо улавливает смену нисходящего тренда выходных дней на восходящий тренд в будни."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим симметричность остатков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff['diff'].hist(bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Гистограмма остатков в целом симметрична относительно 0. Но при этом есть зона \"выбросов\" в значениях менее 100 - видимо это соответствует плохим предсказаниям в периоды после фаз падения (когда модель предсказывает меньшее число заказов, чем фактически - например после ночных часов)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff_plt = df_diff.query('absv < 150')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=df_diff_plt['pred'], y=df_diff_plt['diff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff_plt = df_diff['2018-08-15':'2018-08-17'][['num_orders', 'pred']]\n",
    "\n",
    "#plt.figure(figsize=(15,8))\n",
    "#df_diff_plt.plot(ax=plt.gca())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "    \n",
    "fig.add_trace(\n",
    "        go.Scatter(x=df_diff_plt.index, y=df_diff_plt['num_orders'], name='факт')\n",
    "    )\n",
    "\n",
    "fig.add_trace(\n",
    "        go.Scatter(x=df_diff_plt.index, y=df_diff_plt['pred'], name='предсказания')\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "        xaxis=dict(\n",
    "            tickangle=-45,\n",
    "            title='Дата',\n",
    "            tickformat='%H:%M, %d-%b, %a'\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            #range=num_range,\n",
    "            title='Количество заказов',\n",
    "        ),\n",
    "\n",
    "\n",
    "        autosize=False,\n",
    "        width=950,\n",
    "        height=700\n",
    "    )\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По графику предсказаний видны \"плохие\" места модели: модель плохо предсказывает значение после резких колебаний/падений, например, в интервале 13-15 часов (16 августа) - в этот период падения числа заказов оказалось, видимо, больше чем обучно и модель не смогла на это правильно среагировать.\n",
    "\n",
    "Но наверно для подробной интерпретации действительно необходимо привлекать бизнес - выяснять, с чем могли быть связаны аномальные зоны (например, невыход водителей/ремонт автопарка, технические сбои в системе клиент-водитель и т.д.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем немного улучшить качество предсказания, введя дополнительные обучающие признаки - для группы ночных часов (1 -4 часа ночи) и понедельника."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lgbm = df_train.append(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lgbm['is_night'] = np.where((df_lgbm['hour'] >= 1) & (df_lgbm['hour'] <= 4), 1, 0)\n",
    "df_lgbm['is_mnd'] = np.where(df_lgbm['dayofweek'] == 0, 1, 0)\n",
    "df_lgbm.drop(columns=['D1_rolling_mean_3', 'H4_rolling_mean_3'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lgbm.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [col for col in list(df_lgbm.columns) if col not in target]\n",
    "\n",
    "features_category = ['dayofweek', 'hour', 'is_night', 'is_mnd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in features_category:\n",
    "    df_lgbm[col] = df_lgbm[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_lgbm = df_lgbm.loc[df_train.index]\n",
    "df_test_lgbm = df_lgbm.loc[df_test.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train_lgbm[features]\n",
    "Y_train = df_train_lgbm[target]\n",
    "\n",
    "X_test = df_test_lgbm[features]\n",
    "Y_test = df_test_lgbm[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgbm = lgb.LGBMRegressor(\n",
    "    random_state=random_magic,\n",
    "    device=\"cpu\"\n",
    ")\n",
    "\n",
    "# наилучшие параметры\n",
    "params = {\n",
    "    'max_depth': [5],\n",
    "    'learning_rate': [0.05],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# примерное время выполнения - 23 минуты\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "        estimator=model_lgbm,\n",
    "        param_grid=params, \n",
    "        cv=tscv, \n",
    "        scoring=scoring,\n",
    "        n_jobs=-1, \n",
    "        verbose=5\n",
    "    )\n",
    "fitted_model = grid_search.fit(X_train, Y_train)\n",
    "\n",
    "learning_time = (datetime.datetime.now()-start_time).seconds\n",
    "\n",
    "print_scores(grid_search, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_score, grid_parameters = print_scores_on_test(grid_search, params, X_test, Y_test.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_feature_importance(grid_search.best_estimator_.feature_importances_, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значение метрики RMSE удалось немного улучшить. Добавленные признаки пусть и незначительно, но влияют на качество модели (их вес относительно других признаков - ненулевой)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В рамках исследования проведено построение моделей машинного обучения с целью предсказания количества заказов такси на следующий час на основе исторических данных (за полгода). \n",
    "\n",
    "Исходные данные представлены в виде одной таблицы с двумя признаками:\n",
    "- дата и время\n",
    "- количество заказов\n",
    "В таблице содержится порядка 26.5 тысяч записей с данными о количестве заказов такси (в 10-минутном интервале). В таблице данные представлены за период с 01 марта 2018 года по 31 августа 2018 года (6 месяцев). Границей разделения на обучающую и тестовую выборку является 14 августа 2018 года.\n",
    "\n",
    "В рамках анализа обучающей выборки проведено дополнительное семплирование данных - по дням и 4-часовым промежуткам - и выявление трендов и сезонности в полученных данных.\n",
    "\n",
    "Результаты семплирования и анализа дневных, 4-часовых и часовых графиков позволяют выявить следующие закономерности:\n",
    "- общий тренд рассматриваемых данных - восходящий\n",
    "- данные обладают выраженной недельной и суточной сезонностью (поскольку данные представлены только за 6 месяцев говорить о выявлении более крупных сезонных зависимостях не представляется возможным)\n",
    "\n",
    "Выявленные закономерности позволяют сделать предположение о возможных обучающих признаках - различных комбинациях исторических значений (предыдущих периодов со сдвигом) и скользящих средних переменных размеров окна. Эти предположения были учтены при формировании обучающих признаков для моделей машинного обучения, при генерации признаков соблюдались следующие требования:\n",
    "- в каждом масштабе сохраняем ближайшие предыдущие значения и значения прошлого аналогичного периода (например, для недельного цикла это будут значения - 1, 2 дня назад и 7 дней назад (предыдущий аналог)\n",
    "- скользящие средние комбинируем по окнам разной ширины (при этом для более коротких скользящих средних выбираем способ построения, учитывающий последния значения с бОльшим весом относительно более старых)\n",
    "\n",
    "Проведено обучение 4 различных видов моделей машинного обучения:\n",
    "\n",
    "- линейная регрессия\n",
    "- случайный лес\n",
    "- CatBoostRegressor\n",
    "- LGBMRegressor\n",
    "Все модели улучшили значение метрики RMSE dummy-модели более чем в 1.5 раза. При этом модели градиентного бустинга показали наилучшее значение метрики ~38.3, что на 10% лучше результатов линейной регрессии и случайного леса.\n",
    "\n",
    "С помощью модели LightGBM получено наилучшее значение метрики RMSE. При этом время обучения LightGBM намного меньше чем у CatBoost.\n",
    "\n",
    "В целом следует отметить, что качество линейной регрессии и случайного леса также вполне удовлетворительны - в 1.5 раза лучше dummy-модели и на 10% хуже градиентного бустинга.\n",
    "\n",
    "Также следует отметить, что состав наиболее значимых признаков по всем моделям практически совпадает:\n",
    "- текущий час\n",
    "- значения 24, 48 и 72-часовых сдвигов \n",
    "\n",
    "При этом в линейной регрессии наибольшей значимостью обладает скользящая средняя 4-часовых периодов, рассчитываемая по 24-периодному окну (4 дня).\n",
    "\n",
    "Наиболее сбалансированная веса обучающих признаков в модели LightGBM.\n",
    "\n",
    "Также следует отметить важность во многих моделях признака числа заказов неделю назад (D1_lag_7), что снова подтверждает наличие ярко выраженной недельной цикличности.\n",
    "\n",
    "В целом следует отметить, что указанное сочетание признаков, содержащее как значения сдвигов (разных интервалов на разных масштабах), так и значения скользящих средних (по разным окнам) позволило достичь и существенно превзойти целевое значение метрики RMSE всеми рассмотренными моделями.\n",
    "\n",
    "На завершающем этапе проведена оценка ошибок предсказаний модели LightGBM по дням недели и часам:\n",
    "- определено, что наиболее количество ошибок - в ночные часы (с 1 до 4), когда вероятно на предсказание оказывает большое значение восходящий тренд предыдущего дня (увеличение числа заказов с 18 до 0 часов). Т.е. модель плохо улавливает завершение восходящего вечернего тренда и его смену на ночной период с малым числом заказов. \n",
    "- кроме того в понедельник наибольшее количество ошибок со знаком `-`, т.е. когда модель предсказывает меньшее количество заказов, чем было фактически. Вероятно это связано с тем, что за выходные (когда количество заказов меньше чем в будни) значения предыдущих периодов оказывают большее значение - фактически модель плохо улавливает смену нисходящего тренда выходных дней на восходящий тренд в будни.\n",
    "\n",
    "На основе этого сформированы два дополнительных обучающих признака и проведено повторное обучение модели LightGBM с теми же гиперпараметрами, что позволило еще немного улучшить метрику RMSE. Вместе с тем следует отметить, что подбор обучающих признаков для обучения рассматриваемой модели требует проведения возможно более подробных исследований (перебора по более широкой комбинации сдвиговых и скользящих признаков).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "366.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
