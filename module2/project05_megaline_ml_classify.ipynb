{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Общая-информация-и-предобработка-данных\" data-toc-modified-id=\"Общая-информация-и-предобработка-данных-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Общая информация и предобработка данных</a></span><ul class=\"toc-item\"><li><span><a href=\"#Загрузка-данных\" data-toc-modified-id=\"Загрузка-данных-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Загрузка данных</a></span></li><li><span><a href=\"#Формирование-дополнительных-атрибутов\" data-toc-modified-id=\"Формирование-дополнительных-атрибутов-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Формирование дополнительных атрибутов</a></span></li><li><span><a href=\"#Оценка-корреляций\" data-toc-modified-id=\"Оценка-корреляций-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Оценка корреляций</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Выводы</a></span></li></ul></li><li><span><a href=\"#Разбиение-данных-на-выборки\" data-toc-modified-id=\"Разбиение-данных-на-выборки-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Разбиение данных на выборки</a></span><ul class=\"toc-item\"><li><span><a href=\"#Разбиение-данных-на-обучающую,-валидационную-и-тестовую-выборки\" data-toc-modified-id=\"Разбиение-данных-на-обучающую,-валидационную-и-тестовую-выборки-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Разбиение данных на обучающую, валидационную и тестовую выборки</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Выводы</a></span></li></ul></li><li><span><a href=\"#Исследование-моделей\" data-toc-modified-id=\"Исследование-моделей-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Исследование моделей</a></span><ul class=\"toc-item\"><li><span><a href=\"#Решающее-дерево\" data-toc-modified-id=\"Решающее-дерево-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Решающее дерево</a></span></li><li><span><a href=\"#Случайный-лес\" data-toc-modified-id=\"Случайный-лес-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Случайный лес</a></span></li><li><span><a href=\"#Логистическая-регрессия\" data-toc-modified-id=\"Логистическая-регрессия-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Логистическая регрессия</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Выводы</a></span></li></ul></li><li><span><a href=\"#Проверка-моделей-на-тестовой-выборке\" data-toc-modified-id=\"Проверка-моделей-на-тестовой-выборке-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Проверка моделей на тестовой выборке</a></span><ul class=\"toc-item\"><li><span><a href=\"#Проверка-моделей\" data-toc-modified-id=\"Проверка-моделей-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Проверка моделей</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Выводы</a></span></li></ul></li><li><span><a href=\"#Проверка-моделей-на-адекватность\" data-toc-modified-id=\"Проверка-моделей-на-адекватность-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Проверка моделей на адекватность</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Выводы</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Рекомендация тарифных планов на основе данных о поведении клиентов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**«Мегалайн» — федеральный оператор сотовой связи**\n",
    "\n",
    "Исследование проводится с целью построения модели для задачи классификации, которая выбирает один из двух тарифов оператора «Мегалайн»: «Смарт» и «Ультра».\n",
    "\n",
    "В нашем распоряжении данные о поведении клиентов, которые уже перешли на эти тарифы.\n",
    "\n",
    "**Задачи исследования:**\n",
    "- построение моделей для решения задачи классификации клиентов по тарифам\n",
    "- сравнение моделей и выбор одной с наилучшим значением метрики accuracy (доля правильных ответов) не менее 0.75\n",
    "- проверка модели на адекватность"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Общая информация и предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим переменную для указания в качестве random_state на уровне проекта"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_magic = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таблица `users_behavior` - информация о поведении пользователей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users_behavior = pd.read_csv('datasets/users_behavior.csv')\n",
    "\n",
    "df_users_behavior.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Состав атрибутов\n",
    "\n",
    "В таблице `users_behavior` содержатся значения в следующих атрибутах:\n",
    "- сalls — количество звонков,\n",
    "- minutes — суммарная длительность звонков в минутах,\n",
    "- messages — количество sms-сообщений,\n",
    "- mb_used — израсходованный интернет-трафик в Мб,\n",
    "- is_ultra — каким тарифом пользовался в течение месяца («Ультра» — 1, «Смарт» — 0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Описание тарифов\n",
    "\n",
    "**<span style=\"color:magenta\">Тариф «Ультра»</span>:**\n",
    "- Ежемесячная плата: 1950 рублей\n",
    "- Включено 3000 минут разговора, 1000 сообщений и 30 Гб интернет-трафика\n",
    "- Стоимость услуг сверх тарифного пакета:\n",
    "  - минута разговора: 1 рубль\n",
    "  - сообщение: 1 рубль\n",
    "  - 1 Гб интернет-трафика: 150 рублей\n",
    "\n",
    "**<span style=\"color:green\">Тариф «Смарт»</span>:**\n",
    "- Ежемесячная плата: 550 рублей\n",
    "- Включено 500 минут разговора, 50 сообщений и 15 Гб интернет-трафика\n",
    "- Стоимость услуг сверх тарифного пакета:\n",
    "  - минута разговора: 3 рубля\n",
    "  - сообщение: 3 рубля\n",
    "  - 1 Гб интернет-трафика: 200 рублей\n",
    "\n",
    "\n",
    "**Правила тарификации: **\n",
    "- округление вверх значения длительности звонка (до минут)\n",
    "- округление вверх значения объема трафика интернет-сессии (до мегабайт)\n",
    "- округление вверх значения общего объема трафика (до гигабайт)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подробнее посмотрим общую информацию об атрибутах таблицы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_users_behavior.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users_behavior['is_ultra'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Состав атрибутов совпадает с полученным описанием.\n",
    "\n",
    "В таблице представлено 3214 записей о пользователях «Мегалайн». Пропуски в данных отсутствуют.\n",
    "\n",
    "В таблице 4 вещественных и 1 целочисленный атрибут.\n",
    "\n",
    "Значениями атрибута `is_ultra` являются 1 (тариф «Ультра») и 0 («Смарт»).\n",
    "\n",
    "Применительно к задаче построения модели очевидно, что целевым признаком (target) является атрибут `is_ultra`. Соответственно модель предназначена для решения задачи двоичной (бинарной) классификации.\n",
    "\n",
    "Подробнее посмотрим на данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users_behavior.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users_behavior.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Целесообразно выполнить приведение типов данных из вещественных к целочисленному:\n",
    "- в атрибутах `calls` и `messages` фактически целочисленные значения (количество звонков и сообщений не может быть дробным)\n",
    "- в атрибутах `minutes` и `mb_used` могут быть вещественные значения, но поскольку данные приведены за месяц пользования услугами, можно пренебречь дробными долями суммарных значений (соответственно секундами и килобайтами)\n",
    "\n",
    "Учитывая то, что минимальными значениями атрибутов видов услуг является 0, необходимо выполнить проверку на отсутствие записей с нулевыми значениями одновременно во всех атрибутах (т.е. исключить фактически неактивных пользователей при наличии)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Приведение типов данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users_behavior['calls'] = df_users_behavior['calls'].astype('int')\n",
    "df_users_behavior['minutes'] = df_users_behavior['minutes'].astype('int')\n",
    "df_users_behavior['messages'] = df_users_behavior['messages'].astype('int')\n",
    "df_users_behavior['mb_used'] = df_users_behavior['mb_used'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users_behavior.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users_behavior.query('(calls + minutes + messages + mb_used) == 0')['is_ultra'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразование типов данных выполнено. \n",
    "\n",
    "Проверка на наличие неактивных пользователей проведена - не обнаружено."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Формирование дополнительных атрибутов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определеим значения некоторых допонительных атрибутов, которые, возможно, могут применены на этапе выбора параметров моделей:\n",
    "- `call_duration` - средняя продолжительность звонка\n",
    "- `gb_used` - объем трафика в Гб (трафик за месяц на обоих тарифах округляется до Гб вверх)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users_behavior['call_duration'] = (df_users_behavior['minutes'] / df_users_behavior['calls']).round(2).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users_behavior['gb_used'] = (df_users_behavior['mb_used'] / 1024).apply(np.ceil).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_users_behavior.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"step-1-corr\"></a>\n",
    "### Оценка корреляций"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполним оценку корреляций между значениями всей совокупности атрибутов (исходных и производных)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df_users_behavior[\n",
    "        ['calls', 'minutes', 'messages', 'mb_used', 'gb_used', 'call_duration', 'is_ultra']]\n",
    "    .corr()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.plotting.scatter_matrix(\n",
    "    df_users_behavior\n",
    "    [['calls', 'minutes', 'messages', 'mb_used', 'gb_used', 'call_duration']], \n",
    "    figsize=(15, 15)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очевидным образом в сформированной совокупности атрибутов есть линейная зависимость между исходным параметром `mb_used` и производным `gb_used`. Учитывая наиболее высокий коэффициент корреляции между параметром `mb_used` и целевым признаком `is_ultra` для обучения модели линейной регрессии в перечень обучающих признаков следует включить `mb_used`.\n",
    "\n",
    "Кроме того, следует отметить также высокую корреляцию исходных параметров `calls` и `minutes`. Аналогичным образом для обучения модели линейной регрессии в перечень обучающих признаков следует включить `calls` как имеющий наиболее высокую корреляцию с целевым признаком."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы\n",
    "\n",
    "Исходные данные представлены в виде 1 таблицы с информацией об общем объеме предоставленных за месяц услуг абонентам тарифных планов «Смарт» и «Ультра» оператора «Мегалайн».\n",
    "\n",
    "В исходной таблице представлены вещественные и целочисленные атрибуты. Значения атрибутов позволяют выполнить преобразование в целочисленный тип без потери точности.\n",
    "\n",
    "Пропуски значений отсутствуют, неявные пустые записи (неактивные абоненты) отсутствуют.\n",
    "\n",
    "Дополнительно сформированы атрибуты, котрые, возможно, могут применены на этапе выбора параметров моделей:\n",
    "- `call_duration` - средняя продолжительность звонка\n",
    "- `gb_used` - объем трафика в Гб (трафик за месяц на обоих тарифах округляется до Гб вверх)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разбиение данных на выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разбиение данных на обучающую, валидационную и тестовую выборки "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку данные для обучения и тестирования модели представлены в виде одной таблицы (т.е. скрытая тестовая выборка отсутствует), необходимо разбить исходные данные на три части: \n",
    "- обучающую (`train`): используется для обучения модели\n",
    "- валидационную (`valid`): используется для валидации и выбора наилучшей модели\n",
    "- тестовую (`test`): используется для окончательной проверки точности модели\n",
    "\n",
    "Разобьем исходные данные случайным образом в следующем соотношении: 3:1:1. Учитывая то, что нами решается задача построения модели бинарной классификации, при разбиении воспользуемся принципом стратифицированной рандомизации: сохраним соотношение пользователей тарифов «Смарт» и «Ультра» во всех трех выборках.\n",
    "\n",
    "Последовательно выделим сначала test, потом valid и train (с сохранением соотношения пользователей тарифов)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция разбиения данных на 3 выборки в пропорции 3:1:1\n",
    "# при разбиении соблюдается принцип стратифицированной рандомизации по переданному параметру\n",
    "# df_source - dataframe с исходными данными\n",
    "# stratify_attr - название атрибута стратификации\n",
    "\n",
    "def split_data(df_source, stratify_attr):\n",
    "    df_train_valid, df_test = train_test_split(\n",
    "        df_users_behavior, test_size=0.20, random_state=random_magic, stratify=df_source[stratify_attr]\n",
    "    )\n",
    "    \n",
    "    df_train, df_valid = train_test_split(\n",
    "        df_train_valid, test_size=0.25, random_state=random_magic, stratify=df_train_valid[stratify_attr]\n",
    "    )\n",
    "    \n",
    "    return df_train, df_valid, df_test, df_train_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_valid, df_test, df_train_valid = split_data(df_users_behavior, 'is_ultra')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим соотношение пользователей тарифов в сформированных выборках "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train['is_ultra'].mean(), df_valid['is_ultra'].mean(), df_test['is_ultra'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим графики распределения абонентов тарифов по представленным в исходных данных атрибутах. Оценку проводим на совокупности обучающей и валидационной выборок, чтобы не создать неявных зависимостей с тестовыми данными (не появились 'leaks' - утечки данных)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_features = {\n",
    "    'calls': ('Распределение абонентов по числу совершенных звонков', 'Число звонков'), \n",
    "    'messages': ('Распределение абонентов по числу сообщений', 'Число сообщений'),\n",
    "    'minutes': ('Распределение абонентов по числу минут', 'Число минут'),\n",
    "    'call_duration': ('Распределение абонентов по средней длительности разговора', 'Средняя длительность (сек)'),\n",
    "    'mb_used': ('Распределение абонентов по объему трафика', 'Трафик (Мб)'),\n",
    "    'gb_used': ('Распределение абонентов по объему трафика', 'Трафик (Гб)'),\n",
    "}\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "        nrows=3, \n",
    "        ncols=2, \n",
    "        figsize=(16,20) \n",
    ")\n",
    "    \n",
    "plt.subplots_adjust(hspace=0.3)\n",
    "    \n",
    "# хинт для отображения общих вертикальных и горизонтальных меток - общий невидимых график\n",
    "fig.add_subplot(111, frameon=False)\n",
    "# hide tick and tick label of the big axes\n",
    "plt.tick_params(labelcolor='none', top=False, bottom=False, left=False, right=False)\n",
    "plt.grid(False)\n",
    "    \n",
    "magenta_patch = mpatches.Patch(color='magenta', label='УЛЬТРА')\n",
    "green_patch = mpatches.Patch(color='green', label='СМАРТ')\n",
    "i = 0\n",
    "\n",
    "for feature, (title, x_label) in source_features.items():\n",
    "    i += 1\n",
    "    # расчет позиции графика в матрице 3х2\n",
    "    ax_i = axs[int((i - 1) / 2), (i - 1) % 2]\n",
    "        \n",
    "    fig = df_train_valid.query('is_ultra == 0')[feature].plot(\n",
    "        grid=True, \n",
    "        kind='hist', \n",
    "        color='green', \n",
    "        bins=35,\n",
    "        alpha = 0.8,\n",
    "        ax = ax_i\n",
    "    )\n",
    "\n",
    "    df_train_valid.query('is_ultra == 1')[feature].plot(\n",
    "        grid=True, \n",
    "        kind='hist',\n",
    "        color='magenta',\n",
    "        bins=35,\n",
    "        alpha = 0.6,\n",
    "        ax = ax_i\n",
    "    )\n",
    "    \n",
    "    ax_i.set_title(title, fontsize='x-large')\n",
    "    ax_i.set_xlabel(x_label, fontsize='large')   \n",
    "    ax_i.set_ylabel('Число абонентов' if i % 2 == 1 else '', fontsize='x-large')\n",
    "        \n",
    "    if i % 2 == 0:\n",
    "        ax_i.legend(handles=[magenta_patch, green_patch])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Указанные графики позволяют сделать следующее предположение:\n",
    "\"хвосты\" распределений по параметрам числа совершенных звонков и отправленных сообщений, а также общего объема минут и трафика более характерны для абонентов тарифа «Ультра». \n",
    "\n",
    "Кроме того, возможно, что звонки нулевой средней длительности более характерны для абонентов тарифа «Ультра» (тариф может использоваться в устройствах, не предназначенных для голосовой связи, например, модемах, навигаторах и т.д.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(\n",
    "    df_train_valid, \n",
    "    x = 'call_duration', \n",
    "    marginal = 'box', \n",
    "    color = \"is_ultra\",\n",
    "    title = 'Распределение абонентов по средней длительности разговора',\n",
    "    color_discrete_map={\n",
    "                1: 'Magenta', 0: 'Green'\n",
    "            },\n",
    "    opacity = 0.7\n",
    ")\n",
    "\n",
    "fig.update_layout(xaxis_title=\"Средняя длительность (сек)\", yaxis_title=\"Число абонентов\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На основе указанных предположений рассчитаем дополнительный атрибут, который, возможно, позволит улучшить точность модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция возвращает весовой коэффициент объема потребленных услуг\n",
    "# значения коэффициентов определены на основе распределения значений в тестовой и валидационной выборках \n",
    "# row - запись в исходной таблице объемов услуг\n",
    "\n",
    "def get_ultra_weight(row)->int:\n",
    "    minutes = row['minutes']\n",
    "    calls = row['calls']\n",
    "    messages = row['messages']\n",
    "    gb_used = row['gb_used']\n",
    "    call_duration = row['call_duration']\n",
    "    ultra_weight = 0\n",
    "\n",
    "    if (calls >= 140): ultra_weight += 1\n",
    "    if (messages > 140): ultra_weight += 1\n",
    "    if (minutes >= 1000): ultra_weight += 1\n",
    "    if (gb_used > 35): ultra_weight += 1\n",
    "    if (call_duration <= 0.1): ultra_weight += 1\n",
    "  \n",
    "    return ultra_weight "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users_behavior['ultra_weight'] = df_users_behavior.apply(\n",
    "    lambda row: get_ultra_weight(row),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После добавления нового атрибута к исходным данным, необходимо заново разделить исходный данные на train, valid и test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_valid, df_test, df_train_valid = split_data(df_users_behavior, 'is_ultra')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = px.histogram(\n",
    "    df_train_valid.query('ultra_weight > 0'), \n",
    "    x = 'ultra_weight', \n",
    "    color = \"is_ultra\",\n",
    "    title = 'Соотношение абонентов тарифов для расчетного признака `ultra_weight`',\n",
    "    color_discrete_map={\n",
    "                1: 'Magenta', 0: 'Green'\n",
    "            },\n",
    "    opacity = 0.7\n",
    ")\n",
    "\n",
    "fig.update_layout(xaxis_title=\"Значения расчетного признака `ultra_weight`\", yaxis_title=\"Число абонентов\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполним оценку корреляций между значениями, отобранными для обучения модели линейной регрессии, и новых рассчетным параметром."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df_train_valid[\n",
    "        ['calls', 'messages', 'mb_used', 'call_duration', 'ultra_weight']]\n",
    "    .corr()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сильной линейной зависимости между новым признаком `ultra_weight` и отобранными для обучения линейной модели не выявлено - его также можно включать в перечень обучающих признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы\n",
    "\n",
    "Выполнено разбиение данных случайным образом на обучающую, валидационную и тестовую выборки. Разбиение проведено с сохранением пропорции в целевом атрибуте `is_ultra`.\n",
    "\n",
    "На совокупности обучающей и валидационной выборок проведена оценка распределения абонентов тарифов по представленным в исходных данных атрибутах. Сделан расчет дополнительного атрибута `ultra_weight` на основе наиболее характерных для абонентов тарифа «Ультра» объемах предоставленных услуг. Указанный атрибут будет использован при построении и сравнении моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Исследование моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В первую очередь определим целевой признак для построения моделей - атрибут `is_ultra` (принадлежность одному из двух рассматриваемых тарифов)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = ['is_ultra']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее для сравнения моделей определим несколько наборов признаков, по которым будет проводить обучение моделей.\n",
    "Базовый набор признаков (соответствует исходным атрибутам: `calls`, `minutes`, `messages`, `mb_used`) запишем в словарь с ключом `base`.\n",
    "\n",
    "Соответственно для линейной модели из наборов обучающих признаков исключены сильно коррелирующие друг с другом. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_features = {\n",
    "    'base' : ['calls', 'minutes', 'messages', 'mb_used'],\n",
    "    'ext1' : ['calls', 'minutes', 'messages', 'mb_used', 'gb_used', 'call_duration'],\n",
    "    'ext2' : ['calls', 'minutes', 'messages', 'mb_used', 'gb_used', 'ultra_weight'],\n",
    "    'ext3' : ['calls', 'minutes', 'messages', 'mb_used', 'ultra_weight'],  \n",
    "    'ext4' : ['calls', 'minutes', 'messages', 'gb_used'],\n",
    "    'ext5' : ['calls', 'minutes', 'messages', 'gb_used', 'ultra_weight'], \n",
    " \n",
    "}\n",
    "\n",
    "linear_model_features = {\n",
    "    'base' : ['calls', 'messages', 'mb_used'],\n",
    "    'ext1' : ['calls', 'messages', 'mb_used', 'call_duration'],\n",
    "    'ext2' : ['calls', 'messages', 'mb_used', 'ultra_weight'],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим функцию, которая готовит соответствующие исходным и целевому признакам выборки из совокупности выборок train, valid, test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция подготовки наборов данных с обучающими и целевыми признаками для выборок train, valid и test  \n",
    "# features - набор обучающих признаков\n",
    "# целевой признак - глобальная переменная target\n",
    "# выборки train, valid и test - глобальные переменные df_train, df_valid, df_test соответственно\n",
    "\n",
    "def prepare_model_data(features):\n",
    "    df_train_X = df_train[features]\n",
    "    df_train_Y = df_train[target]\n",
    "\n",
    "    df_valid_X = df_valid[features]\n",
    "    df_valid_Y = df_valid[target]\n",
    "\n",
    "    df_test_X = df_test[features]\n",
    "    df_test_Y = df_test[target]\n",
    "    \n",
    "    return df_train_X, df_train_Y, df_valid_X, df_valid_Y, df_test_X, df_test_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_X, df_train_Y, df_valid_X, df_valid_Y, df_test_X, df_test_Y = prepare_model_data(model_features['base'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Решающее дерево"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим модель \"Решающее дерево\" (DecisionTreeClassifier).\n",
    "Для каждого набора признаков в цикле сделаем перебор параметра модели - максимальной глубины - в диапазоне от 1 до 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = None\n",
    "best_result = 0\n",
    "best_key = None\n",
    "best_feature = None\n",
    "\n",
    "df_compare = pd.DataFrame(columns = ['features', 'param', 'accuracy', 'model']) \n",
    "\n",
    "for key, feature in model_features.items():\n",
    "    df_train_X, df_train_Y, df_valid_X, df_valid_Y, df_test_X, df_test_Y = prepare_model_data(feature)\n",
    "    \n",
    "    for depth in range(1, 11):\n",
    "        # обучение модели с заданной глубиной дерева\n",
    "        model = DecisionTreeClassifier(random_state=random_magic, max_depth=depth)\n",
    "        model.fit(df_train_X, df_train_Y)\n",
    "        \n",
    "        # получение предсказаний на валидационной выборке\n",
    "        predictions = model.predict(df_valid_X) \n",
    "        \n",
    "        # рассчет метрики accuracy\n",
    "        result = accuracy_score(df_valid_Y, predictions) \n",
    "        \n",
    "        df_compare = df_compare.append(\n",
    "            {'features': key, 'param': depth, 'accuracy': result, 'model' : model}, \n",
    "            ignore_index=True\n",
    "        )\n",
    "        \n",
    "        if result > best_result:\n",
    "            best_model = model\n",
    "            best_result = result\n",
    "            best_key = key\n",
    "            best_feature = feature\n",
    "        \n",
    "print(\"Accuracy лучшей модели (набор исходных признаков: {0}): {1}\".format(best_feature, best_result))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значения метрики `accuracy` для всех построенных моделей визуализируем в виде тепловой карты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для отображения распределения метрики `accuracy` в виде тепловой карты \n",
    "# df_compare - dataframe исходных данных\n",
    "# x_label - подпись оси X\n",
    "\n",
    "def show_heatmap(df_compare, x_label):\n",
    "    df_pivot = df_compare.pivot_table(\n",
    "                            index='features', \n",
    "                            columns='param', \n",
    "                            values='accuracy', \n",
    "                            aggfunc=max\n",
    "    ).reset_index().set_index('features')   \n",
    "    \n",
    "    plt.figure(figsize=(18, 7))\n",
    "    sns.heatmap(df_pivot, annot=True, fmt=\".5f\", linewidths=.1, cmap= 'coolwarm')\n",
    "    plt.title('Значения метрики `accuracy`', fontsize=15)\n",
    "    plt.ylabel('Код набора обучающих признаков', fontsize=15)\n",
    "    plt.xlabel(x_label, fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_heatmap(df_compare, 'Максимальная глубина дерева')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По тепловой карте видно, что наилучшее значение метрики `accuracy` достигается для модели DecisionTreeClassifier при следующих условиях:\n",
    "- наборе обучающих признаков [`calls`, `minutes`, `messages`, `gb_used`] и максимальной глубине равной 5\n",
    "- базовом наборе обучающих признаков [`calls`, `minutes`, `messages`, `mb_used`] и значениях параметра максимальной глубины 5 и 7. \n",
    "\n",
    "Выше 0.80 также значение метрики `accuracy` также достигается для базового набора обучающих признаков, дополненного вычисленным атрибутом `ultra_weight`, и значении параметра максимальной глубины равным 7. \n",
    "\n",
    "Указанные 4 модели отберем для последующей проверки на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dtc_to_test = {\n",
    "    'ext4' : {'5' : df_compare.query('features == \\'ext4\\' and param == 5')['model'].values[0]},\n",
    "    'base' : {\n",
    "        '5' : df_compare.query('features == \\'base\\' and param == 5')['model'].values[0],\n",
    "        '7' : df_compare.query('features == \\'base\\' and param == 7')['model'].values[0]\n",
    "             },\n",
    "    'ext3' : {'7' : df_compare.query('features == \\'ext3\\' and param == 7')['model'].values[0]}, \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Случайный лес"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Рассмотрим модель \"Cлучайный лес\" (RandomForestClassifier).\n",
    "Для каждого набора признаков в цикле сделаем перебор параметра модели - количества деревьев - в диапазоне от 1 до 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = None\n",
    "best_result = 0\n",
    "best_key = None\n",
    "best_feature = None\n",
    "\n",
    "df_compare = pd.DataFrame(columns = ['features', 'param', 'accuracy', 'model']) \n",
    "\n",
    "for key, feature in model_features.items():\n",
    "    df_train_X, df_train_Y, df_valid_X, df_valid_Y, df_test_X, df_test_Y = prepare_model_data(feature)\n",
    "    \n",
    "    for est in range(1, 21):\n",
    "        # обучение модели с заданным числом деревьев\n",
    "        model = RandomForestClassifier(random_state=random_magic, n_estimators=est)\n",
    "        model.fit(df_train_X, df_train_Y.values.ravel())\n",
    "        \n",
    "        # рассчет метрики accuracy на валидационной выборке\n",
    "        result = model.score(df_valid_X, df_valid_Y) \n",
    "        \n",
    "        df_compare = df_compare.append(\n",
    "            {'features': key, 'param': est, 'accuracy': result, 'model' : model}, \n",
    "            ignore_index=True\n",
    "        )\n",
    "        \n",
    "        if result > best_result:\n",
    "            best_model = model\n",
    "            best_result = result\n",
    "            best_key = key\n",
    "            best_feature = feature\n",
    "        \n",
    "print(\"Accuracy лучшей модели (набор исходных признаков: {0}): {1}\".format(best_feature, best_result))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значения метрики `accuracy` для всех построенных моделей визуализируем в виде тепловой карты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_heatmap(df_compare, 'Число деревьев')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По тепловой карте видно, что наилучшее значение метрики `accuracy` достигается для модели RandomForestClassifier при следующих условиях:\n",
    "- наборе обучающих признаков [`calls`, `minutes`, `messages`, `gb_used`, `ultra_weight`] и числе деревьев равным 16 и 20\n",
    "- базовом наборе обучающих признаков [`calls`, `minutes`, `messages`, `mb_used`] и числе деревьев равным 12 и 20\n",
    "- наборе обучающих признаков [`calls`, `minutes`, `messages`, `gb_used`] и числе деревьев равным 12\n",
    "\n",
    "Следует отметить, что полученное для модели RandomForestClassifier наилучшее значение `accuracy` больше соответствующего значения модели DecisionTreeClassifier.\n",
    "\n",
    "Указанные 5 моделей отберем для последующей проверки на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rfc_to_test = {\n",
    "    'ext5' : {\n",
    "        '16' : df_compare.query('features == \\'ext5\\' and param == 16')['model'].values[0],\n",
    "        '20' : df_compare.query('features == \\'ext5\\' and param == 20')['model'].values[0]\n",
    "             },\n",
    "    'base' : {\n",
    "        '12' : df_compare.query('features == \\'base\\' and param == 12')['model'].values[0],\n",
    "        '20' : df_compare.query('features == \\'base\\' and param == 20')['model'].values[0]\n",
    "             },          \n",
    "    'ext4' : {'12' : df_compare.query('features == \\'ext4\\' and param == 12')['model'].values[0]}, \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Рассмотрим модель \"Логистическая регрессия\" (LogisticRegression).\n",
    "Для каждого набора признаков проведем расчет метрики `accuracy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = None\n",
    "best_result = 0\n",
    "best_key = None\n",
    "best_feature = None\n",
    "\n",
    "df_compare = pd.DataFrame(columns = ['features', 'param', 'accuracy']) \n",
    "\n",
    "for key, feature in linear_model_features.items():\n",
    "    df_train_X, df_train_Y, df_valid_X, df_valid_Y, df_test_X, df_test_Y = prepare_model_data(feature)\n",
    "\n",
    "    model = LogisticRegression(random_state=random_magic, solver='lbfgs') \n",
    "    model.fit(df_train_X, df_train_Y.values.ravel()) \n",
    "    \n",
    "    # рассчет метрики accuracy на валидационной выборке\n",
    "    result = model.score(df_valid_X, df_valid_Y)\n",
    "\n",
    "    df_compare = df_compare.append(\n",
    "            {'features': key, 'param': '', 'accuracy': result}, \n",
    "            ignore_index=True\n",
    "        )\n",
    "        \n",
    "    if result > best_result:\n",
    "        best_model = model\n",
    "        best_result = result\n",
    "        best_key = key\n",
    "        best_feature = feature\n",
    "        \n",
    "print(\"Accuracy лучшей модели (набор исходных признаков: {0}): {1}\".format(best_feature, best_result))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значения метрики `accuracy` для всех построенных моделей визуализируем в виде тепловой карты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_heatmap(df_compare, '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наилучшая метрика `accuracy` логистической регрессии также получена не для базового набора обучающих признаков, а для набора дополненного вычисленным атрибутом `ultra_weight`.\n",
    "\n",
    "Вместе с тем, полученное значение `accuracy` равное 0.763 много меньше соответствующих значений для рассмотренных выше моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы\n",
    "\n",
    "В рамках построения и сравнения различных моделей были выполнены следующие этапы:\n",
    "- определен целевой признак и сформирован словарь обучающих признаков для построения моделей\n",
    "- для каждого набора обучающих признаков проведена оценка гиперпараметров моделей дерева решений и случайного леса и определены модели с наиболее высоким значением метрики `accuracy`, вычисленным на валидационной выборке\n",
    "- для каждого набора обучающих признаков построена модель логистической регрессии и также определено наиболее высокое значение метрики `accuracy`\n",
    "- сформирован перечень моделей для последующей проверки на тестовой выборке\n",
    "\n",
    "В целом следует отметить, что включение в состав обучающих атрибутов дополнительных расчетных признаков на валидационной выборке позволило получить более высокие значения метрики `accuracy`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка моделей на тестовой выборке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция расчета метрики `accuracy` на тестовых данных\n",
    "# model - модель, для которой выполняются предсказания и расчет метрики\n",
    "# df_test_X - обучающие признаки тестовой выборки \n",
    "# df_test_X - целевые признаки тестовой выборки\n",
    "\n",
    "def calc_accuracy_test(model, df_test_X, df_test_Y):\n",
    "    predictions = model.predict(df_test_X) \n",
    "    result = accuracy_score(df_test_Y, predictions) \n",
    "\n",
    "    return result    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_X = df_test[linear_model_features['ext2']]\n",
    "df_test_Y = df_test[target]\n",
    "    \n",
    "print(\"Accuracy лучшей модели логистической регрессии:\", calc_accuracy_test(best_model, df_test_X, df_test_Y))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy на тестовых данных моделей решающего дерева\")\n",
    "      \n",
    "for key, models in model_dtc_to_test.items():\n",
    "    df_test_X = df_test[model_features[key]]\n",
    "    df_test_Y = df_test[target]\n",
    "    \n",
    "    for param, model in models.items():\n",
    "        print(\"Accuracy модели с обучающим набором {0} и максимальной глубиной {1}: {2}\".format(\n",
    "                        key, param, calc_accuracy_test(model, df_test_X, df_test_Y)\n",
    "                    )\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy на тестовых данных моделей случайного леса\")\n",
    "      \n",
    "for key, models in model_rfc_to_test.items():\n",
    "    df_test_X = df_test[model_features[key]]\n",
    "    df_test_Y = df_test[target]\n",
    "    \n",
    "    for param, model in models.items():\n",
    "        print(\"Accuracy модели с обучающим набором {0} и числом деревьев {1}: {2}\".format(\n",
    "                        key, param, calc_accuracy_test(model, df_test_X, df_test_Y)\n",
    "                    )\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_val_X = df_train_valid[model_features['base']]\n",
    "\n",
    "df_train_val_Y = df_train_valid[target] \n",
    "\n",
    "df_test_X = df_test[model_features['base']]\n",
    "\n",
    "df_test_Y = df_test[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выбираем для перебора гиперпараметров значения в следующих диапазонах:\n",
    "- максимальная глубина: от 4 до 9\n",
    "- число деревьев: от 15 до 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [15, 16, 17, 18, 19, 20],\n",
    "    'max_depth': [4, 5, 6, 7, 8, 9]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=random_magic)\n",
    "\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = StratifiedKFold(n_splits = 4, shuffle=True, random_state=random_magic), \n",
    "                           n_jobs = -1, verbose = 2)\n",
    "\n",
    "grid_search.fit(df_train_val_X, df_train_val_Y.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По результатам обучения с кросс-валидацией наилучшими значениями гиперпараметров определены:\n",
    "- максимальная глубина дерева: 8\n",
    "- число деревьев: 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Accuracy модели с базовым обучающим набором, максимальной глубиной дерева {0} и числом деревьев {1}: {2}\"\n",
    "    .format(8, 16, calc_accuracy_test(grid_search.best_estimator_, df_test_X, df_test_Y))\n",
    ")           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удалось немного улучшить значение `accuracy` на тестовом наборе данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы\n",
    "\n",
    "Выполнена проверка моделей на тестовой выборке. Получены следующие результаты:\n",
    "- всем отобранным моделям (за исключением логистической регрессии) удалось достичь значения метрики `accuracy` равного 0.75\n",
    "- наивысшее значение `accuracy` равное 0.81 у модели случайного леса, построенной на базовом наборе обучающих признаков [`calls`, `minutes`, `messages`, `mb_used`] с числом деревьев 16 и максимальной глубиной 8.\n",
    "- далее следуют модель случайного леса, построенная на том же базовом наборе обучающих признаков с числом деревьев 12, затем - модель случайного леса на наборе обучающих признаков [`calls`, `minutes`, `messages`, `gb_used`] (замена признака объема трафика в мегабайтах на гигабайты) и числом деревьев 12\n",
    "\n",
    "Указанные выводы в целом свидетельствуют о том, что несмотря на более высокие значения метрики `accuracy` на валидационных выборках, модели с расширенным набором признаков (включавшие признаки, полученные рассчетным путем на основе обучающих и валидационных данных) показали худшие результаты на тестовой выборке (отделенной от исходного набора данных до проведения расчетов)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка моделей на адекватность"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка модели на адекватность заключается в сопоставлении полученного значения метрики `accuracy` (0.81) с одним из простых способов классификации клиента оператора «Мегалайн».\n",
    "\n",
    "Учитывая то, что исходные данные - это репрезентативная выборка, то простым способом оценки вероятности угадывания того, что клиент пользуется одним из двух рассматриваемых тарифов является оценка доли клиентов каждого из тарифов в общей выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - df_users_behavior['is_ultra'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Доля клиентов тарифа «Смарт» составляет 0.69, соответственно с этой вероятностью можно решить требуемую задачу классификации клиентов по тарифам \"наугад\".\n",
    "\n",
    "Полученное значение метрики `accuracy` (0.81) выше указанной вероятности, соответственно, модель улучшает случайную метрику, т.е. адекватна."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналогичным образом можно использовать фиктивный классификатор DummyClassifier с параметром `most_frequent` (выбор наиболее часто встречаемого значения целевого признака)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_X, df_train_Y, df_valid_X, df_valid_Y, df_test_X, df_test_Y = prepare_model_data(model_features['base'])\n",
    "\n",
    "dummy_classifier = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_classifier.fit(df_train_X, df_train_Y)\n",
    "\n",
    "predictions = dummy_classifier.predict(df_test_X) \n",
    "result = accuracy_score(df_test_Y, predictions) \n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также на основе значений рассчитанного выше атрибута `ultra_weight` можно предложить еще один простой способ \"угадывания\": отнести всех клиентов, для которых значения атрибута `ultra_weight` больше 0 - к абонентам тарифа «Ультра», всех остальных - к тарифу «Смарт»."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_dummy = df_test.copy()\n",
    "df_test_dummy['is_ultra_dummy'] = (df_test_dummy['ultra_weight'] > 0).astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом случае в качестве метрики `accuracy` будет выступать доля совпадений в исходном атрибуте `is_ultra` и расчетном `is_ultra_dummy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_dummy.query('is_ultra == is_ultra_dummy')['is_ultra'].count() / df_test_dummy['is_ultra'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значение метрики равно ~0.74 и меньше значения метрики `accuracy` построенной модели (0.81). Это также подтверждает адекватность модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В рамках исследования с целью построения модели для задачи бинарной классификации клиентов оператора «Мегалайн» по тарифным планам «Смарт» и «Ультра» выполнены следующие основные этапы:\n",
    "- проведена предварительная оценка и предобработка данных\n",
    "- выполнено разбиение (с сохранением пропорции в целевом атрибуте `is_ultra`) исходных данных случайным образом на обучающую, валидационную и тестовую выборки\n",
    "- выполнен расчет дополнительных атрибутов для последующего построения и сравнения моделей \n",
    "- определен целевой признак и сформирован словарь обучающих признаков для построения моделей\n",
    "- для каждого набора обучающих признаков проведена оценка гиперпараметров моделей дерева решений и случайного леса и определены модели с наиболее высоким значением метрики `accuracy`, вычисленным на валидационной выборке\n",
    "- для каждого набора обучающих признаков построена модель логистической регрессии и также определено наиболее высокое значение метрики `accuracy`\n",
    "- сформированный перечень моделей с наиболее высокими значениями метрики `accuracy` подготовлен для последующей проверки на тестовой выборке.\n",
    "\n",
    "По результатам проверки на тестовой выборке получены следующие результаты:\n",
    "- всем отобранным моделям (за исключением логистической регрессии) удалось достичь требуемого значения метрики `accuracy` равного 0.75\n",
    "- наивысшее значение `accuracy` равное 0.81 у модели случайного леса, построенной на базовом наборе обучающих признаков [`calls`, `minutes`, `messages`, `mb_used`] с числом деревьев 16 и максимальной глубиной 8\n",
    "- далее следуют модель случайного леса, построенная на том же базовом наборе обучающих признаков с числом деревьев 12, затем - модель случайного леса на наборе обучающих признаков [`calls`, `minutes`, `messages`, `gb_used`] (замена признака объема трафика в мегабайтах на гигабайты) и числом деревьев 12\n",
    "\n",
    "Результаты проверки на тестовых данных в целом свидетельствуют о том, что несмотря на более высокие значения метрики `accuracy` на валидационных выборках, модели с расширенным набором признаков (включавшие признаки, полученные рассчетным путем на основе обучающих и валидационных данных) показали худшие результаты на тестовой выборке (отделенной от исходного набора данных до проведения расчетов).\n",
    "\n",
    "Также проведена проверка модели на адекватность, т.е. сравнение полученного значения метрики `accuracy` с простыми способами определения тарифа:\n",
    "- с вероятностью случайного угадывания тарифа пользователя - определена равной 0.69 на основе определения доли абонентов тарифа  «Смарт» в исходном репрезентативной выборке;\n",
    "- с вероятностью простого способа классификации на основе случайного угадывания и учета распределений параметров объема предоставленных услуг - определена равной 0.74. \n",
    "Полученное в результате исследования значение метрики `accuracy` (0.81) выше указанных вероятностей, соответственно, модель улучшает случайные метрики, т.е. адекватна."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
