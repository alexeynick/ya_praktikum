{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Общая-информация-и-подготовка-данных\" data-toc-modified-id=\"Общая-информация-и-подготовка-данных-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Общая информация и подготовка данных</a></span><ul class=\"toc-item\"><li><span><a href=\"#Таблица-Churn---информация-о-клиентах-банка\" data-toc-modified-id=\"Таблица-Churn---информация-о-клиентах-банка-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Таблица Churn - информация о клиентах банка</a></span><ul class=\"toc-item\"><li><span><a href=\"#Состав-атрибутов\" data-toc-modified-id=\"Состав-атрибутов-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>Состав атрибутов</a></span></li><li><span><a href=\"#Предварительные-преобразования-данных\" data-toc-modified-id=\"Предварительные-преобразования-данных-1.1.2\"><span class=\"toc-item-num\">1.1.2&nbsp;&nbsp;</span>Предварительные преобразования данных</a></span></li></ul></li><li><span><a href=\"#Выявление-категориальных-признаков\" data-toc-modified-id=\"Выявление-категориальных-признаков-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Выявление категориальных признаков</a></span></li><li><span><a href=\"#Оценка-корреляции-признаков\" data-toc-modified-id=\"Оценка-корреляции-признаков-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Оценка корреляции признаков</a></span></li><li><span><a href=\"#Оценка-распределения-категориальных-признаков\" data-toc-modified-id=\"Оценка-распределения-категориальных-признаков-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Оценка распределения категориальных признаков</a></span><ul class=\"toc-item\"><li><span><a href=\"#geography---страна-проживания\" data-toc-modified-id=\"geography---страна-проживания-1.4.1\"><span class=\"toc-item-num\">1.4.1&nbsp;&nbsp;</span><code>geography</code> - страна проживания</a></span></li><li><span><a href=\"#gender---пол\" data-toc-modified-id=\"gender---пол-1.4.2\"><span class=\"toc-item-num\">1.4.2&nbsp;&nbsp;</span><code>gender</code> - пол</a></span></li><li><span><a href=\"#has_cr_card---наличие-кредитной-карты\" data-toc-modified-id=\"has_cr_card---наличие-кредитной-карты-1.4.3\"><span class=\"toc-item-num\">1.4.3&nbsp;&nbsp;</span><code>has_cr_card</code> - наличие кредитной карты</a></span></li><li><span><a href=\"#is_active_member---признак-активности\" data-toc-modified-id=\"is_active_member---признак-активности-1.4.4\"><span class=\"toc-item-num\">1.4.4&nbsp;&nbsp;</span><code>is_active_member</code> - признак активности</a></span></li><li><span><a href=\"#num_of_products---количество-продуктов-банка,-используемых-клиентом\" data-toc-modified-id=\"num_of_products---количество-продуктов-банка,-используемых-клиентом-1.4.5\"><span class=\"toc-item-num\">1.4.5&nbsp;&nbsp;</span><code>num_of_products</code> - количество продуктов банка, используемых клиентом</a></span></li></ul></li><li><span><a href=\"#Оценка-распределения-числовых-признаков\" data-toc-modified-id=\"Оценка-распределения-числовых-признаков-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Оценка распределения числовых признаков</a></span><ul class=\"toc-item\"><li><span><a href=\"#credit_score---кредитный-рейтинг\" data-toc-modified-id=\"credit_score---кредитный-рейтинг-1.5.1\"><span class=\"toc-item-num\">1.5.1&nbsp;&nbsp;</span><code>credit_score</code> - кредитный рейтинг</a></span></li><li><span><a href=\"#age---возраст\" data-toc-modified-id=\"age---возраст-1.5.2\"><span class=\"toc-item-num\">1.5.2&nbsp;&nbsp;</span><code>age</code> - возраст</a></span></li><li><span><a href=\"#balance---баланс\" data-toc-modified-id=\"balance---баланс-1.5.3\"><span class=\"toc-item-num\">1.5.3&nbsp;&nbsp;</span><code>balance</code> - баланс</a></span></li><li><span><a href=\"#estimated_salary---предполагаемая-зарплата\" data-toc-modified-id=\"estimated_salary---предполагаемая-зарплата-1.5.4\"><span class=\"toc-item-num\">1.5.4&nbsp;&nbsp;</span><code>estimated_salary</code> - предполагаемая зарплата</a></span></li><li><span><a href=\"#tenure---количество-недвижимости-у-клиента\" data-toc-modified-id=\"tenure---количество-недвижимости-у-клиента-1.5.5\"><span class=\"toc-item-num\">1.5.5&nbsp;&nbsp;</span><code>tenure</code> - количество недвижимости у клиента</a></span></li></ul></li><li><span><a href=\"#Заполнение-пропусков\" data-toc-modified-id=\"Заполнение-пропусков-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>Заполнение пропусков</a></span></li><li><span><a href=\"#Формирование-дополнительных-(производных)-признаков\" data-toc-modified-id=\"Формирование-дополнительных-(производных)-признаков-1.7\"><span class=\"toc-item-num\">1.7&nbsp;&nbsp;</span>Формирование дополнительных (производных) признаков</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-1.8\"><span class=\"toc-item-num\">1.8&nbsp;&nbsp;</span>Выводы</a></span></li></ul></li><li><span><a href=\"#Исследование-задачи\" data-toc-modified-id=\"Исследование-задачи-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Исследование задачи</a></span><ul class=\"toc-item\"><li><span><a href=\"#Оценка-сбалансированности-целевых-классов\" data-toc-modified-id=\"Оценка-сбалансированности-целевых-классов-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Оценка сбалансированности целевых классов</a></span></li><li><span><a href=\"#Разбиение-данных-на-обучающую-и-тестовую-выборки\" data-toc-modified-id=\"Разбиение-данных-на-обучающую-и-тестовую-выборки-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Разбиение данных на обучающую и тестовую выборки</a></span></li><li><span><a href=\"#Подготовка-данных-для-обучения-моделей\" data-toc-modified-id=\"Подготовка-данных-для-обучения-моделей-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Подготовка данных для обучения моделей</a></span><ul class=\"toc-item\"><li><span><a href=\"#Определение-обучающих-и-целевого-признака\" data-toc-modified-id=\"Определение-обучающих-и-целевого-признака-2.3.1\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>Определение обучающих и целевого признака</a></span></li><li><span><a href=\"#Формирование-pipeline-для-подготовки-обучающих-признаков\" data-toc-modified-id=\"Формирование-pipeline-для-подготовки-обучающих-признаков-2.3.2\"><span class=\"toc-item-num\">2.3.2&nbsp;&nbsp;</span>Формирование pipeline для подготовки обучающих признаков</a></span><ul class=\"toc-item\"><li><span><a href=\"#Базовый-pipeline-подготовки-обучающих-признаков\" data-toc-modified-id=\"Базовый-pipeline-подготовки-обучающих-признаков-2.3.2.1\"><span class=\"toc-item-num\">2.3.2.1&nbsp;&nbsp;</span>Базовый pipeline подготовки обучающих признаков</a></span></li><li><span><a href=\"#Pipeline-с-добавлением-масштабирования-числовых-признаков\" data-toc-modified-id=\"Pipeline-с-добавлением-масштабирования-числовых-признаков-2.3.2.2\"><span class=\"toc-item-num\">2.3.2.2&nbsp;&nbsp;</span>Pipeline с добавлением масштабирования числовых признаков</a></span></li><li><span><a href=\"#Pipeline-с-добавлением-производных-признаков\" data-toc-modified-id=\"Pipeline-с-добавлением-производных-признаков-2.3.2.3\"><span class=\"toc-item-num\">2.3.2.3&nbsp;&nbsp;</span>Pipeline с добавлением производных признаков</a></span></li></ul></li></ul></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Выводы</a></span></li></ul></li><li><span><a href=\"#Обучение-моделей\" data-toc-modified-id=\"Обучение-моделей-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Обучение моделей</a></span><ul class=\"toc-item\"><li><span><a href=\"#Логистическая-регрессия\" data-toc-modified-id=\"Логистическая-регрессия-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Логистическая регрессия</a></span><ul class=\"toc-item\"><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3.1.1\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>Выводы</a></span></li></ul></li><li><span><a href=\"#Решающее-дерево\" data-toc-modified-id=\"Решающее-дерево-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Решающее дерево</a></span><ul class=\"toc-item\"><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>Выводы</a></span></li></ul></li><li><span><a href=\"#Случайный-лес\" data-toc-modified-id=\"Случайный-лес-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Случайный лес</a></span><ul class=\"toc-item\"><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3.3.1\"><span class=\"toc-item-num\">3.3.1&nbsp;&nbsp;</span>Выводы</a></span></li></ul></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Выводы</a></span></li></ul></li><li><span><a href=\"#Балансировка-целевых-классов\" data-toc-modified-id=\"Балансировка-целевых-классов-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Балансировка целевых классов</a></span><ul class=\"toc-item\"><li><span><a href=\"#Взвешивание\" data-toc-modified-id=\"Взвешивание-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Взвешивание</a></span><ul class=\"toc-item\"><li><span><a href=\"#Логистическая-регрессия\" data-toc-modified-id=\"Логистическая-регрессия-4.1.1\"><span class=\"toc-item-num\">4.1.1&nbsp;&nbsp;</span>Логистическая регрессия</a></span></li><li><span><a href=\"#Решающее-дерево\" data-toc-modified-id=\"Решающее-дерево-4.1.2\"><span class=\"toc-item-num\">4.1.2&nbsp;&nbsp;</span>Решающее дерево</a></span></li><li><span><a href=\"#Случайный-лес\" data-toc-modified-id=\"Случайный-лес-4.1.3\"><span class=\"toc-item-num\">4.1.3&nbsp;&nbsp;</span>Случайный лес</a></span></li></ul></li><li><span><a href=\"#Увеличение-выборки\" data-toc-modified-id=\"Увеличение-выборки-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Увеличение выборки</a></span><ul class=\"toc-item\"><li><span><a href=\"#Логистическая-регрессия\" data-toc-modified-id=\"Логистическая-регрессия-4.2.1\"><span class=\"toc-item-num\">4.2.1&nbsp;&nbsp;</span>Логистическая регрессия</a></span></li><li><span><a href=\"#Решающее-дерево\" data-toc-modified-id=\"Решающее-дерево-4.2.2\"><span class=\"toc-item-num\">4.2.2&nbsp;&nbsp;</span>Решающее дерево</a></span></li><li><span><a href=\"#Случайный-лес\" data-toc-modified-id=\"Случайный-лес-4.2.3\"><span class=\"toc-item-num\">4.2.3&nbsp;&nbsp;</span>Случайный лес</a></span></li></ul></li><li><span><a href=\"#Уменьшение-выборки\" data-toc-modified-id=\"Уменьшение-выборки-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Уменьшение выборки</a></span><ul class=\"toc-item\"><li><span><a href=\"#Логистическая-регрессия\" data-toc-modified-id=\"Логистическая-регрессия-4.3.1\"><span class=\"toc-item-num\">4.3.1&nbsp;&nbsp;</span>Логистическая регрессия</a></span></li><li><span><a href=\"#Решающее-дерево\" data-toc-modified-id=\"Решающее-дерево-4.3.2\"><span class=\"toc-item-num\">4.3.2&nbsp;&nbsp;</span>Решающее дерево</a></span></li><li><span><a href=\"#Случайный-лес\" data-toc-modified-id=\"Случайный-лес-4.3.3\"><span class=\"toc-item-num\">4.3.3&nbsp;&nbsp;</span>Случайный лес</a></span></li></ul></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Выводы</a></span></li></ul></li><li><span><a href=\"#Итоговое-тестирование-и-оценка-моделей\" data-toc-modified-id=\"Итоговое-тестирование-и-оценка-моделей-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Итоговое тестирование и оценка моделей</a></span><ul class=\"toc-item\"><li><span><a href=\"#Лучшая-модель-логистической-регресси\" data-toc-modified-id=\"Лучшая-модель-логистической-регресси-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Лучшая модель логистической регресси</a></span></li><li><span><a href=\"#Модель-случайного-леса-(вариант-1)\" data-toc-modified-id=\"Модель-случайного-леса-(вариант-1)-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Модель случайного леса (вариант 1)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Изменение-порога\" data-toc-modified-id=\"Изменение-порога-5.2.1\"><span class=\"toc-item-num\">5.2.1&nbsp;&nbsp;</span>Изменение порога</a></span></li></ul></li><li><span><a href=\"#Модель-случайного-леса-(вариант-2)\" data-toc-modified-id=\"Модель-случайного-леса-(вариант-2)-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Модель случайного леса (вариант 2)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Изменение-порога\" data-toc-modified-id=\"Изменение-порога-5.3.1\"><span class=\"toc-item-num\">5.3.1&nbsp;&nbsp;</span>Изменение порога</a></span></li></ul></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>Выводы</a></span></li></ul></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Выводы</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Прогнозирование оттока клиентов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из «Бета-Банка» стали уходить клиенты. Каждый месяц. Немного, но заметно. Банковские маркетологи посчитали: сохранять текущих клиентов дешевле, чем привлекать новых.\n",
    "\n",
    "Нужно спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. \n",
    "\n",
    "В нашем распоряжении исторические данные о поведении клиентов и расторжении договоров с банком (источник данных: [https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling](https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling)).\n",
    "\n",
    "**Задачи исследования:**\n",
    "- построение моделей для решения задачи прогнозирования - уйдет клиент из банка или нет\n",
    "- сравнение моделей и выбор одной с наилучшим значением метрики *F1*-меры не менее 0.59\n",
    "- определение метрики *AUC-ROC*, сравнение её значения с *F1*-мерой"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Общая информация и подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "from IPython.display import display\n",
    "from termcolor import colored\n",
    "\n",
    "# обучение моделей\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# метрики\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import f1_score, roc_auc_score, roc_curve, precision_score, \\\n",
    "                            recall_score, accuracy_score, precision_recall_curve\n",
    "\n",
    "# pipeline\n",
    "#from sklearn import preprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler \n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_magic = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Таблица Churn - информация о клиентах банка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Состав атрибутов\n",
    "\n",
    "По имеющейся от источника информации в таблице содержатся значения в следующих атрибутах:\n",
    "- RowNumber — индекс строки в данных\n",
    "- CustomerId — уникальный идентификатор клиента\n",
    "- Surname — фамилия\n",
    "- CreditScore — кредитный рейтинг\n",
    "- Geography — страна проживания\n",
    "- Gender — пол\n",
    "- Age — возраст\n",
    "- Tenure — количество недвижимости у клиента\n",
    "- Balance — баланс на счёте\n",
    "- NumOfProducts — количество продуктов банка, используемых клиентом\n",
    "- HasCrCard — наличие кредитной карты\n",
    "- IsActiveMember — активность клиента\n",
    "- EstimatedSalary — предполагаемая зарплата\n",
    "- Exited — факт ухода клиента\n",
    "\n",
    "Целевым признаком является `Exited` - факт ухода клиента.\n",
    "\n",
    "Загрузим данные таблицы и проверим общую информацию об атрибутах таблицы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_churn = pd.read_csv('datasets/churn.csv', index_col='RowNumber')\n",
    "\n",
    "df_churn.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_churn.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В таблице содержатся записи о 10 тысячах клиентов банка.\n",
    "\n",
    "Состав атрибутов совпадает с полученным описанием. Для удобства работы следует сделать приведение названий атрибутов из 'CamelCase' в 'snake_case'.\n",
    "\n",
    "В таблице 3 вещественных, 3 строковых и 7 целочисленных атрибутов. Для части атрибутов необходимо выполнить преобразование типов (в частности, для атрибута `tenure` — количество недвижимости у клиента).\n",
    "\n",
    "В атрибуте `tenure` — количество недвижимости у клиента - есть пропуски значений (порядка 10% от всего объема), которые целесообразно дозаполнить. \n",
    "\n",
    "Данные о клиентах содержат персональную информацию - идентификатор и фамилию, которые целесообразно сразу исключить из рассмотрения.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Предварительные преобразования данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполним приведение названий атрибутов к нижнему регистру."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_churn.rename(columns=lambda x: re.sub('(?!^)([A-Z]+)', r'_\\1',x).lower(), inplace=True)\n",
    "df_churn.index.names = ['row_number']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обезличим рассматриваемые данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_churn = df_churn.drop(['customer_id', 'surname'], axis=1)\n",
    "df_churn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполним приведение типов данных из вещественного в целочисленный для атрибутов, содержащих значения в валюте счета (некоторых условных единицах):\n",
    "- balance — баланс на счёте\n",
    "- estimatedsalary — предполагаемая зарплата"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_churn['balance'] = df_churn['balance'].astype('int')\n",
    "df_churn['estimated_salary'] = df_churn['estimated_salary'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_churn.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Указанные предварительные преобразования данных можно оформить в виде функции с целью возможного последующего использования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция предварительного преобразования данных:\n",
    "# - приведение названий атрибутов из 'CamelCase' в 'snake_case'\n",
    "# - обезличивание\n",
    "# - приведение типов\n",
    "def prepare_data_frame(df_data):\n",
    "    df_data.rename(columns=lambda x: re.sub('(?!^)([A-Z]+)', r'_\\1',x).lower(), inplace=True)\n",
    "    df_data.index.names = ['row_number']\n",
    "    \n",
    "    df_data = df_data.drop(['customer_id', 'surname'], axis=1)\n",
    "\n",
    "    df_data['balance'] = df_data['balance'].astype('int')\n",
    "    df_data['estimated_salary'] = df_data['estimated_salary'].astype('int')\n",
    "    \n",
    "    #df_data = df_data.reset_index(drop=True)\n",
    "\n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_churn = prepare_data_frame(pd.read_csv('datasets/Churn.csv', index_col='RowNumber'))\n",
    "df_churn.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выявление категориальных признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подробнее рассмотрим общую информацию о значениях атрибутов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_churn.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_churn['geography'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_churn['gender'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_churn['has_cr_card'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_churn['is_active_member'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_churn['num_of_products'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В рассматриваемой таблице значения указанных атрибутов фактически категориальные:\n",
    "- `gender` - пол:\n",
    "    - мужской (~55%)\n",
    "    - женский (~45%)\n",
    "- `geography` - страна проживания:\n",
    "    - Франция (~50%)\n",
    "    - Германия (~25%)\n",
    "    - Испания (~25%)\n",
    "- `has_cr_card` — наличие кредитной карты:\n",
    "    - 1, есть карта (~71%)\n",
    "    - 0, нет кредитной карты (~29%)\n",
    "- `is_active_member` — активность клиента:\n",
    "    - 1, признак активности (~52%)\n",
    "    - 0, признак неактивности (~48%)    \n",
    "\n",
    "Доля каждого из представленных значений существенна. \n",
    "\n",
    "Также следует обратить внимание на атрибут `num_of_products` — количество продуктов банка, используемых клиентом:\n",
    "- 1 продукт (~50.8%)\n",
    "- 2 продукта (~45.9%) \n",
    "- 3 продукта (~2.5%)\n",
    "- 4 продукта (~0.6%)  \n",
    "\n",
    "Несмотря на то, что потенциально количество продуктов банка, используемых клиентом, может быть неограниченно - фактически скорее всего указанное значение не превышает некоторой разумной величины (условно 5-10). Тем более, если под продуктом понимается вид продукта (депозит, кредит, инвестиционный счет и т.д.), а не конкретный вклад/кредит и т.д. Учитывая то, что в описании к данным эта информация не приводится, а в выборке более 95% клиентов пользуются не более чем двумя продуктами, предположение о том, что это именно вид продукта имеет право на существование. В этом случае на этапе подробного ознакомления с значениями указанного атрибута следует оценить возможность перевода его в категориальный тип.\n",
    "\n",
    "На этапе подготовки данных для моделей целесообразно выполнить преобразование указанных признаков `gender` и `geography` (фактически содержащих категориальные значения) в численные путем прямого кодирования (поскольку количество значений признаков невелико метод прямого кодирования (OHE) применим). Признаки `has_cr_card` и `is_active_member` прямого кодирования не требуют (при применении OHE любого из бинарных признаков создается два столбца, один из которых содержит значения преобразованного столбца, второй - их отрицание; соответственно один из столбцов является избыточным). \n",
    "\n",
    "Для удобства восприятия изменим порядок признаков в исходной таблице."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_churn = df_churn[['geography', 'gender', 'has_cr_card', 'is_active_member',\n",
    "                     'num_of_products', 'tenure', 'credit_score', 'age',  \n",
    "                     'balance', 'estimated_salary', 'exited']]\n",
    "df_churn.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_churn.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оценка корреляции признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполним оценку корреляций между значениями всей совокупности атрибутов (исходных и производных).\n",
    "\n",
    "Для оценки корреляции временно добавим 2 признака с целочисленными кодами категориальных признаков страны проживания и пола. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_churn['geography_cat'] = df_churn['geography'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_churn['gender_cat'] = df_churn['gender'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отобразим матрицу коэффициентов корреляции в виде таблицы коэффициентов корреляции и тепловой карты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция печати диагональной тепловой карты со значениями коэффициентов корреляции\n",
    "# df_corr - dataframe с коэффициентами корреляции\n",
    "def print_corr_heatmap(df_corr):\n",
    "    df_corr = np.abs(df_corr).replace(1,0)\n",
    "\n",
    "    mask = np.zeros_like(df_corr, dtype=np.bool)\n",
    "    mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "    plt.figure(figsize=(18, 7))\n",
    "\n",
    "    sns.heatmap(df_corr, mask=mask, annot=True, fmt=\".5f\", linewidths=.1, cmap= 'coolwarm')\n",
    "    plt.title('Матрица модулей коэффициентов корреляции', fontsize=15)\n",
    "    plt.ylabel('Признак', fontsize=15)\n",
    "    plt.xlabel('Признак', fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция печати таблицы коэффициентов корреляции и тепловой карты с модулями коэффициентов\n",
    "# df_corr - dataframe с коэффициентами корреляции\n",
    "def print_corr_table(df_corr):\n",
    "    print('{0}  Таблица корреляции  {0}'.format('+' * 50))\n",
    "    display(df_corr)\n",
    "    print_corr_heatmap(df_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_corr_table(df_churn.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отобразим матрицу графиков корреляций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.plotting.scatter_matrix(\n",
    "    df_churn\n",
    "    [['has_cr_card', 'is_active_member', 'credit_score', 'age', 'tenure', 'num_of_products', 'balance', 'estimated_salary', 'exited']], \n",
    "    figsize=(15, 15)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По результатам построения матрицы и графиков корреляций следует отметить следующее:\n",
    "- сильно коррелирующих исходных признаков в таблице нет\n",
    "- наивысшие значения коэффициентов корреляции:\n",
    "    - у признаков `balance` и `num_of_products` (-0.304) - отрицательная корреляция свидетельствует о том, что клиенты с бОльшим числом банковским продуктов, имеют меньший баланс (поскольку отрицательных значений признака `balance` нет, то вероятно значение 0 говорит об отсутствии собственных средств на счету у клиента и использовании кредитных продуктов)\n",
    "    - у целевого признака `exited` и признака `age` (0.285) - исходя из того, что по возрасту клиенты представлены в широком диапазоне - от 18 до 92 - то данная корреляция может быть обусловлена естественными факторами стадий жизни человека: в более молодом возрасте клиент впервые обращается в банк, возможно начинает пользоваться банковскими продуктами с продолжительным жизненным циклом (ипотека, длинные кредиты и т.д.). Соответственно уход клиента из банка происходит вероятно позже (например, после выплаты кредита или его рефинансирования через определенное время) и может быть вызван в том числе и смертью клиентов (соответственно в случае смерти проставляется факт ухода клиента из банка, информация о клиенте сохраняется) \n",
    "- отсутствие высокой корреляции целевого признака и иных признаков (можно было предположить, что, например, признак `is_active_member` проставляется в False в случае ухода клиента - в этом случае его следовали бы исключить из модели во избежания возможных утечек (leaks) данных)\n",
    "- наименьшие значения коэффициентов корреляции у признака `estimated_salary` - предполагаемая зарплата (не выше 0.01 со всеми другими признаками)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# удалим временные признаки с кодами категорий\n",
    "df_churn = df_churn.drop(['geography_cat', 'gender_cat'], axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оценка распределения категориальных признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подробнее рассмотрим распределение значений категориальных признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `geography` - страна проживания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция отображения сводной информации о категориальном признаке:\n",
    "# выводит в текстовом виде униклаьные значения признака и график (гистограмму) распределения по категориям:\n",
    "# действующие и ушедшие клиенты\n",
    "def describe_column_category(column, title, df=df_churn):\n",
    "    print('Признак', column, ':\\n')\n",
    "    print('Уникальные значения (процент):')\n",
    "    print(df[column].value_counts(normalize=True).mul(100).round(1).astype(str) + '%')\n",
    "    \n",
    "    print(\"\\nДоля по целевому признаку (ушедшие/все клиенты):\")\n",
    "    print((\n",
    "            df_churn.query('exited == 1')[column].value_counts() / \n",
    "            df_churn[column].value_counts()\n",
    "        ).mul(100).round(1).astype(str) + '%'\n",
    "    )\n",
    "        \n",
    "    fig = px.histogram(\n",
    "        df, \n",
    "        x = column,  \n",
    "        color = \"exited\",\n",
    "        color_discrete_map={\n",
    "                0: 'Green', 1: 'Red'\n",
    "            },\n",
    "        opacity = 0.7,\n",
    "        title = title\n",
    "    )\n",
    "\n",
    "    fig.update_layout(xaxis_title=title, yaxis_title='Число клиентов')\n",
    "    fig.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_column_category('geography', 'Страна проживания')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Доля клиентов из Франции составляет чуть более 50%, из Испании и Германии - примерно по 25%. Вместе с тем доля ушедших клиентов по странам неравномерна: для Германии доля ушедших клиентов самая высокая и составляет 32%, для Испании и Франции - по 16%.\n",
    "\n",
    "С точки зрения последующего обучения модели указанный признак может иметь большой вес."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `gender` - пол"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "describe_column_category('gender', 'Пол')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Доля мужчин и женщин составляет примерно 55% и 45% соответственно. При этом среди уходящих клиентов доля женщин выше - 25% против 16% у мужчин."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `has_cr_card` - наличие кредитной карты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "describe_column_category('has_cr_card', 'Признак наличия кредитной карты')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Доля клиентов, у которых оформлена кредитная карта, составляет чуть более 70%. При этом доля уходящих клиентов среди тех, у кого оформлена и неоформлена кредитная карта, практически одинакова и составляет порядка 20%.\n",
    "\n",
    "Возможно этот признак с точки зрения обучения моделей не будет иметь значения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `is_active_member` - признак активности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "describe_column_category('is_active_member', 'Признак активности')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Доля активных и неактивных клиентов примерно совпадает (51.5% против 48.5% соответственно). При этом доля ушедших клиентов среди неактивных практически в 2 раза выше - 27% против 14%.\n",
    "\n",
    "Вместе с тем, следует отметить тот факт, что в описании к данным подробных сведений о природе указанного признака не приведено. В источнике ([www.kaggle.com](https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling)) также указано, что это некоторая субъективная оценка, возможно выставленная на основе некоторых первичных/дополнительных данных. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `num_of_products` - количество продуктов банка, используемых клиентом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_column_category('num_of_products', 'Количество продуктов банка, используемых клиентом')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оценка распределения числовых признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подробнее рассмотрим распределение значений числовых признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `credit_score` - кредитный рейтинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция отображения сводной информации о числовом признаке:\n",
    "# выводит в текстовом виде основные параметры распределения значений признака и график (гистограмму и \"ящик с усами\")\n",
    "# распределения по категориям:\n",
    "# действующие и ушедшие клиенты\n",
    "def describe_column_numeric(column, title, df=df_churn):\n",
    "    print('Признак', column, ':')\n",
    "    \n",
    "    print(df[column].describe())\n",
    "    \n",
    "    fig = px.histogram(\n",
    "        df, \n",
    "        x = column, \n",
    "        marginal = 'box', \n",
    "        color = \"exited\",\n",
    "        color_discrete_map={\n",
    "                0: 'Green', 1: 'Red'\n",
    "            },\n",
    "        opacity = 0.7,\n",
    "        title = title\n",
    "    )\n",
    "\n",
    "    fig.update_layout(xaxis_title=title, yaxis_title='Число клиентов')\n",
    "    fig.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_column_numeric('credit_score', 'Кредитный рейтинг')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значения кредитного рейтинга находятся в диапазоне от 350 до 850. Распределение значений - близко к нормальному за исключением аномалии в районе максимального значения. Вероятно это связано с тем, что 850 - является максимальным выставляемым значением кредитного рейтинга, при его превышении (фактическая формула расчета кредитного рейтинга неизвестна) вместо фактического значения присваивается максимальное значение - 850.\n",
    "\n",
    "Распределение значений кредитного рейтинга действующих и ушедших клиентов в целом совпадает. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `age` - возраст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_column_numeric('age', 'Возраст')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значения возраста клиентов находятся в диапазоне от 18 до 92. Распределение значений - близко к нормальному.\n",
    "\n",
    "Вместе с тем следует отметить, что значение пика распределения для ушедших клиентов смещено примерно на 10 лет в сторону увеличения (45 против 35 для действующих клиентов). Подтверждает наличие определенной корреляции между фактом уход клиента из банка и возрастом клиента."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `balance` - баланс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_column_numeric('balance', 'Баланс на счете')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На графике отчетливо выделяется зона нулевого значения баланса. Определим долю таких клиентов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_churn.query('balance == 0')['balance'].count() / df_churn['balance'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "36% клиентов не хранят собственные средства на счету в банке. Это могут быть как неактивные клиенты, так и клиенты пользующиеся кредитными продуктами банка."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_churn.query(\n",
    "    'balance == 0 and has_cr_card == False and is_active_member == False'\n",
    ")['balance'].count() / df_churn['balance'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Доля таких клиентов, у которых к тому же не оформлена кредитная карта и не установлен признак активности - 5% от всего объема представленной выборки. Вместе с тем имеющееся описание признака `is_active_member` (дополнительное описание не приведено, в описании на kaggle указано, что это некоторая субъективная оценка, возможно выставленная на основе некоторых первичных/дополнительных данных) не позволяет однозначно утверждать, что это неактивные клиенты. \n",
    "\n",
    "В целом можно сделать предположение, что за значением баланса равным 0, вполне вероятно скрывается дополнительный признак - наличие задолженности перед банком (т.е. клиенты, имеющие отрицательный баланс собственных/кредитных средств).\n",
    "\n",
    "Вернемся к этому предположению на последующих этапах обучения моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим значения баланса текущего счета клиентов, имеющих положительный баланс."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_column_numeric('balance', 'Баланс на счете', df_churn.query('balance > 0'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном случае видим во многом совпадающие нормальные распределения баланса как действующих так и ушедших клиентов, с практическими равными медианными значениями баланса и близкими значениями межквартильного размаха."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `estimated_salary` - предполагаемая зарплата"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_column_numeric('estimated_salary', 'Предполагаемая зарплата')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значения предполагаемой зарплаты практически равномерно распределены в диапазоне от 0 до 200.000, как на всей выборке, так и отдельно для действующих и ушедших клиентов. Сложно однозначно оценить в каких единицах измерения и какому временному интервалу эти данные соответствуют - редко когда значения отличающиеся на несколько порядков имеют подобное распределение (тем более по уровню дохода обычно клиенты делятся на несколько групп - условно средний доход, ниже/выше среднего, сверхбогатые, бедные и т.д.). \n",
    "\n",
    "Учитывая также то, что указанный атрибут имеет наименьшие значения коэффициентов корреляции со всеми другими признаками (не выше 0.01), на этапе обучения следует учесть эту информацию при формировании обучающих признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `tenure` - количество недвижимости у клиента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_column_numeric('tenure', 'Количество недвижимости у клиента')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Признак количества недвижимости у клиента - единственный в исходной выборке - содержит пропуски значений (порядка 10% от всей выборки). \n",
    "\n",
    "Значения количества объектов недвижимости находятся в диапазоне от 0 до 10. Распределение значений во многом совпадает как для действующих, так и ушедших клиентов, с практическими равными медианными значениями и близкими значениями межквартильного размаха.\n",
    "\n",
    "Рассмотрим некоторые способы заполнения пропусков в указанных значениях."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Заполнение пропусков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заполнение пропусков будем делать с помощью модуля `impute` библиотеки `sklearn`. Применение объектов указанного модуля позволит в последующем строить процесс заполнения пропусков в единую цепочку (pipeline) преобразования, обучения и валидации модели.\n",
    "\n",
    "Методы заполнения пропусков будем рассматривать на всей исходной выборке (с целью оценки влияния различных способов на общее распределение). Исключим из выборки целевой и строковые признаки. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = df_churn.drop(['exited', 'geography', 'gender'], axis=1)\n",
    "X_all.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим способы замены пропусков на фиксированное значение. \n",
    "\n",
    "Первый способ - замена на медиану."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция замены пропусков значений с помощью передаваемого алгоритам\n",
    "# (объекта sklearn.impute)\n",
    "# imp - алгоритм замены пропусков\n",
    "def make_inputation(imp):\n",
    "    imputed_df = imp.fit_transform(X_all)\n",
    "\n",
    "    imputed_df = pd.DataFrame(imputed_df, columns=X_all.columns, index=df_churn.index)\n",
    "    imputed_df['exited'] = df_churn['exited']\n",
    "    imputed_df.head(5)\n",
    "    \n",
    "    return imputed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_df = make_inputation(SimpleImputer(missing_values=np.nan, strategy='median'))\n",
    "\n",
    "describe_column_numeric('tenure', 'Количество недвижимости у клиента', imputed_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очевидным образом указанный способ сильно влияет на распределение - доля значений, равных медианному существенно возрастает, межквартильные размахи уменьшаются."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Второй способ - с помощью модели решающего дерева"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_df = make_inputation(\n",
    "    IterativeImputer(\n",
    "        max_iter=5, random_state=random_magic, \n",
    "        estimator=DecisionTreeClassifier(max_depth=10, random_state=random_magic))\n",
    ")\n",
    "\n",
    "describe_column_numeric('tenure', 'Количество недвижимости у клиента', imputed_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Указанный способ более равномерно относительно замены на медиану заполняет пропуски в значениях количества объектов недвижимости. Вместе с тем, доля значений равных 1 и 2 все-таки увеличивается относительно остальных значений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Третий способ - с помощью модели случайного леса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tenure_imputer = IterativeImputer(\n",
    "        max_iter=5, random_state=random_magic, \n",
    "        estimator=RandomForestClassifier(n_estimators = 10, max_depth=10, random_state=random_magic))\n",
    "\n",
    "imputed_df = make_inputation(tenure_imputer)\n",
    "\n",
    "describe_column_numeric('tenure', 'Количество недвижимости у клиента', imputed_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Указанный способ еще более равномерно осуществил вставку пропусков значений признака `tenure`. Характер распределений относительно исходной выборки практически не изменился (немного расширились границы межквартильного размаха).\n",
    "\n",
    "Также проверим отсутствие увеличения корреляции между признаком `tenure` и остальными признаками. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#для сравнения: до заполнения пропусков\n",
    "#tenure           0.027232       0.032178      0.011979 1.000000    0.000062 0.013134  0.007911    0.010520 -0.016761"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_corr_table(imputed_df.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Указанный способ вставки пропусков следует рассматривать в качестве основного в процессе обучения моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Формирование дополнительных (производных) признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На основе проведенной выше оценки значений числовых признаков сформируем некоторые дополнительные признаки:\n",
    "- `max_credit_score` - признак достижения максимального кредитного рейтинга (условие: равенство кредитного рейтинга 850)\n",
    "- `balance_overdraft` - признак отсутствия собственных средств клиента на балансе в банке (условие: равенство баланса 0)\n",
    "- `products_category` - категория клиента по числу используемых продуктов банка (3 категории: 1, 2, 3 и более)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_churn['max_credit_score'] = (df_churn['credit_score'] == 850).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_churn['balance_overdraft'] = (df_churn['balance'] == 0). astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_churn['products_category'] = df_churn.apply(\n",
    "    lambda row: 1 if row['num_of_products'] == 1 else (\n",
    "        2 if row['num_of_products'] == 2 else 3\n",
    "    ),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_churn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Указанные признаки можно использовать на этапе обучения и подбора параметров моделей.\n",
    "\n",
    "Проверим корреляцию производных и исходных признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_corr_table(df_churn.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следует отметить, что производные признаки сильно коррелируют с исходными:\n",
    "- `products_category` и `num_of_products` - 0.99\n",
    "- `balance_overdraft` и `balance` - 0.92\n",
    "\n",
    "Соответственно для модели логистической регрессии необходимо будет оставить один из этих признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исходные данные представлены в виде 1 таблицы с информацией о клиентах банка - их возрасте, уровне дохода, кредитном рейтинге, активности внутри банка и т.д.\n",
    "\n",
    "В исходной таблице представлены вещественные, строковые и целочисленные атрибуты. Часть признаков - категориальные (как бинарные признаки, так и отдельные строковые признаки - страна проживания и пол).\n",
    "\n",
    "В рамках предварительной обработки выполнены следующие этапы:\n",
    "- данные о клиентах обезличены\n",
    "- выполнено приведение типов (из вещественного в целочисленный)\n",
    "- выполнено приведение названий атрибутов из `CamelCase` в `snake_case`\n",
    "- проведена оценка корреляции исходных признаков - по результатам оценки сильно коррелирующих исходных признаков не выявлено\n",
    "- проведена оценка распределения категориальных и числовых признаков, на основе которой сделаны предположения по формированию производных признаков:\n",
    "    - `max_credit_score` - признак достижения максимального кредитного рейтинга (условие: равенство кредитного рейтинга 850)\n",
    "    - `balance_overdraft` - признак отсутствия собственных средств клиента на балансе в банке (условие: равенство баланса 0)\n",
    "    - `products_category` - категория клиента по числу используемых продуктов банка (3 категории: 1, 2, 3 и более)\n",
    "- проведена оценка корреляции предложенных признаков с исходными\n",
    "- рассмотрены алгоритмы заполнения пропусков в значениях атрибута `tenure` (количество недвижимости у клиента) и выбран один, в наименьшей степени изменяющий исходное распределение \n",
    "\n",
    "Данные подготовлены для последующего изучения и преобразования в соответствии с требованиями моделей обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Исследование задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оценка сбалансированности целевых классов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим соотношения классов в целевом признаке. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_churn['exited'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "К положительному классу отнесем значение \"1\" (ушедшие клиенты). Доля значений положительного класса - 20%. \n",
    "\n",
    "Классы целевого признака несбаллансированы. С учетом дисбаланса обучение моделей будем проводить в несколько этапов:\n",
    "- на первом этапе:\n",
    "    - сформируем обучающую и тестовую выборки\n",
    "    - рассмотрим различные варианты подготовки обучающих признаков\n",
    "- на втором этапе:\n",
    "    - для выбранных моделей (логистическая регрессия, решающее дерево, случайный лес) проведем обучение с перебором гиперпараметров на каждом из подготовленных наборов обучающих признаков\n",
    "    - проведем оценку полученных результатов (значений метрик на тестовом наборе данных)\n",
    "- на третьем этапе применим различные подходы по устранению дисбаланса и повторно проведем обучение моделей, показавших наилучшие результаты на этапе обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разбиение данных на обучающую и тестовую выборки "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку данные для обучения и тестирования модели представлены в виде одной таблицы (т.е. скрытая тестовая выборка отсутствует), необходимо разбить исходные данные на две части: \n",
    "- обучающую (`train`): используется для обучения модели\n",
    "- тестовую (`test`): используется для окончательной проверки точности модели\n",
    "\n",
    "Выделение валидационной выборки (`valid`) не требуется, поскольку при обучении для проверки моделей будем применять кросс-валидацию.\n",
    "\n",
    "Разобьем исходные данные случайным образом в следующем соотношении: 4:1. Учитывая то, что нами решается задача построения модели бинарной классификации, при разбиении воспользуемся принципом стратифицированной рандомизации: сохраним соотношение пользователей по целевому признаку во всех выборках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция разбиения данных на 2 выборки в пропорции 4:1\n",
    "# при разбиении соблюдается принцип стратифицированной рандомизации по переданному параметру\n",
    "# df_source - dataframe с исходными данными\n",
    "# stratify_attr - название атрибута стратификации\n",
    "\n",
    "def split_data(df_source, stratify_attr, test_size=0.20):\n",
    "    df_train, df_test = train_test_split(\n",
    "        df_source, test_size=test_size, random_state=random_magic, stratify=df_source[stratify_attr]\n",
    "    )\n",
    "\n",
    "    return df_train.copy(), df_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = split_data(df_churn, 'exited')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверяем, что соотношение сохранилось."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['exited'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка данных для обучения моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В рамках этапа подготовки данных для обучения моделей выполним следующие шаги:\n",
    "- выделим целевой признак\n",
    "- определим возможные наборы обучающих признаков\n",
    "- формирование pipeline предобработки обучающих признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Определение обучающих и целевого признака"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим массив со значениями обучающих и целевого признака"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['geography', 'gender', 'has_cr_card', 'is_active_member',\n",
    "            'num_of_products', 'tenure', 'credit_score', 'age',  \n",
    "            'balance', 'estimated_salary']\n",
    "target = ['exited']\n",
    "\n",
    "features_impute = ['has_cr_card', 'is_active_member',\n",
    "                    'num_of_products', 'tenure', 'credit_score', 'age',  \n",
    "                    'balance', 'estimated_salary']\n",
    "\n",
    "features_category = ['geography', 'gender']\n",
    "\n",
    "features_passthrough = ['has_cr_card', 'is_active_member']\n",
    "\n",
    "features_discrete = ['num_of_products', 'tenure']\n",
    "\n",
    "features_numeric = ['credit_score', 'age', 'balance', 'estimated_salary']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполним заполнение пропусков признака `tenure` с помощью рассмотренного выше алгоритма."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_imputed(df):\n",
    "    imputed_df = tenure_imputer.fit_transform(df[features_impute])\n",
    "\n",
    "    imputed_df = pd.DataFrame(imputed_df, index=df.index)\n",
    "    imputed_df.columns = features_impute\n",
    "\n",
    "    df['tenure'] = imputed_df['tenure']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = get_imputed(df_train)\n",
    "df_test = get_imputed(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим dataframe со значениями обучающих и целевого признака в выборках train и test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция формирования совокупности наборов данных: обучающие и целевые признаки обучающего и тестового \n",
    "# наборов данных\n",
    "# features - перечень обучающих признаков\n",
    "# target - перечень целевых признаков\n",
    "# df_train - обучающий набор данных\n",
    "# df_test - тестовый набор данных\n",
    "def get_train_test_X_Y(features, target, df_train, df_test):\n",
    "    return df_train[features], df_train[target].values.ravel(), df_test[features], df_test[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_test, Y_test = get_train_test_X_Y(features, target, df_train, df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Формирование pipeline для подготовки обучающих признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим несколько способов формирования состава обучающих признаков:\n",
    "- в качестве базового сценария рассмотрим исходный набор признаков и применением прямого кодирования категориальных признаков\n",
    "- далее добавим масштабирование числовых признаков\n",
    "- в качестве отдельного сценария рассмотрим видоизмененный состав обучающих признаков (с добавлением производных признаков)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Базовый pipeline подготовки обучающих признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В базовом сценарии подготовки обучающих признаков необходимо выполнить прямое кодирование (OHE) рассмотренных выше категориальных признаков:\n",
    "- `gender` - пол\n",
    "- `geography` - страна проживания\n",
    "\n",
    "Остальные признаки оставим без изменений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция формирования pipeline из передаваемых компонент:\n",
    "# preprocessor - преобразователь обучающих признаков\n",
    "# model (по умолчанию None) - обучающая модель\n",
    "def make_pipeline(preprocessor, model = None):\n",
    "    if (model is None):\n",
    "        return Pipeline(\n",
    "            steps=[\n",
    "                ('preprocessor', preprocessor),\n",
    "            ]\n",
    "        )\n",
    "    else:\n",
    "        return Pipeline(\n",
    "            steps=[\n",
    "                ('preprocessor', preprocessor),\n",
    "                ('model', model)\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В преобразователь признаков добавим OneHotEncoder библиотеки sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# объединение преобразователей признаков в один трансформер\n",
    "preprocessor_opt1 = ColumnTransformer(\n",
    "    remainder='passthrough',\n",
    "    transformers=[\n",
    "        # преобразователь категориальных признаков - прямое кодирование OHE (с удалением первого генерируемого признака)\n",
    "        ('cat', OneHotEncoder(handle_unknown='error', drop='first'), features_category),\n",
    "    ])\n",
    "\n",
    "pipeline_dt = make_pipeline(preprocessor_opt1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполним этап предобработки данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция преобразования передаваемого dataframe с обучающими признаками\n",
    "# pipeline - pipeline преобразования (предобработки) обучающих признаков \n",
    "# выходной параметр - dataframe с преобразованным набором обучающих признаков \n",
    "# (фактически - исходные данные для последующего обучения модели)\n",
    "def get_transformed_data(pipeline, X_train):\n",
    "    X_transformed = pipeline.fit_transform(X_train)\n",
    "    X_transformed = pd.DataFrame(X_transformed, index=X_train.index)\n",
    "    X_transformed = X_transformed.add_prefix('Xt_')\n",
    "    \n",
    "    return X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transformed = get_transformed_data(pipeline_dt, X_train)\n",
    "\n",
    "X_transformed.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names_opt1 = ['geography_ohe_1', 'geography_ohe_2', 'gender_ohe_1', 'has_cr_card', \n",
    "                     'is_active_member', 'num_of_products', 'tenure', 'credit_score', 'age',  \n",
    "                     'balance', 'estimated_salary']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В результате применения указанных преобразований получены ожидаемые результаты:\n",
    "- признак `geography` путем прямого кодирования (OHE) преобразован в два признака (Xt_0 и Xt_1)\n",
    "- признак `gender` путем прямого кодирования (OHE) преобразован в один признак (Xt_2)\n",
    "\n",
    "Остальные признаки перенесены без изменений.\n",
    "\n",
    "Также проверим отсутствие после выполнения преобразований сильных корреляций между признаками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_corr_table(X_transformed.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Увеличилась корреляция между страновым признаком и балансом - 0.40 (в сравнее с 0.07 между балансом и исходным признаком с кодами стран).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pipeline с добавлением масштабирования числовых признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим в сформированный pipeline предобработки операции масштабирования числовых признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# объединение преобразователей признаков в один трансформер\n",
    "preprocessor_opt2 = ColumnTransformer(\n",
    "    remainder='drop',\n",
    "    transformers=[\n",
    "        # преобразователь категориальных признаков - прямое кодирование OHE (с удалением первого генерируемого признака)\n",
    "        ('cat', OneHotEncoder(handle_unknown='error', drop='first'), features_category),\n",
    "        ('pass', 'passthrough', features_passthrough),\n",
    "        ('scl1', StandardScaler(copy=False, with_mean=True, with_std=True), features_discrete),\n",
    "        ('scl2', StandardScaler(copy=False, with_mean=True, with_std=True), features_numeric), \n",
    "    ])\n",
    "\n",
    "pipeline_dt = make_pipeline(preprocessor_opt2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполним этап предобработки данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transformed = get_transformed_data(pipeline_dt, X_train)\n",
    "\n",
    "X_transformed.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names_opt2 = ['geography_ohe_1', 'geography_ohe_2', 'gender_ohe_1', 'has_cr_card', 'is_active_member',\n",
    "                     'num_of_products_scaled', 'tenure_scaled', 'credit_score_scaled', 'age_scaled',  \n",
    "                     'balance_scaled', 'estimated_salary_scaled']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В результате применения указанных преобразований получены ожидаемые результаты:\n",
    "- признак `geography` путем прямого кодирования (OHE) преобразован в два признака (Xt_0 и Xt_1)\n",
    "- признак `gender` путем прямого кодирования (OHE) преобразован в один признак (Xt_2)\n",
    "- признаки `has_cr_card` и `is_active_member` оставлены без изменений (Xt_3 и Xt_4)\n",
    "- к каждому из числовых признаков `num_of_products`, `tenure`, `credit_score`, `age`, `balance` и `estimated_salary` применено масштабирование (StandardScaler) - (Xt_5, Xt_6, Xt_7, Xt_8, Xt_9, Xt_10)\n",
    "\n",
    "Также проверим отсутствие после выполнения преобразований сильных корреляций между признаками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print_corr_table(X_transformed.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pipeline с добавлением производных признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сформировуем отдельный pipeline предобработки обучающих признаков, расширенных производными признаками:\n",
    "- исключим признак `estimated_salary`\n",
    "- вместо числового признака `num_of_prodcuts` введем категориальный признак `products_category` и применим к нему прямое кодирование\n",
    "- добавим бинарные признаки `max_credit_score` и `balance_overdraft`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_opt3 = ['geography', 'gender', 'products_category', \n",
    "            'has_cr_card', 'is_active_member', 'max_credit_score', 'balance_overdraft',\n",
    "            'tenure', 'credit_score', 'age', 'balance',\n",
    "           ]\n",
    "\n",
    "features_category_opt3 = ['geography', 'gender', 'products_category']\n",
    "\n",
    "features_passthrough_opt3 = ['has_cr_card', 'is_active_member', 'max_credit_score', 'balance_overdraft']\n",
    "\n",
    "features_discrete_opt3 = ['tenure']\n",
    "\n",
    "features_numeric_opt3 = ['credit_score', 'age', 'balance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_test, Y_test = get_train_test_X_Y(features_opt3, target, df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# объединение преобразователей признаков в один трансформер\n",
    "preprocessor_opt3 = ColumnTransformer(\n",
    "    remainder='drop',\n",
    "    transformers=[\n",
    "        # преобразователь категориальных признаков - прямое кодирование OHE (с удалением первого генерируемого признака)\n",
    "        ('cat', OneHotEncoder(handle_unknown='error', drop='first'), features_category_opt3),\n",
    "        ('pass', 'passthrough', features_passthrough_opt3),\n",
    "        ('scl1', StandardScaler(copy=False, with_mean=True, with_std=True), features_discrete_opt3),\n",
    "        ('scl2', StandardScaler(copy=False, with_mean=True, with_std=True), features_numeric_opt3), \n",
    "    ])\n",
    "\n",
    "pipeline_dt = make_pipeline(preprocessor_opt3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполним этап предобработки данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transformed = get_transformed_data(pipeline_dt, X_train)\n",
    "\n",
    "X_transformed.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names_opt3 = ['geography_ohe_1', 'geography_ohe_2', 'gender_ohe_1', \n",
    "                     'products_category_ohe_1', 'products_category_ohe_2', \n",
    "                     'has_cr_card', 'is_active_member', 'max_credit_score', 'balance_overdraft', \n",
    "                     'tenure_scaled', 'credit_score_scaled', 'age_scaled',  \n",
    "                     'balance_scaled']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В результате применения указанных преобразований получены ожидаемые результаты:\n",
    "- признак `geography` путем прямого кодирования (OHE) преобразован в два признака (Xt_0 и Xt_1)\n",
    "- признак `gender` путем прямого кодирования (OHE) преобразован в один признак (Xt_2)\n",
    "- признак `products_category` путем прямого кодирования (OHE) преобразован в два признака (Xt_3 и Xt_4)\n",
    "- признаки `has_cr_card`, `is_active_member`, `max_credit_score` и `balance_overdraft` оставлены без изменений (Xt_5, Xt_6, Xt_7 и Xt_8)\n",
    "- к каждому из числовых признаков `tenure`, `credit_score`, `age` и `balance` применено масштабирование (StandardScaler) - (Xt_9, Xt_10, Xt_11 и Xt_12)\n",
    "\n",
    "Также проверим отсутствие после выполнения преобразований сильных корреляций между признаками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print_corr_table(X_transformed.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Учитывая высокое значение коэффициента корреляции между признаками `balance` и `balance_overdraft` (после преобразований - 0.92) для модели логистической регрессии следует исключить производный признак `balance_overdraft`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_passthrough_opt3_lr = ['has_cr_card', 'is_active_member', 'max_credit_score']\n",
    "\n",
    "preprocessor_opt3_lr = ColumnTransformer(\n",
    "    remainder='drop',\n",
    "    transformers=[\n",
    "        # преобразователь категориальных признаков - прямое кодирование OHE (с удалением первого генерируемого признака)\n",
    "        ('cat', OneHotEncoder(handle_unknown='error', drop='first'), features_category_opt3),\n",
    "        ('pass', 'passthrough', features_passthrough_opt3_lr),\n",
    "        ('scl1', StandardScaler(copy=False, with_mean=True, with_std=True), features_discrete_opt3),\n",
    "        ('scl2', StandardScaler(copy=False, with_mean=True, with_std=True), features_numeric_opt3), \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names_opt3_lr = ['geography_ohe_1', 'geography_ohe_2', 'gender_ohe_1', \n",
    "                     'products_category_ohe_1', 'products_category_ohe_2', \n",
    "                     'has_cr_card', 'is_active_member', 'max_credit_score', \n",
    "                     'tenure_scaled', 'credit_score_scaled', 'age_scaled', 'balance_scaled']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В рамках проведенного изучения исходных данных и уточнения задач исследования выполнены следующие шаги:\n",
    "- определен целевой признак\n",
    "- сформированы 3 набора обучающих признаков и для каждого из них сформирован pipeline преобразований данных, который может быть использован в качестве элемента единого pipeline обработки данных и обучения моделей\n",
    "- для каждого набора признаков по результатам применения преобразований проведена оценка корреляции значений, поступающих непосредственно в качестве исходных данных для обучения моделей\n",
    "\n",
    "Полученные результаты позволяют перейти к этапу обучения моделей и сравнения их параметров."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На основе рассмотренных выше преобразований исходных обучающих признаков проведем последовательное обучение моделей логистической регресси, решающего дерева и случайного леса и сравним полученные значения метрики F1.\n",
    "\n",
    "В рамках обучения каждой модели выполняются следующие шаги:\n",
    "- формируется единый pipeline, состоящий из этапов предобработки и обучения моделей (с перебором гиперпараметров)\n",
    "- рассчет метрик на тестовых данных и оценка полученных параметров моделей \n",
    "\n",
    "При выводе результатов модели, показавшие значение метрики F1 на тестовых данных выше целевого (0.59), отобразим с графиком ROC-кривой в зеленом цвете. Модели, показавшие значение метрики F1 в диапазоне (0,56 - 0,59) - с графиком ROC-кривой в красном цвете. По остальным моделям значения метрик выведем только в виде текста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# политика разбиения на фолды при кросс-валидации: число фолдов - 8, со стратификацией\n",
    "cv = StratifiedKFold(8, random_state=random_magic, shuffle=True)\n",
    "\n",
    "# мера, используемая при кросс-валидации - F1, положительный класс - значение '1' (ушедшие клиенты)\n",
    "#scoring = make_scorer(f1_score, labels=['1'])\n",
    "scoring = make_scorer(roc_auc_score, labels=['1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_test, Y_test = get_train_test_X_Y(features, target, df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_opt3, Y_train_opt3, X_test_opt3, Y_test_opt3 = get_train_test_X_Y(features_opt3, target, df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция печати \n",
    "def print_scores(grid_search, params, X_test, Y_test, print_plot=False):\n",
    "    print ('Best score: %0.3f' % grid_search.best_score_)\n",
    "    print ('Best parameters set:')\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    \n",
    "    for param_name in sorted(params.keys()):\n",
    "        print ('\\t%s: %r' % (param_name, best_parameters[param_name]))\n",
    "\n",
    "    predictions = grid_search.predict(X_test)\n",
    "    \n",
    "    probabilities_valid = grid_search.predict_proba(X_test)\n",
    "    probabilities_one_valid = probabilities_valid[:, 1]\n",
    "\n",
    "    f1_val = f1_score(Y_test, predictions)\n",
    "    roc_auc_val = roc_auc_score(Y_test, probabilities_one_valid)\n",
    "    \n",
    "    print(colored(\"\\x1b[1mF1: {0}\\x1b[0m\".format(f1_val), 'red' if f1_val < 0.59 else 'green'))\n",
    "    print('AUC-ROC:', roc_auc_val)\n",
    "    print('Precision:', precision_score(Y_test, predictions))\n",
    "    print('Recall:', recall_score(Y_test, predictions))\n",
    "    print('Accuracy:', accuracy_score(Y_test, predictions))\n",
    "    \n",
    "    if f1_val >= 0.56 or print_plot:\n",
    "        fpr, tpr, thresholds = roc_curve(Y_test, probabilities_one_valid) \n",
    "\n",
    "        df_roc_auc = pd.DataFrame()\n",
    "        df_roc_auc['fpr'] = fpr\n",
    "        df_roc_auc['tpr'] = tpr\n",
    "        df_roc_auc['thresholds'] = thresholds\n",
    "        df_roc_auc['color'] = 'red'\n",
    "        \n",
    "        if f1_val >= 0.59:\n",
    "            df_roc_auc['color'] = 'green'\n",
    "            print_roc_auc_plot(df_roc_auc, roc_auc_val, 'green')\n",
    "        else:\n",
    "            print_roc_auc_plot(df_roc_auc, roc_auc_val, 'red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим функцию перебора гиперпараметров и обучения модели с последующим выводом параметров наилучшей модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция обучения модели с перебором гиперпараметров\n",
    "# pipeline - общий pipeline (предобработка данных и модель)\n",
    "# params - гиперпараметры модели\n",
    "# X_train - dataframe с обучающими признаками обучающей выборки\n",
    "# Y_train - dataframe с целевым признаком обучающей выборки\n",
    "# X_test - dataframe с обучающими признаками тестовой выборки\n",
    "# Y_test - dataframe с целевым признаком тестовой выборки\n",
    "def make_grid_search(pipeline, params, X_train, Y_train, X_test, Y_test, print_plot=False):\n",
    "    grid_search = GridSearchCV(\n",
    "        pipeline, \n",
    "        param_grid=params, \n",
    "        cv=cv, \n",
    "        #scoring=scoring\n",
    "        scoring='roc_auc',\n",
    "    )    \n",
    "\n",
    "    grid_search.fit(X_train, Y_train)\n",
    "\n",
    "    print_scores(grid_search, params, X_test, Y_test, print_plot)\n",
    "    \n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим функцию вывода параметров наилучшей модели по результатам перебора гиперпараметров, а также значения различных метрик по результатам тестирования модели на тестовых данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция печати графика ROC-кривой\n",
    "# df_roc_auc - dataframe исходных данных для построения графика ROC-кривой (значения TPR, FPR и пороговые отсечки)\n",
    "# roc_auc_val - значение метрики ROC-AUC\n",
    "# color - цвет отображения\n",
    "def print_roc_auc_plot(df_roc_auc, roc_auc_val, color):\n",
    "    fig = px.area(\n",
    "        df_roc_auc,\n",
    "        x='fpr', y='tpr',\n",
    "        title=f'ROC-кривая (AUC={roc_auc_val:.4f})',\n",
    "        width=900, \n",
    "        height=500,\n",
    "        color='color',\n",
    "        color_discrete_map={\n",
    "                'red': 'Red', 'green': 'Green'\n",
    "            },\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[0, 1], \n",
    "            y=[0, 1], \n",
    "            name=\"Случайная модель\",\n",
    "            line=dict(color=color, width=2, dash='dash'),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.update_yaxes(scaleanchor=\"x\", scaleratio=0.9)\n",
    "    fig.update_xaxes(constrain='domain')\n",
    "    fig.update_layout(xaxis_title='FPR (доля ложноположительных)', yaxis_title='TPR (доля истинно положительных)')\n",
    "    fig.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим модель и выполним перебор значений гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = LogisticRegression(random_state=random_magic, max_iter=5000, solver='liblinear')\n",
    "\n",
    "param_grid_lr = {\n",
    "    'model__C': [100, 10, 1.0, 0.1, 0.01],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_result = make_grid_search(\n",
    "    make_pipeline(preprocessor_opt1, model_lr), \n",
    "    param_grid_lr, \n",
    "    X_train, Y_train, X_test, Y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_result = make_grid_search(\n",
    "    make_pipeline(preprocessor_opt2, model_lr), \n",
    "    param_grid_lr, \n",
    "    X_train, Y_train, X_test, Y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_result = make_grid_search(\n",
    "    make_pipeline(preprocessor_opt3_lr, model_lr), \n",
    "    param_grid_lr, \n",
    "    X_train_opt3, Y_train_opt3, X_test_opt3, Y_test_opt3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Выводы\n",
    "\n",
    "Максимальное значение метрики F1 модели логистической регрессии получено на наборе данных с добавлением производных признаков. Вместе с тем, полученное значение (0,49) далеко от целевого (0,59)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Решающее дерево"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dtc = DecisionTreeClassifier(random_state=random_magic)\n",
    "\n",
    "param_grid_dtc = {\n",
    "    'model__max_depth': [3, 5, 10, 15],\n",
    "    'model__min_samples_split': [2, 3, 4, 5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_result = make_grid_search(\n",
    "    make_pipeline(preprocessor_opt1, model_dtc), \n",
    "    param_grid_dtc, \n",
    "    X_train, Y_train, X_test, Y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_result = make_grid_search(\n",
    "    make_pipeline(preprocessor_opt2, model_dtc), \n",
    "    param_grid_dtc, \n",
    "    X_train, Y_train, X_test, Y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_result = make_grid_search(\n",
    "    make_pipeline(preprocessor_opt3, model_dtc), \n",
    "    param_grid_dtc, \n",
    "    X_train_opt3, Y_train_opt3, X_test_opt3, Y_test_opt3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Выводы\n",
    "\n",
    "На каждом из наборов данных модель решающего дерева показала неплохое значение метрики F1 (0.56-0.57). Максимальное значение метрики F1 и наилучшее значение метрики ROC-AUC (а также наиболее выпуклый вид ROC-кривой) также получено на наборе данных с добавлением производных признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Случайный лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rfc = RandomForestClassifier(random_state=random_magic)\n",
    "\n",
    "param_grid_rfc = {\n",
    "    'model__n_estimators': [10, 20, 30, 50],\n",
    "    'model__max_depth': [7, 10, 15],\n",
    "    'model__min_samples_split': [2, 3, 4]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_result = make_grid_search(\n",
    "    make_pipeline(preprocessor_opt1, model_rfc), \n",
    "    param_grid_rfc, \n",
    "    X_train, Y_train, X_test, Y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_result = make_grid_search(\n",
    "    make_pipeline(preprocessor_opt2, model_rfc), \n",
    "    param_grid_rfc, \n",
    "    X_train, Y_train, X_test, Y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_result = make_grid_search(\n",
    "    make_pipeline(preprocessor_opt3, model_rfc), \n",
    "    param_grid_rfc, \n",
    "    X_train_opt3, Y_train_opt3, X_test_opt3, Y_test_opt3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Выводы\n",
    "\n",
    "На каждом из наборов данных модель случайного леса показала неплохое значение метрики F1 (0.56-0.58). Максимальное значение метрики F1 и наилучшее значение метрики ROC-AUC (а также наиболее выпуклый вид ROC-кривой) получено на базовом наборе данных (исходный набор с прямым кодированием категориальных признаков)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По результатам обучения моделей (без учета наличия дисбаланса в классах целевого признака) получены следующие результаты:\n",
    "- наилучшие значения метрики F1 (0.56 - 0.58) получены для моделей случайного леса и решающего дерева (на разных наборах обучающих признаков), при этом значения метрики AUC-ROC для моделей случайного леса выше, а график ROC-кривой более выпуклый и пологий\n",
    "- максимальное значение метрики F1 модели логистической регрессии получено на наборе данных с добавлением производных признаков, но полученное значение (0,49) далеко от целевого (0,59)\n",
    "\n",
    "С учетом полученных результатов целесообразно провести балансировку целевых классов с целью возможного улучшения значений рассматриваемых метрик."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Балансировка целевых классов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С целью увеличения значений метрики F1 рассматриваемых моделей попробуем выполнить балансировку целевых классов. Балансировку выполним тремя различными способами:\n",
    "- взвешивание\n",
    "- увеличение обучающей выборки\n",
    "- уменьшение обучающей выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Взвешивание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Укажем значением атрибута `class_weight` значение `balanced` для всех рассматриваемых моделей. Указанный параметр позволит моделям увеличить вес положительного класса на основе имеющих соотношений (примерно 4:1, разделение на обучающую и тестовую выборку выполнялось со стратификацией).\n",
    "\n",
    "На этом этапе будем рассматривать те модели из каждого класса, которые показали наилучшие значения на первом этапе обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = LogisticRegression(random_state=random_magic, max_iter=5000, solver='liblinear', class_weight='balanced')\n",
    "\n",
    "param_grid_lr = {\n",
    "    'model__C': [100, 10, 1.0],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_result = make_grid_search(\n",
    "    make_pipeline(preprocessor_opt2, model_lr), \n",
    "    param_grid_lr, \n",
    "    X_train, Y_train, X_test, Y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_result = make_grid_search(\n",
    "    make_pipeline(preprocessor_opt3_lr, model_lr), \n",
    "    param_grid_lr, \n",
    "    X_train_opt3, Y_train_opt3, X_test_opt3, Y_test_opt3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выводы**\n",
    "\n",
    "Максимальное значение метрики F1 модели логистической регрессии получено на наборе данных с добавлением производных признаков. Полученное значение (0.55) выше, чем для несбалансированных классов, но вместе с тем также достаточно далеко от целевого (0,59)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Решающее дерево"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dtc = DecisionTreeClassifier(random_state=random_magic, class_weight='balanced')\n",
    "\n",
    "param_grid_dtc = {\n",
    "    'model__max_depth': [3, 4, 5, 7, 10],\n",
    "    'model__min_samples_split': [2, 3, 4, 5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_result = make_grid_search(\n",
    "    make_pipeline(preprocessor_opt2, model_dtc), \n",
    "    param_grid_dtc, \n",
    "    X_train, Y_train, X_test, Y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_result = make_grid_search(\n",
    "    make_pipeline(preprocessor_opt3, model_dtc), \n",
    "    param_grid_dtc, \n",
    "    X_train_opt3, Y_train_opt3, X_test_opt3, Y_test_opt3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выводы**\n",
    "\n",
    "Значения метрики F1 на каждом из наборов данных увеличилось, на наборе данных с добавлением производных признаков практически достигнут целевой показатель - 0.587. Значение метрики ROC-AUC - 0.83, график ROC-кривой выпуклый, практически без резких скачкообразных изменений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Случайный лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rfc = RandomForestClassifier(random_state=random_magic, class_weight='balanced')\n",
    "\n",
    "param_grid_rfc = {\n",
    "    'model__n_estimators': [20, 30, 50],\n",
    "    'model__max_depth': [7, 10, 15],\n",
    "    'model__min_samples_split': [2, 3, 4]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_result = make_grid_search(\n",
    "    make_pipeline(preprocessor_opt2, model_rfc), \n",
    "    param_grid_rfc, \n",
    "    X_train, Y_train, X_test, Y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_result = make_grid_search(\n",
    "    make_pipeline(preprocessor_opt3, model_rfc), \n",
    "    param_grid_rfc, \n",
    "    X_train_opt3, Y_train_opt3, X_test_opt3, Y_test_opt3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выводы**\n",
    "\n",
    "На обоих рассматриваемых наборах обучающих признаков модель случайного леса превысила целевой параметр метрики F1 (0.59) - получены значения 0.62 и 0.61.\n",
    "\n",
    "Максимальное значение метрики F1 и наилучшее значение метрики ROC-AUC (а также наиболее выпуклый вид ROC-кривой) получено на базовом наборе данных с добавлением масштабирования численных признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Увеличение выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Увеличим в обучающей выборке (техника upsample) долю объектов положительного класса в 4 раза, перемешаем полученные данные и передадим их в качестве новой обучающей выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_zeros = df_train.loc[df_train['exited'] == 0]\n",
    "features_ones = df_train.loc[df_train['exited'] == 1]\n",
    "\n",
    "features_upsampled = pd.concat([features_zeros] + [features_ones] * 4)\n",
    "\n",
    "features_upsampled = shuffle(features_upsampled, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_upsampled['exited'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Баланс классов соблюден (1:1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_test, Y_test = get_train_test_X_Y(features, target, features_upsampled, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_opt3, Y_train_opt3, X_test_opt3, Y_test_opt3 = get_train_test_X_Y(features_opt3, target, features_upsampled, df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = LogisticRegression(random_state=random_magic, max_iter=5000, solver='liblinear')\n",
    "\n",
    "param_grid_lr = {\n",
    "    'model__C': [100, 10, 1.0],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_result = make_grid_search(\n",
    "    make_pipeline(preprocessor_opt3_lr, model_lr), \n",
    "    param_grid_lr, \n",
    "    X_train_opt3, Y_train_opt3, X_test_opt3, Y_test_opt3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выводы**\n",
    "\n",
    "Максимальное значение метрики F1 модели логистической регрессии получено на наборе данных с добавлением производных признаков. \n",
    "Полученное значение (0.55) выше, чем для несбалансированных классов, и совпадает со значением, полученным при взвешивании классов. Значение метрики достаточно далеко от целевого (0,59)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Решающее дерево"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dtc = DecisionTreeClassifier(random_state=random_magic)\n",
    "\n",
    "param_grid_dtc = {\n",
    "    'model__max_depth': [3, 4, 5, 7, 10],\n",
    "    'model__min_samples_split': [2, 3, 4, 5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_result = make_grid_search(\n",
    "    make_pipeline(preprocessor_opt2, model_dtc), \n",
    "    param_grid_dtc, \n",
    "    X_train, Y_train, X_test, Y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_result = make_grid_search(\n",
    "    make_pipeline(preprocessor_opt3, model_dtc), \n",
    "    param_grid_dtc, \n",
    "    X_train_opt3, Y_train_opt3, X_test_opt3, Y_test_opt3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выводы**\n",
    "\n",
    "Значения метрики F1 на каждом из наборов данных увеличилось по сравнению с несбалансированными классами, но уменьшилось в сравнении с техникой взвешивания. Целевой показатель метрики F1 не достигнут."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Случайный лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rfc = RandomForestClassifier(random_state=random_magic)\n",
    "\n",
    "param_grid_rfc = {\n",
    "    'model__n_estimators': [20, 30, 50],\n",
    "    'model__max_depth': [7, 10, 15],\n",
    "    'model__min_samples_split': [2, 3, 4]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_result = make_grid_search(\n",
    "    make_pipeline(preprocessor_opt2, model_rfc), \n",
    "    param_grid_rfc, \n",
    "    X_train, Y_train, X_test, Y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_result = make_grid_search(\n",
    "    make_pipeline(preprocessor_opt3, model_rfc), \n",
    "    param_grid_rfc, \n",
    "    X_train_opt3, Y_train_opt3, X_test_opt3, Y_test_opt3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выводы**\n",
    "\n",
    "На обоих рассматриваемых наборах обучающих признаков модель случайного леса превысила целевой параметр метрики F1 (0.59) - получены значения 0.595 и 0.61.\n",
    "\n",
    "Следует отметить, что в сравнении с техникой взвешивания модели на рассматриваемых наборах обучающих признаков показали разнонаправленную динамику:\n",
    "- на базовом наборе данных с добавлением масштабирования численных признаков значение метрики уменьшилось: 0.595 против 0.621; значение метрики ROC-AUC - 0.858 против 0.859\n",
    "- на наборе данных с добавлением производных признаков практически не изменилось: 0.612 против 0.610; значение метрики ROC-AUC - 0.850 против 0.853"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Уменьшение выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Уменьшим в обучающей выборке (техника downsample) долю объектов положительного класса в 4 раза, перемешаем полученные данные и передадим их в качестве новой обучающей выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_zeros = df_train.loc[df_train['exited'] == 0]\n",
    "features_ones = df_train.loc[df_train['exited'] == 1]\n",
    "\n",
    "features_downsampled = pd.concat([features_zeros.sample(frac=0.25, random_state=12345)] + [features_ones])\n",
    "\n",
    "features_downsampled = shuffle(features_downsampled, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_downsampled['exited'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_test, Y_test = get_train_test_X_Y(features, target, features_downsampled, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_opt3, Y_train_opt3, X_test_opt3, Y_test_opt3 = get_train_test_X_Y(features_opt3, target, features_downsampled, df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = LogisticRegression(random_state=random_magic, max_iter=5000, solver='liblinear')\n",
    "\n",
    "param_grid_lr = {\n",
    "    'model__C': [100, 10, 1.0],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_result = make_grid_search(\n",
    "    make_pipeline(preprocessor_opt3_lr, model_lr), \n",
    "    param_grid_lr, \n",
    "    X_train_opt3, Y_train_opt3, X_test_opt3, Y_test_opt3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выводы**\n",
    "\n",
    "Максимальное значение метрики F1 модели логистической регрессии получено на наборе данных с добавлением производных признаков. \n",
    "Полученное значение (0.55) выше, чем для несбалансированных классов, и совпадает со значением, полученным при взвешивании классов. Значение метрики достаточно далеко от целевого (0,59)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Решающее дерево"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dtc = DecisionTreeClassifier(random_state=random_magic)\n",
    "\n",
    "param_grid_dtc = {\n",
    "    'model__max_depth': [3, 4, 5, 7, 10],\n",
    "    'model__min_samples_split': [2, 3, 4, 5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_result = make_grid_search(\n",
    "    make_pipeline(preprocessor_opt2, model_dtc), \n",
    "    param_grid_dtc, \n",
    "    X_train, Y_train, X_test, Y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_result = make_grid_search(\n",
    "    make_pipeline(preprocessor_opt3, model_dtc), \n",
    "    param_grid_dtc, \n",
    "    X_train_opt3, Y_train_opt3, X_test_opt3, Y_test_opt3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выводы**\n",
    "\n",
    "Значения метрики F1 на каждом из наборов данных увеличилось по сравнению с несбалансированными классами, но уменьшилось в сравнении с техникой взвешивания. Целевой показатель метрики F1 не достигнут."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Случайный лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rfc = RandomForestClassifier(random_state=random_magic)\n",
    "\n",
    "param_grid_rfc = {\n",
    "    'model__n_estimators': [20, 30, 50],\n",
    "    'model__max_depth': [7, 10, 15],\n",
    "    'model__min_samples_split': [2, 3, 4]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_result = make_grid_search(\n",
    "    make_pipeline(preprocessor_opt2, model_rfc), \n",
    "    param_grid_rfc, \n",
    "    X_train, Y_train, X_test, Y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_result = make_grid_search(\n",
    "    make_pipeline(preprocessor_opt3, model_rfc), \n",
    "    param_grid_rfc, \n",
    "    X_train_opt3, Y_train_opt3, X_test_opt3, Y_test_opt3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выводы**\n",
    "\n",
    "На наборе данных с добавлением производных признаков модель случайного леса превысила целевой параметр метрики F1 (0.59) - получено значения 0.593.\n",
    "\n",
    "Следует отметить, что в сравнении с техникой взвешивания модели на рассматриваемых наборах обучающих признаков показали отрицательную динамику: значения метрики F1 уменьшились."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С целью увеличения значений метрики F1 рассматриваемых моделей выполнена балансировка целевых классов тремя различными способами:\n",
    "- взвешивание\n",
    "- увеличение обучающей выборки\n",
    "- уменьшение обучающей выборки\n",
    "\n",
    "По результатам обучения моделей с применением техник балансировки целевых классов получены следующие результаты:\n",
    "- по всем моделям показатели метрик увеличились относительно аналогичных несбалансированных случаев\n",
    "- наилучшие значения метрик - у моделей случайного леса\n",
    "- при применении взвешивания модели случайного леса показали следующий результат:\n",
    "    - на обоих рассматриваемых наборах обучающих признаков модель случайного леса превысила целевой параметр метрики F1 (0.59) - получены значения 0.62 и 0.61\n",
    "    - максимальное значение метрики F1 и наилучшее значение метрики ROC-AUC (а также наиболее выпуклый вид ROC-кривой) получено на базовом наборе данных с добавлением масштабирования численных признаков\n",
    "\n",
    "\n",
    "- при применении увеличения обучающей выборки имодели случайного леса показали следующий результат:\n",
    "    - на обоих рассматриваемых наборах обучающих признаков модель случайного леса превысила целевой параметр метрики F1 (0.59) - получены значения 0.595 и 0.61\n",
    "    - в сравнении с техникой взвешивания модели на рассматриваемых наборах обучающих признаков показали разнонаправленную динамику:\n",
    "      - на базовом наборе данных с добавлением масштабирования численных признаков значение метрики уменьшилось: 0.595 против 0.621; значение метрики ROC-AUC - 0.858 против 0.859\n",
    "      - на наборе данных с добавлением производных признаков практически не изменилось: 0.612 против 0.610; значение метрики ROC-AUC - 0.850 против 0.853\n",
    "\n",
    "\n",
    "- при применении уменьшения обучающей выборки имодели случайного леса показали следующий результат:\n",
    "    - на наборе данных с добавлением производных признаков модель случайного леса превысила целевой параметр метрики F1 (0.59) - получено значения 0.593\n",
    "    - следует отметить, что в сравнении с техникой взвешивания модели на рассматриваемых наборах обучающих признаков показали отрицательную динамику: значения метрики F1 уменьшились\n",
    "\n",
    "- относительно модели логистической регрессии - целевое значение метрики F1 не достигнуто, но при этом оно (0.55) выше, чем в несбалансированном случае\n",
    "\n",
    "По результатат обучения можно выделить две модели, которые целесообразно допустить до этапа итогового тестирования:\n",
    "- модель случайного леса со взвешиванием классов и значениями гиперпараметров:\n",
    "    - max_depth: 10\n",
    "    - min_samples_split: 3\n",
    "    - n_estimators: 50\n",
    "\n",
    "- модель случайного леса с применением увеличения обучающей выборки и значениями гиперпараметров:\n",
    "    - max_depth: 15\n",
    "    - min_samples_split: 3\n",
    "    - n_estimators: 50    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Итоговое тестирование и оценка моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем итоговое тестирование и оценку рассмотренных ранее моделей.\n",
    "\n",
    "Заново разделим данные на обучающую и тестовую выборки. Для итогового тестирования отведем на тестовую выборку 25% исходных данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = split_data(df_churn, 'exited', 0.25)\n",
    "df_train = get_imputed(df_train)\n",
    "df_test = get_imputed(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_opt3, Y_train_opt3, X_test_opt3, Y_test_opt3 = get_train_test_X_Y(features_opt3, target, df_train, df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Лучшая модель логистической регресси"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель логистической регрессии не смогла достичь целевого показателя метрики F1 равного 0.59. Наилучшее значение - 0.55 - получено при применении техники взвешивания для балансировки целевых классов на наиболее широком наборе обучающих признаков.\n",
    "\n",
    "Вместе с тем в рамках общей оценки полученных результатов проведем оценку параметров наилучшей модели этого класса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = LogisticRegression(random_state=random_magic, max_iter=5000, solver='liblinear', class_weight='balanced')\n",
    "\n",
    "param_grid_lr = {\n",
    "    'model__C': [1.0],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_result = make_grid_search(\n",
    "    make_pipeline(preprocessor_opt3_lr, model_lr), \n",
    "    param_grid_lr, \n",
    "    X_train_opt3, Y_train_opt3, X_test_opt3, Y_test_opt3,\n",
    "    True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отобразим график относительной значимости (модулей значений) признаков логистической регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_feature_importance(arr_importance, column_names):\n",
    "    rel_feature_imp = np.abs(100 * (arr_importance / max(arr_importance)))\n",
    "    \n",
    "    rel_feature_df = pd.DataFrame(\n",
    "        {\n",
    "            'features' : list(column_names),\n",
    "            'rel_importance' : rel_feature_imp\n",
    "        }\n",
    "    )\n",
    "\n",
    "    rel_feature_df = rel_feature_df.sort_values('rel_importance', ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.yticks(fontsize=15)\n",
    "\n",
    "    ax = sns.barplot(\n",
    "        x = 'rel_importance', \n",
    "        y = 'features',\n",
    "        data = rel_feature_df,\n",
    "        palette = 'Accent_r'\n",
    "    )\n",
    "\n",
    "    plt.xlabel('Относительная значимость', fontsize=25)\n",
    "    plt.ylabel('Признаки', fontsize=25)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_feature_importance(gs_result.best_estimator_.get_params()['model'].coef_[0], column_names_opt3_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следует отметить, что наиболее значимыми признаками модели оказались:\n",
    "- категория числа используемых банковских продуктов\n",
    "- признак активности\n",
    "- страна проживания\n",
    "- возраст\n",
    "- пол"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель случайного леса (вариант 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве первой модели, достигшей целевого уровня F1 (0.621 на тестовой выборке), рассмотрим модель случайного леса со значениями гиперпараметров\n",
    "- max_depth: 10\n",
    "- min_samples_split: 3\n",
    "- n_estimators: 50\n",
    "\n",
    "Проведем повторное обучение в более узком диапазоне гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_test, Y_test = get_train_test_X_Y(features, target, df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rfc = RandomForestClassifier(random_state=random_magic, class_weight='balanced')\n",
    "\n",
    "param_grid_rfc = {\n",
    "    'model__n_estimators': [40, 45, 50, 60],\n",
    "    'model__max_depth': [8, 10, 12],\n",
    "    'model__min_samples_split': [3, 4],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_result = make_grid_search(\n",
    "    make_pipeline(preprocessor_opt2, model_rfc), \n",
    "    param_grid_rfc, \n",
    "    X_train, Y_train, X_test, Y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_feature_importance(gs_result.best_estimator_.get_params()['model'].feature_importances_, column_names_opt2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализируем значения метрики F1, полученные на этапе обучения модели в виде 3D-куба (в зависимости от перебираемых параметров гипермодели). \n",
    "\n",
    "Размер точки обратно пропорционален времени обучения модели (чем больше диаметр точки, тем быстрее обучалась модель)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gridsearch_3d = (\n",
    "    pd.DataFrame({\n",
    "        \"mean_test_score\": gs_result.cv_results_[\"mean_test_score\"],\n",
    "        \"mean_fit_time\": gs_result.cv_results_[\"mean_fit_time\"]})\n",
    "      .join(json_normalize(gs_result.cv_results_[\"params\"]).add_prefix(\"param_\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list = list(\n",
    "    zip(\n",
    "        'max_depth: ' + df_gridsearch_3d['param_model__max_depth'].apply(str),\n",
    "        'n_estimators: ' + df_gridsearch_3d['param_model__n_estimators'].apply(str),\n",
    "        'min_samples_split: ' + df_gridsearch_3d['param_model__min_samples_split'].apply(str),\n",
    "        'Test score: ' + df_gridsearch_3d.mean_test_score.round(4).apply(str),\n",
    "         'Training time: ' + df_gridsearch_3d.mean_fit_time.round(2).apply(str) + 's',\n",
    "    )\n",
    ")\n",
    "\n",
    "text = ['<br>'.join(t) for t in text_list]\n",
    "\n",
    "df_gridsearch_3d['Text'] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_notebook_mode(connected=True)\n",
    "\n",
    "trace = go.Scatter3d(\n",
    "    x=df_gridsearch_3d['param_model__max_depth'],\n",
    "    y=df_gridsearch_3d['param_model__n_estimators'],\n",
    "    z=df_gridsearch_3d['param_model__min_samples_split'],\n",
    "    mode='markers', \n",
    "    marker=dict(\n",
    "        size= np.minimum(1 / np.log(df_gridsearch_3d.mean_fit_time * 10) * 30, 30),\n",
    "        color=df_gridsearch_3d.mean_test_score,\n",
    "        opacity=0.95,\n",
    "        colorscale='viridis',\n",
    "        colorbar=dict(title = 'Test score'),\n",
    "        line=dict(color='rgb(140, 140, 170)'),\n",
    "    ),\n",
    "    text=df_gridsearch_3d.Text,\n",
    "    hoverinfo='text'\n",
    ")\n",
    "\n",
    "data = [trace]\n",
    "layout = go.Layout(\n",
    "    title='Значения метрики F1 при кросс-валидации в зависимости от гиперпараметров',\n",
    "    margin=dict(\n",
    "        l=30,\n",
    "        r=30,\n",
    "        b=30,\n",
    "        t=30\n",
    "    ),\n",
    "    scene = dict(\n",
    "        xaxis = dict(\n",
    "            title='max_depth',\n",
    "            nticks=10\n",
    "        ),\n",
    "        yaxis = dict(\n",
    "            title='n_estimators',\n",
    "        ),\n",
    "        zaxis = dict(\n",
    "            title='min_samples_split',\n",
    "\n",
    "        ),\n",
    "    ),\n",
    " \n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значения метрики F1, полученные при обучении модели, максимальны для параметров:\n",
    "- max_depth (максимальная глубина дерева) равного 8\n",
    "- min_samples_split (минимальное количество элементов, необходимых для разделения внутреннего узла дерева) равном 3\n",
    "- n_estimators (число деревьев) равном 60\n",
    "\n",
    "Вместе с тем следует отметить, что указанное максимальное значение метрики находится в углу куба - это задает возможное направление для последующей настройки модели (более узкий диапазон параметров).\n",
    "\n",
    "Проведем повторное обучение модели в более узком диапазоне гиперпараметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rfc = RandomForestClassifier(random_state=random_magic, class_weight='balanced', min_samples_split=4)\n",
    "\n",
    "param_grid_rfc = {\n",
    "    'model__n_estimators': [55, 60, 65],\n",
    "    'model__max_depth': [7, 8, 9],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_result = make_grid_search(\n",
    "    make_pipeline(preprocessor_opt2, model_rfc), \n",
    "    param_grid_rfc, \n",
    "    X_train, Y_train, X_test, Y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ранее полученные параметры оказались оптимальными. Целевой показатель метрики F1 достигнут."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Изменение порога"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = gs_result.best_estimator_\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "probabilities_valid = best_model.predict_proba(X_test)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "\n",
    "for threshold in np.arange(0.3, 0.7, 0.01):\n",
    "    predicted_valid = probabilities_one_valid > threshold\n",
    "    precision = precision_score(Y_test, predicted_valid)\n",
    "    recall = recall_score(Y_test, predicted_valid)\n",
    "    f1 = f1_score(Y_test, predicted_valid)\n",
    "\n",
    "    print(\"Порог = {:.2f} | Точность = {:.3f}, Полнота = {:.3f}, F1 = {:.3f}\".format(\n",
    "        threshold, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В нашем случае важнее полнота - чем выше полнота, тем меньше ложноотрицательных ответов (т.е. клиентов, которые фактически ушли, но по которым модель дала отрицательное предсказание - соответственно им бы не были сделаны предложения, которые могли бы их оставить клиентами банка). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проанализировать, что важнее - точность или полнота!\n",
    "\n",
    "Полнота выявляет, какую долю положительных среди всех ответов выделила модель. Обычно они на вес золота, и важно понимать, как хорошо модель их находит.\n",
    "\n",
    "Recall = TP / (TP + FN)\n",
    "\n",
    "Полнота — это доля TP-ответов среди всех, у которых истинная метка 1. Хорошо, когда значение recall близко к единице: модель хорошо ищет положительные объекты. Если ближе к нулю — модель надо перепроверить и починить.\n",
    "\n",
    "Точность определяет, как много отрицательных ответов нашла модель, пока искала положительные. Чем больше отрицательных, тем ниже точность.\n",
    "\n",
    "Precision = TP / (TP + FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities_valid = best_model.predict_proba(X_test)\n",
    "precision, recall, thresholds = precision_recall_curve(Y_test, probabilities_valid[:, 1])\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.step(recall, precision, where='post')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('Кривая Precision-Recall')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель случайного леса (вариант 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве второй модели, достигшей целевого уровня F1 (0.612 на тестовой выборке), рассмотрим модель случайного леса со значениями гиперпараметров\n",
    "- max_depth: 15\n",
    "- min_samples_split: 3\n",
    "- n_estimators: 50\n",
    "\n",
    "Проведем повторное обучение в более узком диапазоне гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_zeros = df_train.loc[df_train['exited'] == 0]\n",
    "features_ones = df_train.loc[df_train['exited'] == 1]\n",
    "\n",
    "features_upsampled = pd.concat([features_zeros] + [features_ones] * 4)\n",
    "\n",
    "features_upsampled = shuffle(features_upsampled, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_upsampled['exited'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_opt3, Y_train_opt3, X_test_opt3, Y_test_opt3 = get_train_test_X_Y(features_opt3, target, features_upsampled, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rfc = RandomForestClassifier(random_state=random_magic)\n",
    "\n",
    "param_grid_rfc = {\n",
    "    'model__n_estimators': [40, 50, 70],\n",
    "    'model__max_depth': [8, 10, 15],\n",
    "    'model__min_samples_split': [2, 3, 4],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_result = make_grid_search(\n",
    "    make_pipeline(preprocessor_opt3, model_rfc), \n",
    "    param_grid_rfc, \n",
    "    X_train_opt3, Y_train_opt3, X_test_opt3, Y_test_opt3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_feature_importance(gs_result.best_estimator_.get_params()['model'].feature_importances_, column_names_opt3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следует отметить значительные различия в значениях метрики F1 на обучающей и тестовых выборках (0.95 и 0.60 соответственно), что вероятно свидетельствует о высокой степени переобученности нашей модели.\n",
    "\n",
    "Также следует отметить некоторые различия в значимости обучающих признаков от рассмотренной выше модели случайного леса. Состав первой пятерки признаков в целом совпадает, за исключением того, что указанная модель обучалась на наборе из которого был исключен первичный признак `estimated_salary` (предполагаемая зарплата), имеющих один из высоких коэффициентов значимости в модели выше. \n",
    "\n",
    "Вместе с тем данной модели также удалось достичь целевого показателя метрики F1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Изменение порога"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = gs_result.best_estimator_\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities_valid = best_model.predict_proba(X_test_opt3)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "\n",
    "for threshold in np.arange(0.3, 0.7, 0.01):\n",
    "    predicted_valid = probabilities_one_valid > threshold\n",
    "    precision = precision_score(Y_test_opt3, predicted_valid)\n",
    "    recall = recall_score(Y_test_opt3, predicted_valid)\n",
    "    f1 = f1_score(Y_test_opt3, predicted_valid)\n",
    "\n",
    "    print(\"Порог = {:.2f} | Точность = {:.3f}, Полнота = {:.3f}, F1 = {:.3f}\".format(\n",
    "        threshold, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В рамках тестирования проведено дополнительное обучение в более узком диапазоне гиперпараметров, а также оценка значимости обучающих признаков.\n",
    "\n",
    "По результатам итогового тестирования отобранные модели достигли целевого значения метрики (F1 = 0.61, ROC-AUC = 0.86 и F1 = 0.60, ROC-AUC = 0.85 соответственно при целевом значении F1 = 0.59). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В рамках ииследования по прогнозированию оттока клиентов «Бета-Банка» выполнены следующие основные этапы:\n",
    "\n",
    "1. На этапе предварительной обработки выполнены следующие шаги:\n",
    "- данные о клиентах обезличены\n",
    "- проведена оценка корреляции исходных признаков - по результатам оценки сильно коррелирующих исходных признаков не выявлено\n",
    "- проведена оценка распределения категориальных и числовых признаков, на основе которой сделаны предположения по формированию производных признаков:\n",
    "    - `max_credit_score` - признак достижения максимального кредитного рейтинга (условие: равенство кредитного рейтинга 850)\n",
    "    - `balance_overdraft` - признак отсутствия собственных средств клиента на балансе в банке (условие: равенство баланса 0)\n",
    "    - `products_category` - категория клиента по числу используемых продуктов банка (3 категории: 1, 2, 3 и более)\n",
    "- проведена оценка корреляции предложенных признаков с исходными\n",
    "- рассмотрены алгоритмы заполнения пропусков в значениях атрибута `tenure` (количество недвижимости у клиента) и выбран один, в наименьшей степени изменяющий исходное распределение \n",
    "\n",
    "2. В рамках дальнейшего изучения изучения исходных данных и уточнения задач исследования выполнены следующие шаги:\n",
    "- определен целевой признак\n",
    "- выявлен дисбаланс в классах целевого признака (соотношение 1:4 положительного и отрицательного класса) \n",
    "- сформированы 3 набора обучающих признаков и для каждого из них сформирован pipeline преобразований данных, который может быть использован в качестве элемента единого pipeline обработки данных и обучения моделей\n",
    "- для каждого набора признаков по результатам применения преобразований проведена оценка корреляции значений, поступающих непосредственно в качестве исходных данных для обучения моделей\n",
    "\n",
    "3. Проведено обучение моделей без учета наличия дисбаланса в классах целевого признака:\n",
    "- наилучшие значения метрики F1 (0.56 - 0.58) получены для моделей случайного леса и решающего дерева (на разных наборах обучающих признаков), при этом значения метрики AUC-ROC для моделей случайного леса выше, а график ROC-кривой более выпуклый и пологий\n",
    "- максимальное значение метрики F1 модели логистической регрессии получено на наборе данных с добавлением производных признаков, но полученное значение (0,49) далеко от целевого (0,59)\n",
    "\n",
    "4. С целью увеличения значений метрики F1 рассматриваемых моделей выполнена балансировка целевых классов тремя различными способами:\n",
    "- взвешивание\n",
    "- увеличение обучающей выборки\n",
    "- уменьшение обучающей выборки\n",
    "\n",
    "По результатам обучения моделей с применением техник балансировки получены следующие результаты:\n",
    "- по всем моделям показатели метрик увеличились относительно аналогичных несбалансированных случаев\n",
    "- наилучшие значения метрик - у моделей случайного леса\n",
    "- определены две модели для итогового тестирования:\n",
    "    - модель случайного леса со взвешиванием классов и значениями гиперпараметров:\n",
    "        - max_depth: 10\n",
    "        - min_samples_split: 3\n",
    "        - n_estimators: 50\n",
    "    - модель случайного леса с применением увеличения обучающей выборки и значениями гиперпараметров:\n",
    "        - max_depth: 15\n",
    "        - min_samples_split: 3\n",
    "        - n_estimators: 50  \n",
    "\n",
    "\n",
    "В рамках тестирования проведено дополнительное обучение в более узком диапазоне гиперпараметров, а также оценка значимости обучающих признаков. По результатам итогового тестирования отобранные модели достигли целевого значения метрики (F1 = 0.61, ROC-AUC = 0.86 и F1 = 0.60, ROC-AUC = 0.85 соответственно при целевом значении F1 = 0.59). \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "275px",
    "width": "749px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "283.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
